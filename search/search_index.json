{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Ruixiang's Notes","text":"<p>Ruixiang's Personal Page</p> <p>This site contains my technical notes. It has been a convenient reference to me for the past a few years. I hope some of the contents may also be useful to you.</p> <p>The notes are categorized into the following sections:</p> <ul> <li>System: OS/RTOS, Network, Software Framework/Middleware</li> <li>Hardware: embedded hardware, e.g. Raspberry Pi, Nvidia Jetson</li> <li>Programming: programming languages, e.g. C++/Python</li> <li>Robotics: knowledge base in robotics</li> <li>HOWTOs: short HOW-TO instructions</li> <li>Resource: useful online resources and references</li> </ul> <p>You can use the navigation bar on the left to browse the contents.</p>"},{"location":"hardware/beaglebone/beaglebone-boottime/","title":"Reduce Boot Time for Beaglebone","text":"<p>The following packages can be safely removed to reduce boot time:</p> <pre><code>$ sudo apt remove haveged bonescript c9-core-installer bb-node-red-installer nodejs bone101 nginx-full --purge\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-boottime/#reference","title":"Reference","text":"<ul> <li>[1] https://github.com/RobertCNelson/omap-image-builder/issues/113</li> </ul>"},{"location":"hardware/beaglebone/beaglebone-iio-imu/","title":"Build IMU IIO driver for Pocketbeagle","text":"<p>The workspace is assumed to be at \"~/beaglebone\" and everything will be inside this folder by default in the following steps.</p>"},{"location":"hardware/beaglebone/beaglebone-iio-imu/#install-tools","title":"Install tools","text":"<p>Install tools:</p> <pre><code>$ sudo apt install git bc bison flex libssl-dev make lzop\n</code></pre> <p>Install the same version of gcc compiler with the one in your debian image on Beaglebone. </p>"},{"location":"hardware/beaglebone/beaglebone-iio-imu/#fetch-linux-kernel-source","title":"Fetch Linux kernel source","text":"<ul> <li>Beaglebone Linux Kernel ()</li> </ul> <pre><code>$ git clone -b 4.19-rt https://github.com/beagleboard/linux.git\n</code></pre> <p>The folder \"linux\" will be refered as the \"target directory\" in the following context.</p> <ul> <li>ST Linux Kernel with IIO Drivers</li> </ul> <pre><code>$ git clone -b linux-4.19.y-gh https://github.com/STMicroelectronics/STMems_Linux_IIO_drivers.git\n</code></pre> <p>The folder \"STMems_Linux_IIO_drivers\" will be refered as the \"driver source directory\" in the following context.</p> <p>Note: you will need to switch to a different branch accordingly if you want to use a different Linux kernel version.</p>"},{"location":"hardware/beaglebone/beaglebone-iio-imu/#integrate-iio-drivers","title":"Integrate IIO drivers","text":"<p>Follow the instructions in README.md at https://github.com/STMicroelectronics/STMems_Linux_IIO_drivers/tree/linux-4.19.y-gh </p> <p>Here is a brief summary of the steps:</p> <ol> <li>Copy driver source code (STMems_Linux_IIO_drivers/drivers/iio/imu/&lt;your-imu-ic-name&gt;) into the target directory (linux/drivers/iio/imu/&lt;your-imu-ic-name&gt;)</li> <li>Update Kconfig and makefile in the target directory to include the driver to be integrated</li> <li>Update custom event and channel types in \"include/uapi/linux/iio/types.h\" and \"include/uapi/linux/iio/types.h\" in the target directory</li> </ol> <p>Now you have the beaglebone kernel source \"patched\" with the ST IIO sensor driver. You can build and deploy the kernel as usual.</p> <pre><code>$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- bb.org_defconfig \n$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- menuconfig\n</code></pre> <p>You would need to update the following configurations. Additional options might be needed according to your application:</p> <pre><code>* General setup ---&gt; \n    - Local version - append to kernel release : \"-pb-imu-rt\"\n* Kernel Features  ---&gt;\n    - Timer frequency : change to 1000Hz\n* Device Drivers ---&gt;\n    - Industrial I/O support ---&gt;\n        - Mark your driver module as \"M\"\n</code></pre> <p>After configuration, you can build the kernel</p> <pre><code>$ make -j12 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- deb-pkg\n</code></pre> <p>You will get 3 .deb files to be installed on the pocketbeagle, e.g.:</p> <ul> <li>linux-headers-4.19.94-pb-imu-rt+_4.19.94-pb-imu-rt+-5_armhf.deb</li> <li>linux-libc-dev_4.19.94-pb-imu-rt+-5_armhf.deb</li> <li>linux-image-4.19.94-pb-imu-rt+_4.19.94-pb-imu-rt+-5_armhf.deb</li> </ul> <p>Copy and install on pocketbeagle with \"dpkg\" command.</p>"},{"location":"hardware/beaglebone/beaglebone-iio-imu/#update-device-tree-overlay","title":"Update device tree overlay","text":"<ul> <li>Build the device tree overlay</li> </ul> <p>Now you've got the drivers compiled with the kernel and you will need to add a device tree overlay to load the driver.</p> <pre><code>$ git clone https://github.com/beagleboard/bb.org-overlays.git\n</code></pre> <p>It's easiest to use overlay files inside this repository as the base and modify from one that is cloest to your setup. For example, my LSM6DSM is connected to the SPI0 on pocketbeagle and I use \"bb.org-overlays/src/arm/PB-SPI0-ETH-WIZ-CLICK.dts\" as a reference to make my \"bb.org-overlays/src/arm/PB-SPI0-LSM6DSMTR.dts\"</p> <pre><code>/*\n * Copyright (C) 2017 Robert Nelson &lt;robertcnelson@gmail.com&gt;\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n *\n */\n\n/dts-v1/;\n/plugin/;\n\n#include &lt;dt-bindings/gpio/gpio.h&gt;\n#include &lt;dt-bindings/pinctrl/am33xx.h&gt;\n#include &lt;dt-bindings/interrupt-controller/irq.h&gt;\n\n/ {\n    /*\n     * Helper to show loaded overlays under: /proc/device-tree/chosen/overlays/\n     */\n    fragment@0 {\n        target-path=\"/\";\n        __overlay__ {\n\n            chosen {\n                overlays {\n                    PB-SPI0-LSM6DSMTR = __TIMESTAMP__;\n                };\n            };\n        };\n    };\n\n    /*\n     * Free up the pins used by the cape from the pinmux helpers.\n     */\n    fragment@1 {\n        target = &lt;&amp;ocp&gt;;\n        __overlay__ {\n            P1_04_pinmux { status = \"disabled\"; }; /* LSM6DSMTR INT1 */\n            P1_06_pinmux { status = \"disabled\"; }; /* SPI0 CS0 */\n            P1_08_pinmux { status = \"disabled\"; }; /* SPI0 CLK */\n            P1_10_pinmux { status = \"disabled\"; }; /* SPI0 MISO */\n            P1_12_pinmux { status = \"disabled\"; }; /* SPI0 MOSI */\n            P2_22_pinmux { status = \"disabled\"; }; /* LSM6DSMTR INT2 (not used) */\n        };\n    };\n\n    fragment@2 {\n        target = &lt;&amp;am33xx_pinmux&gt;;\n        __overlay__ {\n            lsm6dsmtr_pins: pinmux_lsm6dsmtr_pins {\n                pinctrl-single,pins = &lt;\n                    AM33XX_IOPAD(0x0838, PIN_INPUT | MUX_MODE7 ) /* (T6) P2_22, gpmc_ad14.gpio1[14] INT2 */\n                    AM33XX_IOPAD(0x08ec, PIN_INPUT | MUX_MODE7 ) /* (R6) P1_04, gpmc_a11.gpio2[25] INT1 */\n                &gt;;\n            };\n\n            pb_spi0_pins: pinmux_pb_spi0_pins {\n                pinctrl-single,pins = &lt;\n                    AM33XX_IOPAD(0x0950, PIN_INPUT | MUX_MODE0 ) /* (A17) spi0_sclk.spi0_sclk */\n                    AM33XX_IOPAD(0x0954, PIN_INPUT | MUX_MODE0 ) /* (B17) spi0_d0.spi0_d0 */\n                    AM33XX_IOPAD(0x0958, PIN_INPUT | MUX_MODE0 ) /* (B16) spi0_d1.spi0_d1 */\n                    AM33XX_IOPAD(0x095c, PIN_INPUT | MUX_MODE0 ) /* (A16) spi0_cs0.spi0_cs0 */\n                &gt;;\n            };\n        };\n    };\n\n    fragment@3 {\n        target = &lt;&amp;spi0&gt;;\n        __overlay__ {\n            status = \"okay\";\n            pinctrl-names = \"default\";\n            pinctrl-0 = &lt;&amp;pb_spi0_pins&gt;;\n\n            channel@0{ status = \"disabled\"; };\n            channel@1{ status = \"disabled\"; };\n        };\n    };\n\n    fragment@4 {\n        target = &lt;&amp;spi0&gt;;\n        __overlay__ {\n            #address-cells = &lt;1&gt;;\n            #size-cells = &lt;0&gt;;\n\n            lsm6dsmtr: lsm6dsm@0 {\n                spi-max-frequency = &lt;5000000&gt;;\n                compatible = \"st,lsm6dsm\";\n                reg = &lt;0x0&gt;;\n                interrupt-parent = &lt;&amp;gpio2&gt;;\n                interrupts = &lt;25 IRQ_TYPE_LEVEL_HIGH&gt;;\n            };\n        };\n    };\n};\n</code></pre> <p>If everything in the device tree is set up correctly, you will get \"bb.org-overlays/src/arm/PB-SPI0-LSM6DSMTR.dtbo\" after executing \"make\". Copy this dtbo file to \"/lib/firmware\" folder on the pocketbeagle.</p> <ul> <li>Use the compiled device tree overlay file</li> </ul> <p>Open \"/boot/uEnv.txt\" with a text editor on your pocketbeagle, add the following line at the \"Additional custom capes\" section:</p> <pre><code>###Additional custom capes\nuboot_overlay_addr4=/lib/firmware/PB-SPI0-LSM6DSMTR-INT1.dtbo\n</code></pre> <p>Now you can reboot and the driver should be loaded correctly. You can check the IMU devices at \"/sys/bus/iio/devices\" and you should see devices like \"iio:device0\", \"iio:device1\" etc. In my case, \"iio:device1\" cooresponds to the accelerometer and you can see attributes like:</p> <ul> <li>current_timestamp_clock</li> <li>in_accel_x_raw</li> <li>in_accel_x_scale</li> <li>in_accel_y_raw</li> <li>in_accel_y_scale</li> <li>in_accel_z_raw</li> <li>in_accel_z_scale</li> </ul> <p>You should be able to read values from the attributes, for example: </p> <pre><code>debian@beaglebone:/sys/bus/iio/devices/iio:device1$ cat in_accel_z_raw\n17111\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-iio-imu/#reference","title":"Reference","text":"<ul> <li>[1] https://wiki.analog.com/resources/tools-software/linux-drivers/iio-inertial-measurement-units/adis16475#trigger_management</li> <li>[2] https://events19.linuxfoundation.org/wp-content/uploads/2017/12/Bandan-Das_Drone_SITL_bringup_with_the_IIO_framework.pdf</li> <li>[3] https://github.com/STMicroelectronics/st-mems-android-linux-drivers-iio</li> <li>[4] https://www.kernel.org/doc/html/v5.10/driver-api/iio/index.html</li> </ul>"},{"location":"hardware/beaglebone/beaglebone-setup/","title":"Beaglebone Setup","text":""},{"location":"hardware/beaglebone/beaglebone-setup/#flash-image-to-emmc","title":"Flash Image to eMMC","text":"<p>Follow reference [1] to flash the OS to the eMMC storage. A brief summary:</p> <ul> <li>Download image and extract the .img file</li> <li>Create a bootable SD card with the image (using tools such as etcher)</li> <li>Boot into the OS on the SD card (holding the SD button and then power up the board)</li> <li>Modify \"/boot/uEnv.txt\" and uncomment the line that enables the flasher</li> <li>Shutdown the board and boot from the SD again, wait until the eMMC is flashed with the system</li> </ul> <p>You can login to the system after the board boots up</p> <pre><code>$ ssh debian@192.168.7.2 # default password: temppwd\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-setup/#setup-ethernet-over-usb-for-pocketbeagle","title":"Setup Ethernet over USB for Pocketbeagle","text":"<p>Add the following lines to /etc/network/interfaces by modifying the files directly after you mount the SD card to your computer</p> <pre><code>iface usb0 inet static\n    address 192.168.7.2\n    netmask 255.255.255.0\n    gateway 192.168.7.1\n    dns-nameservers 8.8.8.8\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-setup/#add-new-user","title":"Add New User","text":"<p>Now you can add your own account and delete the default one</p> <pre><code>$ sudo adduser --ingroup users &lt;USERNAME&gt;\n$ sudo adduser &lt;YOUR_USERNAME&gt; sudo\n$ logout\n$ sudo deluser --remove-home user\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-setup/#setup-wifi","title":"Setup Wifi","text":"<p>You can use \"connman\" to manage the wireless network. But I personally prefer using the old way.</p> <ul> <li>Disable connman</li> </ul> <pre><code>$ systemctl disable connman.service\n</code></pre> <ul> <li>Generate WPA passphrase for your WiFi</li> </ul> <pre><code>$ wpa_passphrase &lt;ssid&gt; &lt;password&gt;\n</code></pre> <ul> <li>Update iface usb0 inet static     address 192.168.7.2     netmask 255.255.255.0     gateway 192.168.7.1     dns-nameservers 8.8.8.8</li> </ul> <p><pre><code>$ sudo nano /etc/network/interfaces\n</code></pre> <pre><code># interfaces(5) file used by ifup(8) and ifdown(8)\nauto lo\niface lo inet loopback\n\nauto wlan0\niface wlan0 inet dhcp\n    wpa-ssid ExampleWifi\n    wpa-psk &lt;wpa-psk-generated-by-wpa-passphrase-command&gt;   \n</code></pre></p>"},{"location":"hardware/beaglebone/beaglebone-setup/#mount-usr-and-home-on-sd-card","title":"Mount \"/usr\" and \"/home\" on SD card","text":"<p>The BeagleBone Blue has 4G on-board eMMC flash storage. It could be enough for many applications. But for experimental projects, it's more convenient to have more space so that you don't need to worry too much about filling the eMMC flash up when installing new packages.</p> <p>Check reference [2] to get more detailed instructions. Here is a brief summary of what you need to do:</p> <pre><code># 1. format your SD card into two partitions\n# 2. insert the SD card and power up the board\n# 3. check if you have the two partitions on the SD card recognized by the OS correctly\n$ fdisk -l\n# (the two partitions are labeled as \"/dev/mmcblk0p1\" and \"/dev/mmcblk0p2\" on my board)\n# 4. format the two partions as ext4\n$ mkfs.ext4 /dev/mmcblk0p1\n$ mkfs.ext4 /dev/mmcblk0p2 \n# 5. create temporary folders in /tmp and mount the two partitions to the temporary folders, copy files from /usr and /home accordingly\n$ sudo mkdir /tmp/usr \n$ sudo mkdir /tmp/home\n$ sudo mount /dev/mmcblk0p1 /tmp/usr \n$ sudo mount /dev/mmcblk0p2 /tmp/home\n$ sudo rsync -ahv --progress /usr/ /tmp/usr/\n$ sudo rsync -ahv --progress /home/ /tmp/home/ \n# 6. update /etc/fstab to reflect the change\n$ sudo lsblk -no UUID /dev/mmcblk0p1 # get UUID of /dev/mmcblk0p1\n# add two lines in /etc/fstab\n$ UUID=&lt;ID-YOU-GOT-FROM-ABOVE-CMD&gt; /usr ext4    defaults 0 1\n$ UUID=&lt;ID-YOU-GOT-FROM-ABOVE-CMD&gt; /home ext4    defaults 0 1\nor\n$ /dev/mmcblk0p1 /usr ext4 defaults 0 1\n$ /dev/mmcblk0p2 /home ext4 defaults 0 1\n# 7. reboot and check the files\n$ df -h\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-setup/#add-a-swap-file","title":"Add a Swap File","text":"<p>Sometimes a swap area may be needed to compile a large project on beaglebone black. Instead of setting up a swap partition, you can also use a swap file.</p> <p>In the following steps, a swap file \"/usr/swapfile1\" will be created and used.</p> <pre><code># 1. Create Storage File\n$ sudo dd if=/dev/zero of=/usr/swapfile1 bs=1024 count=524288\n# 2. Secure swap file\n$ sudo chown root:root /usr/swapfile1\n$ sudo chmod 0600 /usr/swapfile1\n# 3. Set up a Linux swap area and enable the swap file\n$ sudo mkswap /usr/swapfile1\n$ sudo swapon /usr/swapfile1\n# 4. Update /etc/fstab file\n$ sudo nano /etc/fstab \n# Add the following line\n/usr/swapfile1 none swap sw 0 0\n</code></pre> <p>Reboot the board and use htop to check if the swap file is set up correctly.</p>"},{"location":"hardware/beaglebone/beaglebone-setup/#update-kernel","title":"Update Kernel","text":"<p>You can upgrade or change to a Preempt-RT patched kernel using the script provided in the Debian OS from Beaglebone</p> <pre><code>$ cd /opt/scripts/tools\n$ git pull   # you may need to use sudo here\n$ sudo /opt/scripts/tools/update_kernel.sh --bone-rt-channel --lts-4_4   # --lts-stable or other available options\n</code></pre> <p>Refer to [5] for additiona options.</p> <p>Note that if you use the kernel from TI channel (for example, use \"--ti-rt-channel\" option), you might experience errors related to the PINMUX helper driver. </p>"},{"location":"hardware/beaglebone/beaglebone-setup/#robotics-cape-library","title":"Robotics Cape library","text":"<p>TI channel kernels have more complete support to PRU drivers so you may want to use a kernel from the TI channel if you're using the Robotics Cape or Beaglebone Blue.[7]</p> <p>When using the TI channel RT kernel 4.4 and 4.9 on Beaglebone Blue with the Robotics Cape library, I got the following error message from the library:</p> <pre><code>...\ncan't open: /sys/devices/platform/ocp/ocp:P9_24_pinmux/state\nPinmux: No such file or directory\nWARNING: missing PINMUX driver\nYou probbaly just need a newer kernel\n</code></pre> <p>I'm not sure if this will happen to other boards or how to install this pinmux helper driver manually for the TI channel kernels. I resolved this issue by switching to a bone channel kernel.</p> <p>The other issue related to the Robotics Cape library that occured even after installing the bone channel RT kernel is on the pru-rproc driver, which gives the error message</p> <pre><code>ERROR: pru-rproc driver missing\n</code></pre> <p>The solution is to add a symbolic link of clpru executable to /usr/share/ti/cgt-pru/bin folder:</p> <pre><code>$ cd /usr/share/ti/cgt-pru\n$ mkdir bin\n$ cd bin\n$ ln -s /usr/bin/clpru clpru\n</code></pre> <p>See [6] for more discussions on this issue and the above solution is from this page.</p> <p>Reference</p> <ul> <li>[1] https://github.com/beagleboard/beaglebone-blue/wiki/Flashing-firmware</li> <li>[2] https://gist.github.com/rxdu/35fb70c71cde5b44815e52bd8c338ff3</li> <li>[3] http://xeikonmirkwood.blogspot.com/2014/05/connman-is-annoying.html</li> <li>[4] http://pdkb.azurewebsites.net/Home/Detail/installing-can-bus-drivers-for-osd3358-systems-running-debian</li> <li>[5] https://github.com/beagleboard/bb.org-overlays</li> <li>[6] https://groups.google.com/forum/#!topic/beagleboard/od6h9yTKUD4</li> <li>[7] https://github.com/StrawsonDesign/librobotcontrol/issues/130</li> <li>[8] https://www.cyberciti.biz/faq/linux-add-a-swap-file-howto/</li> </ul>"},{"location":"hardware/beaglebone/beaglebone-usb-network-share/","title":"Share Internet through the USB Port on Pocketbeagle","text":"<p>On the host computer, there are two interfaces invoved: </p> <ul> <li>the USB connection to pocketbeagle, e.g. \"enx60640568c683\"</li> <li>the other network adapter that has Internet access, e.g. \"eno1\"</li> </ul> <p>then on the host computer, do the following</p> <pre><code>$ sudo -i\n$ echo \"1\" &gt; /proc/sys/net/ipv4/ip_forward\n$ iptables --table nat --append POSTROUTING --out-interface eno1 -j MASQUERADE\n$ iptables --append FORWARD --in-interface enx60640568c683 --out-interface eno1 -j ACCEPT\n$ iptables --append FORWARD --in-interface eno1 --out-interface enx60640568c683 -m state --state RELATED,ESTABLISHED -j ACCEPT\n$ iptables --append FORWARD --in-interface enx60640568c683 -j ACCEPT\n</code></pre> <p>On the pocketbeagle, do the following</p> <pre><code>$ sudo route add default gw 192.168.7.1\n$ sudo bash -c 'echo \"nameserver 8.8.8.8\" &gt;&gt; /etc/resolv.conf'\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-usb-network-share/#reference","title":"Reference","text":"<ul> <li>[1] https://wiki.analog.com/resources/tools-software/linux-drivers/iio-inertial-measurement-units/adis16475#trigger_management</li> </ul>"},{"location":"hardware/beaglebone/beaglebone-xenomai/","title":"Xenomai on Beaglebone","text":"<p>Build Xenomai-patched Linux for Beaglebone Black[1]. The general building steps for other ARM-based boards should be similar but specific details related to hardware can be drastically different.</p>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#install-toolchain","title":"Install toolchain","text":"<p>If you use a pre-built root file system, make sure you're using a compatible toolchain to compile bootloader and kernel.</p> <pre><code>$ wget -c https://releases.linaro.org/components/toolchain/binaries/6.4-2018.05/arm-linux-gnueabihf/gcc-linaro-6.4.1-2018.05-x86_64_arm-linux-gnueabihf.tar.xz\n$ tar xf gcc-linaro-6.4.1-2018.05-x86_64_arm-linux-gnueabihf.tar.xz\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#install-dependencies","title":"Install dependencies","text":"<pre><code>$ sudo apt install bison flex lzop u-boot-tools\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#build-bootloader","title":"Build bootloader","text":"<pre><code>$ git clone https://github.com/u-boot/u-boot\n$ cd u-boot/\n$ git checkout v2018.09 -b tmp-v2018.09\n\n$ wget -c https://rcn-ee.com/repos/git/u-boot-patches/v2018.09/0001-am335x_evm-uEnv.txt-bootz-n-fixes.patch\n$ wget -c https://rcn-ee.com/repos/git/u-boot-patches/v2018.09/0002-U-Boot-BeagleBone-Cape-Manager.patch\n\n$ patch -p1 &lt; 0001-am335x_evm-uEnv.txt-bootz-n-fixes.patch\n$ patch -p1 &lt; 0002-U-Boot-BeagleBone-Cape-Manager.patch\n\n$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- distclean\n$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- am335x_evm_defconfig\n$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- \n</code></pre> <p>You should get \"MLO\", \"u-boot.img\" in the root folder of u-boot after successful compilation.</p>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#buid-kernel","title":"Buid Kernel","text":"<p>Download kernel source file</p> <pre><code>$ git clone https://github.com/beagleboard/linux.git\n\n# look for the desired branch, for example\n$ git tag -l | grep 4.9\n\n# checkout the desired version into a new branch, use \"4.9.88-ti-xenomai-r107\" as an example\n$ git checkout 4.9.88-ti-xenomai-r107 -b tmp-4.9.88-ti-xenomai-r107\n</code></pre> <p>Start the configuration menu and modify kernel options</p> <pre><code>$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- bb.org_defconfig \n$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- menuconfig\n</code></pre> <p>Check the following configurations for Xenomai</p> <pre><code>* General setup ---&gt; \n- Local version - append to kernel release : \"-ti-xenomai-r107\"\n- Stack Protector buffer overflow detection: Disable \n* Kernel Features  ---&gt;\n- Preemption Model : select \"Preemptible Kernel (Low-Latency Desktop)\"                           \n- Timer frequency : change to 1000Hz\n- [] Allow for memory compaction : Disable\n- [] Contiguous Memory Allocator : Disable\n* CPU Power Management  ---&gt;\n- [] CPU Frequency scaling : Disable\n\n* Kernel hacking  ---&gt;\n- [] KGDB: kernel debugger : Disable\n</code></pre> <p>You could also enable Xenomai supported device drivers in the config according to your needs.</p> <p>Build kernel image:</p> <pre><code>$ make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- zImage dtbs\n$ make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- modules\n</code></pre> <p>If you need to build uImage</p> <pre><code>$ make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- uImage LOADADDR=0x80008000\n</code></pre> <p>You can also build debian packages for easier installation (for example, update kernel on the eMMC)</p> <pre><code>$ make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- deb-pkg\n</code></pre> <p>If you want to add a custom string identifier to your kernel name, you can add the \"LOCALVERSION\" parameter</p> <pre><code>$ make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- deb-pkg LOCALVERSION=-rt\n</code></pre> <p>Alternatively, you could deploy to the SD card manually.</p>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#prepare-sd-card","title":"Prepare SD card","text":"<p>Create 2 partitions</p> <ul> <li>/boot formated in FAT32 with \"boot\" flag </li> <li>/rootfs formated in ext4</li> </ul> <p>Set SD card location and kernel version for installation</p> <pre><code>$ export SD_ROOTFS=/media/rdu/rootfs\n$ export kernel_version=4.9.88-ti-xenomai-r107 \n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#deploy-u-boot","title":"Deploy u-boot","text":"<p>You need to copy \"MLO\", \"u-boot.img\", and the \"uEnv.txt\" into the /boot partitiona on the SD card.</p> <p><pre><code>##Rename as: uEnv.txt to override old bootloader in eMMC\n##These are needed to be compliant with Angstrom's 2013.06.20 u-boot.\n\nloadaddr=0x82000000\nfdtaddr=0x88000000\nrdaddr=0x88080000\n\ninitrd_high=0xffffffff\nfdt_high=0xffffffff\n\n##These are needed to be compliant with Debian 2014-05-14 u-boot.\n\nloadximage=echo debug: [/boot/vmlinuz-${uname_r}] ... ; load mmc 0:2 ${loadaddr} /boot/vmlinuz-${uname_r}\nloadxfdt=echo debug: [/boot/dtbs/${uname_r}/${fdtfile}] ... ;load mmc 0:2 ${fdtaddr} /boot/dtbs/${uname_r}/${fdtfile}\nloadxrd=echo debug: [/boot/initrd.img-${uname_r}] ... ; load mmc 0:2 ${rdaddr} /boot/initrd.img-${uname_r}; setenv rdsize ${filesize}\nloaduEnvtxt=load mmc 0:2 ${loadaddr} /boot/uEnv.txt ; env import -t ${loadaddr} ${filesize};\ncheck_dtb=if test -n ${dtb}; then setenv fdtfile ${dtb};fi;\ncheck_uboot_overlays=if test -n ${enable_uboot_overlays}; then setenv enable_uboot_overlays ;fi;\nloadall=run loaduEnvtxt; run check_dtb; run check_uboot_overlays; run loadximage; run loadxrd; run loadxfdt;\n\nmmcargs=setenv bootargs console=tty0 console=${console} ${optargs} ${cape_disable} ${cape_enable} root=/dev/mmcblk0p2 rootfstype=${mmcrootfstype} ${cmdline}\n\nuenvcmd=run loadall; run mmcargs; echo debug: [${bootargs}] ... ; echo debug: [bootz ${loadaddr} ${rdaddr}:${rdsize} ${fdtaddr}] ... ; bootz ${loadaddr} ${rdaddr}:${rdsize} ${fdtaddr};\n</code></pre> Make sure you specify the right path to the rootfs in \"/boot/uEnv.txt\". In the uEnv.txt shown above, it is \"root=/dev/mmcblk0p2\".</p>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#root-file-system","title":"Root file system","text":"<p>You can use tools like buildroot to make your customized root file system or you can use debootstrap or multistrap to build your Debian/Ubuntu distribution. Here I use the pre-built debian for Beaglebone.</p> <p>Copy pre-built root file system to the SD card</p> <pre><code>$ wget -c https://rcn-ee.com/rootfs/eewiki/minfs/debian-9.5-minimal-armhf-2018-07-30.tar.xz\n$ tar xf debian-9.5-minimal-armhf-2018-07-30.tar.xz\n$ sudo tar xfvp ./*-*-*-armhf-*/armhf-rootfs-*.tar -C /media/rootfs/\n$ sync\n$ sudo chown root:root /media/rootfs/\n$ sudo chmod 755 /media/rootfs/\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#deploy-kernel","title":"Deploy kernel","text":"<p>Install kernel and device tree:</p> <pre><code># kernel\n$ sudo cp -v ./arch/arm/boot/zImage ${SD_ROOTFS}/boot/vmlinuz-${kernel_version}\n\n# device tree\n$ sudo mkdir -p ${SD_ROOTFS}/boot/dtbs/${kernel_version}\n$ sudo cp -v ./arch/arm/boot/dts/am335x* ${SD_ROOTFS}/boot/dtbs/${kernel_version}\n</code></pre> <p>Install headers:</p> <pre><code>$ make -j8 ARCH=arm headers_check\n$ sudo make -j8 ARCH=arm INSTALL_HDR_PATH=${SD_ROOTFS} headers_install\n</code></pre> <p>Install modules and firmware</p> <pre><code>$ sudo make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- modules_install INSTALL_MOD_PATH=${SD_ROOTFS}\n$ sudo make -j8 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- firmware_install INSTALL_MOD_PATH=${SD_ROOTFS}\n</code></pre> <p>Update \"/rootfs/boot/uEnv.txt\":</p> <pre><code>uname_r=4.9.88-ti-xenomai-r107\n</code></pre>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#additional-configurations","title":"Additional configurations","text":"<p>Update fstab (Note you may need to change \"/dev/mmcblk0p2\" according to your SD configuration)</p> <pre><code>$ sudo sh -c \"echo '/dev/mmcblk0p2  /  auto  errors=remount-ro  0  1' &gt;&gt; /media/rootfs/etc/fstab\"\n</code></pre> <p>Update hostname (default is \"arm\")</p> <pre><code>$ sudo nano /etc/hostname\n$ sudo nano /etc/hosts\n</code></pre> <p>Update network interface </p> <pre><code>$ sudo nano /etc/network/interfaces\n</code></pre> <pre><code>auto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet dhcp\n</code></pre> <p>At this point, you should have a bootable Linux running on the Beaglebone.</p>"},{"location":"hardware/beaglebone/beaglebone-xenomai/#install-xenomai-tools-and-libraries","title":"Install Xenomai tools and libraries","text":"<p>First you need to check which version of Xenomai is install with the kernel. </p> <pre><code>$ cat /proc/xenomai/version\n</code></pre> <p>In this case, the version of Xenomai is 3.0.6. Download code from the Xenomai website. </p> <p>Install dependencies</p> <pre><code>$ sudo apt-get install build-essential libtool libltdl-dev\n</code></pre> <p>Finally build the code</p> <pre><code>$ ./scripts/bootstrap\n$ ./configure --enable-smp --with-core=cobalt\n$ make\n$ sudo make install\n</code></pre> <p>Once finished, you can test if the installation is successful</p> <p><pre><code>$ cd /usr/xenomai/bin\n$ sudo ./latency\n</code></pre> You should get something like</p> <pre><code>== Sampling period: 1000 us\n== Test mode: periodic user-mode task\n== All results in microseconds\nwarming up...\nRTT|  00:00:01  (periodic user-mode task, 1000 us period, priority 99)\nRTH|----lat min|----lat avg|----lat max|-overrun|---msw|---lat best|--lat worst\nRTD|      4.041|      6.969|     28.750|       0|     0|      4.041|     28.750\nRTD|      4.083|      8.077|     39.708|       0|     0|      4.041|     39.708\nRTD|      4.041|      7.884|     40.541|       0|     0|      4.041|     40.541\nRTD|      4.082|      7.033|     37.291|       0|     0|      4.041|     40.541\nRTD|      4.082|      8.122|     42.165|       0|     0|      4.041|     42.165\nRTD|      4.082|      7.020|     37.249|       0|     0|      4.041|     42.165\nRTD|      4.082|      8.145|     42.457|       0|     0|      4.041|     42.457\nRTD|      3.831|      7.878|     41.415|       0|     0|      3.831|     42.457\nRTD|      4.040|      6.717|     32.665|       0|     0|      3.831|     42.457\n</code></pre> <p>Reference</p> <ul> <li>[1] https://www.digikey.com/eewiki/display/linuxonarm/BeagleBone+Black</li> <li>[2] http://www.simplerobot.net/2018/06/build-realtime-xenomai-3-kernel-for.html</li> <li>[3] https://lemariva.com/blog/2018/07/raspberry-pi-xenomai-patching-tutorial-for-kernel-4-14-y</li> <li>[4] https://stackoverflow.com/questions/21740619/how-can-i-generate-kernel-headers-for-an-unknown-embedded-arm-system</li> <li>[5] https://www.vultr.com/docs/how-to-change-your-hostname-on-debian</li> </ul>"},{"location":"hardware/jetson/boot-jetson-tx2-from-microsd/","title":"Boot Jetson TX2/Nano from MicroSD Card","text":"<p>This note may be useful if you're using a Jetson Nano/TX2 production module with 16G eMMC but want to boot from an SD card for more space.</p>"},{"location":"hardware/jetson/boot-jetson-tx2-from-microsd/#install-the-bootloader","title":"Install the bootloader","text":"<p>You first need to flash the eMMC normally with SDK manager. This process will install bootloader and firmware to the module.</p>"},{"location":"hardware/jetson/boot-jetson-tx2-from-microsd/#copy-root-filesystem-to-sd-card","title":"Copy Root Filesystem to SD Card","text":"<p>After the normal flashing process, you should be able to boot into the l4t system on eMMC. Insert the SD card to the Jetson board and format the card as \"ext4\" filesystem. Mount the SD card to the system. Here it's assumed that you mount the card to \"/media/user/sdcard\". Now you can copy the root filesystem to the SD card.</p> <pre><code>$ sudo rsync -axHAWX --numeric-ids --info=progress2 --exclude=/proc / /media/user/sdcard\n</code></pre>"},{"location":"hardware/jetson/boot-jetson-tx2-from-microsd/#modify-boot-sequence","title":"Modify Boot Sequence","text":"<p>For Jetpack 4.x (tested with Jetpack 4.6.2), the bootloader searches for the filesystem following the following order: SD card &gt; eMMC &gt; USB &gt; NFS. This means if you want to boot from SD card, the boot configuration file \"/boot/extlinux/extlinux.conf\" on the SD card must be modified properly. What you need to do is to add a new boot entry, change root to the desired device (e.g. \"/dev/mmcblk2p1\") and update the default entry to be \"microsd\". The following is an example of the boot configuration file:</p> <pre><code>TIMEOUT 30\nDEFAULT microsd\n\nMENU TITLE L4T boot options\n\nLABEL microsd\n      MENU LABEL microsd kernel\n      LINUX /boot/Image\n      INITRD /boot/initrd\n      APPEND ${cbootargs} quiet root=/dev/mmcblk2p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 OS=l4t fbcon=map:0 net.ifnames=0\n\nLABEL primary\n      MENU LABEL primary kernel\n      LINUX /boot/Image\n      INITRD /boot/initrd\n      APPEND ${cbootargs} quiet root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 OS=l4t fbcon=map:0 net.ifnames=0 \n\n# When testing a custom kernel, it is recommended that you create a backup of\n# ...\n# ...\n</code></pre> <p>Now reboot and verify your rootfilesystem is on the SD card.</p> <pre><code>$ df -h\n</code></pre>"},{"location":"hardware/jetson/boot-jetson-tx2-from-microsd/#reference","title":"Reference","text":"<ul> <li>[1] https://ttyusb0978.medium.com/nvidia-jetson-tx2-boot-menu-ad929204a70e</li> <li>[2] https://github.com/jetsonhacks/bootFromUSB/blob/main/copyRootToUSB.sh</li> <li>[3] https://elinux.org/Boot_from_sd</li> </ul>"},{"location":"hardware/jetson/flash-jetson-with-docker/","title":"Flash Jetson with SDK Manager in Docker","text":"<p>For older Jetson boards (such as TX2) that only supports Jetpack 4.x, normally you will need to have a SDK manager in a native Ubuntu 18.04 system to flash the system. Otherwise, you can try to use virtual machine (virtualbox) to flash the board. But it's not guaranteed to work. This is the case for TX2 + Orbitty carrier board I recently tried. One more method is to use the docker image provided by Nvidia. Here are the steps to do it:</p>"},{"location":"hardware/jetson/flash-jetson-with-docker/#get-docker-image","title":"Get Docker Image","text":"<ul> <li>Download the docker image from: https://developer.nvidia.com/nvidia-sdk-manager</li> <li>Load and tag the docker image:</li> </ul> <pre><code>$ docker load -i ./sdkmanager-xxx_docker.tar.gz \n$ docker tag sdkmanager:xxx sdkmanager:latest \n</code></pre> <ul> <li>Verify the image can run properly:</li> </ul> <pre><code>$ docker run -it --rm sdkmanager:latest --ver\n</code></pre>"},{"location":"hardware/jetson/flash-jetson-with-docker/#use-the-sdk-manager-in-docker","title":"Use the SDK Manager in Docker","text":"<ul> <li>Start the docker container with proper resource:</li> </ul> <pre><code>$ docker run -it --privileged \\\n    -v /dev/bus/usb:/dev/bus/usb/ \\\n    -v /dev:/dev \\\n    -v /media/$USER:/media/nvidia:slave \\\n    --name JetPack_TX2 --network host sdkmanager:latest \\\n    --cli install --logintype devzone --product Jetson --version 4.6.2 --targetos Linux --host --target JETSON_TX2_TARGETS --flash all --additionalsdk 'DeepStream 6.0.1'\n</code></pre> <p>Now you should have a TUI similar to the GUI-version of SDK manager. Choose the right target board and start installing packages and creating the OS image.</p> <p></p> <p>You may proceed with the TUI-version of SDK manager and finish the flashing process. If the SDK manager fails to flash, you can manually flash the system with the \"flash.sh\" script located at: ~/nvidia/nvidia_sdk/JetPack_4.6.2_Linux_JETSON_TX2_TARGETS/Linux_for_Tegra:</p> <pre><code># open a new terminal and attach to the running container\n$ docker exec -it &lt;container-id&gt; bash\n$ cd ~/nvidia/nvidia_sdk/JetPack_4.6.2_Linux_JETSON_TX2_TARGETS/Linux_for_Tegra\n$ sudo ./flash.sh jetson-tx2 mmcblk0p1\n</code></pre> <p>Note: The local user inside the Docker is nvidia with nvidia as the password. The home folder is /home/nvidia.</p> <p>If you're using a third-party carrier board, you may need to apply the BSP patch before flashing the system:</p> <pre><code>$ cd ~/nvidia/nvidia_sdk/JetPack_4.6.2_Linux_JETSON_TX2_TARGETS/Linux_for_Tegra\n$ wget https://connecttech.com/ftp/Drivers/CTI-L4T-TX2-32.7.2-V001.tgz\n$ tar -xzf CTI-L4T-TX2-32.7.2-V001.tgz\n$ cd CTI-L4T &amp; sudo ./install.sh\n$ sudo ./cti-flash.sh\n</code></pre>"},{"location":"hardware/jetson/flash-jetson-with-docker/#save-the-image","title":"Save the Image","text":"<p>You can save the state of the image so that you don't have to repeat the download and build process again next time when you flash the same board:</p> <pre><code>$ docker commit &lt;container-id&gt;  sdkmanager:tx2-orbbity\n</code></pre> <p>Note: it may take a long time to save the commit as the size of the image get much bigger with everything downloaded.</p>"},{"location":"hardware/jetson/flash-jetson-with-docker/#reference","title":"Reference","text":"<ul> <li>[1] https://docs.nvidia.com/sdk-manager/docker-containers/index.html</li> </ul>"},{"location":"hardware/jetson/flash-jetson-with-vm/","title":"Flash Jetson Device with Virtualbox","text":"<p>NOTE The method described here is not reliable. In my case, it worked with Xavier NX dev kit but didn't work with the TX2 + Orbitty carrier board.</p> <p>The main issue that may stop you from using an OS in virtualbox to flash a Jetson device using SDKManager is the USB setup. If the Jetson can be recognized properly in virtualbox, then the whole flashing process is basically the same with that in a native system.</p> <p>General steps to follow:</p> <ul> <li>Install Virtualbox (tested with virtualbox v6.1)</li> <li>Install additional virtualbox supporting packages</li> </ul> <pre><code>$ sudo apt install virtualbox-ext-pack virtualbox-guest-additions-iso\n</code></pre> <ul> <li>Add user in host system to \"vboxusers\" group</li> </ul> <pre><code># you can check if your user is in vboxusers group\ngroups $USER\n# if not, add to the group\n$ sudo usermod -a -G vboxusers $USER\n</code></pre> <ul> <li>Restart your computer and put the Jetson device into recovery mode. </li> </ul> <p>Now you should be able to add the Nvidia USB device to the virtualbox and flash the OS inside with SDKManager.</p>"},{"location":"hardware/jetson/jetson-robotics-resource/","title":"Jetson Robotics Resource","text":"<ul> <li>Jetson ROS2</li> <li>Nvidia Isaac ROS</li> <li>Jetson Inference</li> </ul>"},{"location":"hardware/odroid/odroid-xu4-wireguard/","title":"Install Wireguard on Odroid XU4","text":"<p>In order to install the wireguard kernel module properly, you need to make sure the linux headers are install properly first. You can find the headers package that matches your kernel with the commands:</p> <pre><code># find kernel version\n$ uname -r\n# search for linux-headers package\n$ apt search linux-headers\n</code></pre> <p>For the case that the Odroid XU4 runs Armbian Ubuntu Jammy with kernel \"5.4.253-current-odroidxu4\", you can install</p> <pre><code>$ sudo apt install linux-headers-current-odroidxu4\n</code></pre> <p>Then you can try to install wireguard</p> <pre><code>$ sudo apt install wireguard wireguard-dkms\n</code></pre> <p>If the installation is successful, you should be able to bring up the interface. </p> <p>In the case that you encounter the following error during bring up</p> <pre><code>Warning: /etc/resolv.conf is not a symbolic link to /run/resolvconf/resolv.conf\n</code></pre> <p>You can try to resolve the issue by </p> <pre><code>$ sudo dpkg-reconfigure resolvconf\n</code></pre>"},{"location":"hardware/odroid/odroid-xu4-wireguard/#reference","title":"Reference","text":"<ul> <li>[1] https://forum.armbian.com/topic/9282-installation-of-wireguard/</li> <li>[2] https://github.com/pop-os/pop/issues/773</li> </ul>"},{"location":"hardware/pcb/mosfet/","title":"MOSFET Reference","text":"<p>This note summarizes the key characteristics of MOSFET and some of its typical use cases. Some of the figures and tables are taken from tutorials listed in the <code>Reference</code> section.</p>"},{"location":"hardware/pcb/mosfet/#mosfet-types","title":"MOSFET Types","text":"<p>MOSFET is a type of device where the current flows between its drain and source terminals (\\(I_D\\)) can be controlled by the voltage between its gate and source terminals (\\(V_{GS}\\)). There are 4 types of MOSFET: N-channel, P-channel of enhanced type or depletion type for each. Their symbols are given below [1]:</p> <p></p> <p>Enhanced-type N-channel MOSFET (NMOS) is the most commonly used type. Enhanced-type P-channel MOSFET (PMOS) may also be used in certain cases. Depletion type MOSFETs are rarely used in practice.</p> <p>MOSFET is often used a switch and it operates between its cut-off region and saturation region. The state of its connectivity between drain and source is given in the following table [1].  </p> MOSFET type \\(V_{GS}\\) = +ve \\(V_{GS}\\) = 0 \\(V_{GS}\\) = -ve N-Channel  Enhancement ON OFF OFF P-Channel Enhancement OFF OFF ON N-Channel   Depletion ON ON OFF P-Channel   Depletion OFF ON ON <p>Use N-channel enhanced type MOSFET as an example, you can consider it as a voltage-controlled resistor. When \\(V_{GS}\\) is smaller than \\(ve\\), the resistence is very large and when it's bigger than \\(ve\\), the resistence becomes very small (\\(R_{dson}\\)).</p>"},{"location":"hardware/pcb/mosfet/#mosfet-as-a-switch","title":"MOSFET as a Switch","text":"<p>The following are two typical use cases of NMOS and PMOS as a switch. [3]</p> <p></p> <p>Because NMOS is turned on when \\(V_{GS}\\) is high, it's normally placed at the lower side connecting to the ground so that it doesn't require a very high voltage to turn on. For similar reasons, PMOS is usually placed at the top side conntecting to the power positive so that it's easy to turn it on by pulling the voltage at gate low.</p> <p>Another difference to note is that the current flows from source to drain in PMOS, which is opposite from the current in NMOS.</p>"},{"location":"hardware/pcb/mosfet/#practical-design","title":"Practical Design","text":"<p>A circuit that uses NMOS to trigger a relay to power a motor.</p> <p></p> <ul> <li>R1 and D2 are used to indicate ON/OFF state of the relay</li> <li>D1 is a flyback diode</li> <li>R4 is a pull-down resistor</li> <li>R3 is used to limite gate current, control switch on/off speed of the NMOS</li> <li>A zener diode can be connected between gate and source to protect the MOSFET to be damaged by high voltage (in parallel to R4)</li> <li>A diode may be added in parallel to R3 (pointing to control input) to reduce the turn-off time</li> </ul>"},{"location":"hardware/pcb/mosfet/#reference","title":"Reference","text":"<ul> <li>[1] https://www.electronics-tutorials.ws/transistor/tran_6.html</li> <li>[2] https://www.electronics-tutorials.ws/transistor/tran_7.html</li> <li>[3] https://www.youtube.com/watch?v=Uk1CPNROjNk</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-cross-chroot-docker/","title":"Cross-compile with Chroot and Docker","text":"<p>Natively compiling a medium to large project could take a long time on Raspberry Pi. In this case, setting up cross-compiling on your host computer and do the hard work on a more powerful desktop CPU could significantly reduce the build time.</p>"},{"location":"hardware/raspberrypi/raspberrypi-cross-chroot-docker/#install-tools","title":"Install Tools","text":"<p>First install the following dependencies in order to run binaries built for arm platforms on an x86_64 computer:</p> <pre><code>$ sudo apt install qemu qemu-user-static binfmt-support\n</code></pre> <p>You can read more about how this works in [3] and even more details from the QEMU project website. Briefly, the setup works as follows</p> <pre><code>arm applications\n        |\n        v\nQEMU arm emulator \n        |\n        v\n host OS (x86_64) \n        |\n        v\nhost hardware (x86_64) \n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-cross-chroot-docker/#setup-chroot-with-sd-card","title":"Setup chroot with SD Card","text":"<p>With the above tools, you can now mount the file system on your Raspberry Pi SD card to your host computer and chroot into it. </p> <p>Note here it's assumed the SD card has been setup correctly beforehand. You can flash the Raspberry Pi OS as usual to the SD card and make sure you run the initial setup on the Pi board to expand the file system to the whole SD card. Then you can remove the SD card and connect it to to your computer (with a SD to USB adapter). You need to identify the sd card drive name appeared in your computer</p> <pre><code>$ lsblk\n</code></pre> <p>Here I have a SD card with the official Raspberry Pi OS installed, and it appeared as \"/dev/sdc\"</p> <p></p> <p>There is a script from Github that you can use to easily setup the chroot \"chroot-to-pi.sh\":</p> <pre><code>$ sudo ./chroot-to-pi.sh /dev/sdc\n</code></pre> <p>I copy the content of the script here just to show what has been done by the script: it first mounts the partitions on the SD card to the host system at /mnt/raspbian and then chroot to this folder. Finally it will do the cleanup work for you after you finish the work in the chroot environment.</p> <pre><code>mkdir -p /mnt/raspbian\n\n# mount partition\nmount -o rw ${1}2  /mnt/raspbian\nmount -o rw ${1}1 /mnt/raspbian/boot\n\n# mount binds\nmount --bind /dev /mnt/raspbian/dev/\nmount --bind /sys /mnt/raspbian/sys/\nmount --bind /proc /mnt/raspbian/proc/\nmount --bind /dev/pts /mnt/raspbian/dev/pts\n\n# ld.so.preload fix\nsed -i 's/^/#CHROOT /g' /mnt/raspbian/etc/ld.so.preload\n\n# copy qemu binary\ncp /usr/bin/qemu-arm-static /mnt/raspbian/usr/bin/\n\necho \"You will be transferred to the bash shell now.\"\necho \"Issue 'exit' when you are done.\"\necho \"Issue 'su pi' if you need to work as the user pi.\"\n\n# chroot to raspbian\nchroot /mnt/raspbian /bin/bash\n\n# ----------------------------\n# Clean up\n# revert ld.so.preload fix\nsed -i 's/^#CHROOT //g' /mnt/raspbian/etc/ld.so.preload\n\n# unmount everything\numount /mnt/raspbian/{dev/pts,dev,sys,proc,boot,}\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-cross-chroot-docker/#buildrun-docker-image-for-arm-platform-on-x86-computer","title":"Build/Run Docker Image for Arm Platform on x86 Computer","text":"<p>Install the docker engine by following instructions here.</p> <p>You can check the architecture of your system using uname command. </p> <p><pre><code>uname -m\n</code></pre> On you host computer, you should get a string \"x86_64\". But if you try to run a docker image built for arm platform, you will get execution errors. </p> <p>To make this work, you need to run the following docker image, in addition to installing the above tools:</p> <pre><code>sudo docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n</code></pre> <p>You can get more details about \"qemu-user-static\" from its Github page here. Now you should be able to build or run docker image for Arm platforms. Note you will need to find a proper base image, e.g. nvcr.io/nvidia/l4t-base:r32.6.1 for a Nvidia Jetson board. Refer to [3] for a more detailed example. </p>"},{"location":"hardware/raspberrypi/raspberrypi-cross-chroot-docker/#reference","title":"Reference","text":"<ul> <li>[1] https://www.j1nx.nl/diy/crosscompiling-software-for-raspbian-in-a-chroot-environment/</li> <li>[2] https://gist.github.com/htruong/7df502fb60268eeee5bca21ef3e436eb</li> <li>[3] https://www.stereolabs.com/docs/docker/building-arm-container-on-x86/</li> <li>[4] https://github.com/multiarch/qemu-user-static</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-install-docker/","title":"Install Docker in Raspberry Pi OS","text":""},{"location":"hardware/raspberrypi/raspberrypi-install-docker/#install-docker","title":"Install Docker","text":"<pre><code>$ curl -fsSL https://get.docker.com -o get-docker.sh\n$ chmod +x ./get-docker.sh\n$ sudo sh get-docker.sh\n$ sudo systemctl to enable Docker\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-install-docker/#include-a-non-root-account-to-the-docker-group","title":"Include a Non-Root Account to the Docker Group","text":"<pre><code>$ sudo usermod -aG docker ${USER}\n$ sudo usermod -aG docker ${USER}\n</code></pre> <p>Check whether it\u2019s running:</p> <pre><code>$ groups ${USER}\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-install-docker/#install-docker-compose","title":"Install Docker-Compose","text":"<pre><code>$ sudo apt-get install libffi-dev libssl-dev\n$ sudo apt install python3-dev\n$ sudo apt-get install -y python3 python3-pip\n$ sudo pip3 install docker-compose\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-install-docker/#reference","title":"Reference","text":"<ul> <li>[1] https://jfrog.com/connect/post/install-docker-compose-on-raspberry-pi/</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-pican/","title":"PiCAN2 on Raspberry Pi 3","text":"<p>(Tested on Raspberry Pi3 with Raspbian Stretch 2017-09-07)</p>"},{"location":"hardware/raspberrypi/raspberrypi-pican/#setup-driver","title":"Setup driver","text":"<pre><code>$ sudo nano /boot/config.txt\n</code></pre> <p>Add the following lines</p> <pre><code>dtparam=spi=on\ndtoverlay=mcp2515-can0,oscillator=16000000,interrupt=25\ndtoverlay=spi-bcm2835\n</code></pre> <p>Reboot the board.</p>"},{"location":"hardware/raspberrypi/raspberrypi-pican/#bring-up-can-interface","title":"Bring up CAN interface","text":"<p>Note that the maximum bitrate is 1000000 for PiCAN2.</p> <pre><code>$ sudo ip link set can0 up type can bitrate 1000000\n</code></pre> <p>To bring up the interface when boot, you can modify \"/etc/network/interfaces\"</p> <pre><code>$ sudo nano /etc/network/interfaces\n</code></pre> <p>Add the following lines</p> <pre><code>auto can0\n     iface can0 inet manual\n     pre-up /sbin/ip link set can0 type can bitrate 1000000 \n     up /sbin/ifconfig can0 up\n     down /sbin/ifconfig can0 down\n</code></pre> <p>You can check if CAN is brought up by using command \"ifconfig\". You should see something similar to this</p> <pre><code>$ can0: flags=193&lt;UP,RUNNING,NOARP&gt;  mtu 16\n$     unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 10  (UNSPEC)\n$     RX packets 4  bytes 32 (32.0 B)\n$     RX errors 0  dropped 0  overruns 0  frame 0\n$     TX packets 4  bytes 32 (32.0 B)\n$     TX errors 1  dropped 1 overruns 0  carrier 1  collisions 0\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-pican/#loopback-test","title":"Loopback test","text":"<p>You can use the loopback mode to test if PiCAN2 is working properly. You need to enable the loopback mode first.</p> <pre><code>$ sudo ip link set can0 down\n$ sudo ip link set can0 type can loopback on\n$ sudo ip link set can0 up type can bitrate 1000000\n</code></pre> <p>Now open two terminals, one as sender and one as receiver.</p> <p>In sender terminal:</p> <pre><code>$ cansend can0 001#1122334455667788\n</code></pre> <p>In receiver terminal:</p> <pre><code>$ candump can0\n</code></pre> <p>If successful, you should expect</p> <pre><code>$ candump can0\n$ can0  001   [8]  11 22 33 44 55 66 77 88\n$ can0  001   [8]  11 22 33 44 55 66 77 88\n</code></pre> <p>Turn off the loopback mode:</p> <pre><code>$ sudo ip link set can0 down\n$ sudo ip link set can0 type can loopback off\n$ sudo ip link set can0 up type can bitrate 1000000\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-pican/#more-commands","title":"More commands","text":"<p>Use this command to find more information of CAN related commands</p> <pre><code>$ ip link set can0 up type can help\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-pican/#reference","title":"Reference","text":"<ul> <li>[1] http://copperhilltech.com/pican2-controller-area-network-can-interface-for-raspberry-pi/</li> <li>[2] https://raspberrypi.stackexchange.com/questions/51829/unable-to-bring-can-interface-up-on-raspberry-pi-3</li> <li>[3] https://www.raspberrypi.org/forums/viewtopic.php?t=141052</li> <li>[4] https://harrisonsand.com/can-on-the-raspberry-pi/</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-projects/","title":"Raspberry Pi Projects","text":"<ul> <li>https://pi-hole.net/</li> <li>https://docs.pivpn.io/</li> <li>https://rpi4cluster.com/</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-rt-kernel-usb/","title":"Fix USB Issue in Kernel 4.19.y-rt for Raspberry Pi","text":"<p>After building and replacing the Linux kernel 4.19.y-rt on Raspberry Pi 4B (8G), all the USB ports stopped working. The following shows the fix to this issue.</p>"},{"location":"hardware/raspberrypi/raspberrypi-rt-kernel-usb/#update-device-tree","title":"Update Device Tree","text":"<p>The device tree file \"/arch/arm/boot/dts/bcm2711-rpi-4-b.dts\" doesn't include the USB related snippets.</p> <pre><code>--- a/arch/arm/boot/dts/bcm2711-rpi-4-b.dts     2020-12-18 13:20:23.973176269 +0000\n+++ b/arch/arm/boot/dts/bcm2711-rpi-4-b.dts     2020-12-18 13:20:51.072542212 +0000\n@@ -2,6 +2,7 @@\n /dts-v1/;\n #include \"bcm2711.dtsi\"\n #include \"bcm2835-rpi.dtsi\"\n+#include \"bcm283x-rpi-usb-peripheral.dtsi\"\n\n #include &lt;dt-bindings/reset/raspberrypi,firmware-reset.h&gt;\n\n--- /dev/null   2020-12-15 00:20:37.047999998 +0000\n+++ a/arch/arm/boot/dts/bcm283x-rpi-usb-peripheral.dtsi 2020-12-18 13:25:45.090219029 +0000\n@@ -0,0 +1,7 @@\n+// SPDX-License-Identifier: GPL-2.0\n+&amp;usb {\n+       dr_mode = \"peripheral\";\n+       g-rx-fifo-size = &lt;256&gt;;\n+       g-np-tx-fifo-size = &lt;32&gt;;\n+       g-tx-fifo-size = &lt;256 256 512 512 512 768 768&gt;;\n+};\n</code></pre> <p>There are two changes. The first one simply add a line to include \"bcm283x-rpi-usb-peripheral.dtsi\" in the \"/arch/arm/boot/dts/bcm2711-rpi-4-b.dts\". The second one creates the included snippets which was missing in the Linux source tree.</p>"},{"location":"hardware/raspberrypi/raspberrypi-rt-kernel-usb/#change-the-firmware","title":"Change the Firmware","text":"<p>According to the discussion in [2], there seems to be some issues in the default firmware. As suggested, copy the firmware binaries from the Ubuntu distribution. Download the firmware package from here: linux-firmware-raspi2_1.20200212.orig.tar.gz.</p> <p>Extract the files and copy to \"/boot\" on the Raspberry Pi. You can backup the existing \".elf\" and \".dat\" in case you need to recover late.</p> <p>After rebooting, the USB ports should work. But do note that it's unknown wether there are any other possible issues not covered by this fix and further investigations are required.</p>"},{"location":"hardware/raspberrypi/raspberrypi-rt-kernel-usb/#reference","title":"Reference","text":"<ul> <li>[1] https://github.com/raspberrypi/linux/issues/3976</li> <li>[2] https://archlinuxarm.org/forum/viewtopic.php?f=65&amp;t=14734&amp;p=65334#p65334</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-xenomai/","title":"Xenomai on Raspberry Pi","text":""},{"location":"hardware/raspberrypi/raspberrypi-xenomai/#setup-xenomai-on-raspberry-pi-zerow","title":"Setup Xenomai on Raspberry Pi ZeroW","text":"<ul> <li>Install toolchain</li> </ul> <pre><code>$ sudo apt-get install gcc-arm-linux-gnueabihf\n$ sudo apt-get install --no-install-recommends ncurses-dev bc\n</code></pre> <ul> <li>Create a workspace folder to keep everything at one place</li> </ul> <pre><code>$ cd &lt;Your-Workspace-Directory&gt;\n$ mkdir linux_xenomai\n$ cd linux_xenomai\n</code></pre> <ul> <li>Download Linux kernel for Raspberry Pi </li> </ul> <pre><code>$ git clone https://github.com/raspberrypi/linux.git --depth 3\n</code></pre> <ul> <li>Download Xenomai source code </li> </ul> <pre><code>$ wget https://xenomai.org/downloads/xenomai/stable/xenomai-3.0.7.tar.bz2\n$ ln -s xenomai-3.0.7 xenomai\n</code></pre> <p>Extract files and modify \"xenomai/scripts/prepare-kernel.sh\": replace \"ln -sf\" with \"cp\" so that it will copy all neccessary xenomai files to linux source</p> <ul> <li>Download Xenomai kernel patch</li> </ul> <p>Download the kernel patch from https://xenomai.org/downloads/ipipe/ . For best compatibility, choose the kernel and patch with similar version number. Otherwise, you may have to fix issues by yourself.</p> <pre><code>$ wget https://xenomai.org/downloads/ipipe/v4.x/arm/ipipe-core-4.14.36-arm-1.patch\n</code></pre> <p>At the time of writing, patch for kernel 4.14.36 is the latest one for downloading. Accordingly we need to switch to a different commit of the linux kernel for RPi for least compatibility issues. Choose 4.14.37 in our case:</p> <pre><code>$ cd linux\n$ git reset --hard 29653ef5475124316b9284adb6cbfc97e9cae48f\n</code></pre> <p>You need to replace the following two files in \"linux/drivers/irqchip/\" to patch the kernel successfully:</p> <pre><code>linux/drivers/irqchip/irq-bcm2835.c\nlinux/drivers/irqchip/irq-bcm2836.c\n</code></pre> <p>Find the modified files from: https://github.com/lemariva/RT-Tools-RPi</p> <ul> <li>Patch the kernel</li> </ul> <pre><code>$ cd linux_xenomai\n$ ./xenomai/scripts/prepare-kernel.sh --linux=./linux --arch=arm --ipipe=./ipipe-core-4.14.36-arm-1.patch\n</code></pre> <p>If the patching is successful, you should get something like:</p> <pre><code>...\nI-pipe core/arm #1 installed.\nLinks installed.\nBuild system ready.\n</code></pre> <ul> <li>Configure and build patched kernel (for Raspberry Pi ZeroW)</li> </ul> <pre><code>$ cd linux\n$ make -j8 O=build ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- bcmrpi_defconfig\nmake O=build ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- -j8 menuconfig\n</code></pre> <p>Make changes according to the instructions in [1].</p> <p>Build kernel image, modules and device overlay</p> <pre><code>$ make O=build ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- -j8 bzImage modules dtbs\n$ make O=build ARCH=arm INSTALL_MOD_PATH=dist -j8 modules_install\n</code></pre> <ul> <li>Deploy the kernel</li> </ul> <p>You can either configure the new kernel manually like [2] or build the kernel/headers to be \".deb\" packages like [1].</p> <ul> <li>Compiling Xenomai tools</li> </ul> <pre><code>$ cd xenomai\n$ ./scripts/bootstrap\n$ ./configure --host=arm-linux-gnueabihf --disable-smp --with-core=cobalt\n$ make\n$ sudo make install\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-xenomai/#reference","title":"Reference:","text":"<ul> <li>[1] https://github.com/thanhtam-h/rpi01-4.1.21-xeno3/tree/master/scripts</li> <li>[2] https://lemariva.com/blog/2018/07/raspberry-pi-xenomai-patching-tutorial-for-kernel-4-14-y</li> <li>[3] https://gitlab.denx.de/Xenomai/xenomai/wikis/Setting_Up</li> </ul>"},{"location":"hardware/raspberrypi/raspberrypi-zerow-setup/","title":"Basic setup for Raspberry Pi Zero W","text":""},{"location":"hardware/raspberrypi/raspberrypi-zerow-setup/#setup-raspberry-pi-zero-w","title":"Setup Raspberry Pi Zero W","text":""},{"location":"hardware/raspberrypi/raspberrypi-zerow-setup/#ssh-via-usb-and-serial-console","title":"SSH via USB and serial console","text":"<ol> <li> <p>Download the raspbian image and flash to the SD card. Mount the SD card on the host computer. You should see two partitions \"boot\" and \"rootfs\".</p> </li> <li> <p>Edit the file \"/boot/config.txt\" and add the following line to the end of the text:</p> </li> </ol> <pre><code>dtoverlay=dwc2\n# add the following line if you also want serial console\nenable_uart=1\n</code></pre> <ol> <li>Edit the file \"/boot/cmdline.txt\", add \"modules-load=dwc2,g_ether\" after rootwait. It's a one-line text file and be careful about the format. After the change, it should look something like:</li> </ol> <pre><code>dwc_otg.lpm_enable=0 console=serial0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait modules-load=dwc2,g_ether\n</code></pre> <ol> <li>Create a new file named \"ssh\" without any suffix to enable ssh.</li> </ol> <pre><code>$ touch ssh\n</code></pre> <ol> <li>USB network configuration. Edit \"rootfs/etc/network/interfaces\" and add the following lines:</li> </ol> <pre><code>allow-hotplug usb0\niface usb0 inet static\n    address 192.168.7.2\n    netmask 255.255.255.0\n    network 192.168.7.0\n    broadcast 192.168.7.255\n</code></pre> <ol> <li>Now you can plug the SD card back to rpi0W and boot the board. If the host computer fails to get an IP address for the USB connection with rpi, you need to manually assign one:</li> </ol> <pre><code># use ifconfig to check the name of the USB connection with rpi first\n$ sudo ifconfig enp0s20f0u2 192.168.7.3 netmask 255.255.255.0\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-zerow-setup/#patch-kernel-with-xenomai-3","title":"Patch kernel with Xenomai 3","text":"<p>Before pactching Xenomai 3, ther kernel shipped with \"2018-06-27-raspbian-stretch-lite.img\" is \"4.14.50+\". Afterwards the kernel is \"4.14.37-ipipe+\".</p>"},{"location":"hardware/raspberrypi/raspberrypi-zerow-setup/#additional-commands","title":"Additional commands","text":"<pre><code># disable dhcpcd service\n$ sudo systemctl disable dhcpcd.service \n$ sudo systemctl enable wpa_supplicant.service\n</code></pre>"},{"location":"hardware/raspberrypi/raspberrypi-zerow-setup/#reference","title":"Reference:","text":"<ul> <li>https://raspberrypi.stackexchange.com/questions/66431/headless-pi-zero-ssh-access-over-usb</li> <li>https://learn.adafruit.com/turning-your-raspberry-pi-zero-into-a-usb-gadget/ethernet-gadget</li> <li>https://learn.adafruit.com/raspberry-pi-zero-creation/give-it-life</li> <li>https://www.thepolyglotdeveloper.com/2017/02/connect-raspberry-pi-pi-zero-usb-ttl-serial-cable/</li> <li>https://www.raspberrypi.org/documentation/configuration/uart.md</li> </ul>"},{"location":"hardware/rk3588/secure-boot/","title":"RK3588 Secure Boot","text":"<ul> <li>Enabling Secure Boot on RockChip SoCs</li> <li>EDK2 UEFI firmware for RK3588</li> <li>Notes for Rockchip 3588</li> </ul>"},{"location":"howtos/check-linux-disk-usage/","title":"Check Linux Disk Usage","text":"<p>You may have encountered the situation that your Linux system is running out of space. This happens more often on embedded devices running on a small eMMC or SD card. To cleanup the system, you first need to find out what is taking up the space. </p> <ul> <li>Check partitions</li> </ul> <pre><code>$ df -h\n</code></pre> <p>With this command you will know which partition is full.</p> <ul> <li>Check file/folder within a partition</li> </ul> <pre><code>$ sudo apt-get install ncdu\n$ sudo ncdu -x &lt;the-folder-you-want-to-check&gt;\n</code></pre> <p>With this command you will know which file/folder is taking up the space.</p>"},{"location":"howtos/check-linux-disk-usage/#reference","title":"Reference","text":"<ul> <li>[1] https://askubuntu.com/questions/266825/what-do-i-do-when-my-root-filesystem-is-full</li> </ul>"},{"location":"howtos/cleanup-git-branch/","title":"Cleanup Git Branch","text":"<p>You may have many local or remote git branches that are no longer needed. </p> <pre><code>git branch -d $(git branch --merged=main | grep -v main)\ngit fetch --prune\n</code></pre> <ul> <li>The first command deletes all local branches that have been merged into the main branch, except for the main branch itself. </li> <li>The second command cleans up remote-tracking branches that no longer exist on the remote repository.</li> </ul>"},{"location":"howtos/cleanup-git-branch/#reference","title":"Reference","text":"<ul> <li>https://medium.com/@FlorentDestrema/a-simple-way-to-clean-up-your-git-project-branches-283b87478fbc</li> </ul>"},{"location":"howtos/create-ssh-key/","title":"Create SSH Key","text":"<p>Create key pair using different algorithms</p> <pre><code>$ ssh-keygen -t rsa -b 4096\n$ ssh-keygen -t dsa\n$ ssh-keygen -t ecdsa -b 521\n$ ssh-keygen -t ed25519\n</code></pre> <p>Specify a file name while creating the key pair</p> <pre><code>$ ssh-keygen -f ~/.ssh/rdu_github -t rsa -b 4096\n</code></pre> <p>Typically you want the permissions to be:</p> <ul> <li>.ssh directory: 700 (drwx------)</li> <li>public key (.pub file): 644 (-rw-r--r--)</li> <li>private key (id_rsa): 600 (-rw-------)</li> </ul> <p>To access Github repositories with a SSH key, you may add the following config to ~/.ssh/config</p> <pre><code>Host github.com\n  HostName github.com\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/&lt;your-ssh-key-file-name&gt;\n  IdentitiesOnly=yes\n</code></pre>"},{"location":"howtos/create-ssh-key/#reference","title":"Reference","text":"<ul> <li>[1] https://www.ssh.com/ssh/keygen/</li> <li>[2] https://superuser.com/questions/215504/permissions-on-private-key-in-ssh-folder</li> </ul>"},{"location":"howtos/edit-grub-menu/","title":"Edit Grub Menu","text":"<p>Ubuntu uses Grub2 as its bootloader. If you have installed multiple operating systems on your computer, you may need to modify the boot order or remove certain boot entries.</p> <p>There are two files you may need to modify:</p> <ul> <li><code>/etc/default/grub</code>: contains the default settings and configurations for GRUB</li> <li><code>/boot/grub/grub.cfg</code>: is the actual GRUB configuration file that the GRUB bootloader reads at boot time</li> </ul> <p>If you modify <code>/etc/default/grub</code>, you need to run </p> <pre><code>$ sudo update-grub\n</code></pre> <p>to update the changes to <code>/boot/grub/grub.cfg</code>.  </p> <p>Typically, you may update <code>/etc/default/grub</code> to change:</p> <ul> <li>whether to show the boot menu (GRUB_DISABLE_OS_PROBER)</li> <li>timeout of the boot menu (GRUB_TIMEOUT)</li> </ul> <p>You may need to update <code>/boot/grub/grub.cfg</code> if you want to change the boot menu entries. The following shows an example of the menu entry and submenu:</p> <pre><code>menuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os ...\n        recordfail\n        load_video\n        ...\n}\nsubmenu 'Advanced options for Ubuntu' $menuentry_id_option ... {\n        menuentry 'Ubuntu, with Linux 6.5.0-35-generic' --class ubuntu ...\n                recordfail\n                load_video\n                ...\n        }\n</code></pre> <p>Typically you may comment out or change the order of the menus and submenus.</p>"},{"location":"howtos/edit-grub-menu/#reference","title":"Reference","text":"<ul> <li>https://www.ubuntubuzz.com/2022/06/how-to-edit-ubuntu-bootloader-menu-made-simple.html</li> </ul>"},{"location":"howtos/fix-aws-lightsail-browser-ssh/","title":"Fix Lightsail SSH","text":"<p>When updating the Ubuntu system, I accidentally changed the SSH settings and the broswer SSH won't allow me to login. The error message was something like: </p> <pre><code>Log in failed. If this instance has just started up, try again in a minute or two.\n\nCLIENT_UNAUTHORIZED [769]\n</code></pre> <p>In order to fix this issue, you can ssh into the system using the SSH key and then add the following two lines to the SSH config file at \"/etc/ssh/sshd_config\"</p> <pre><code>TrustedUserCAKeys /etc/ssh/lightsail_instance_ca.pub\nCASignatureAlgorithms +ssh-rsa\n</code></pre> <p>Restart the instance and the browser-based SSH should work again.</p>"},{"location":"howtos/fix-librt-not-found-in-jammy/","title":"Fix librt.so issue on Ubuntu 22.04","text":"<p>On a freshly installed Ubuntu 22.04, you may get compile error complaining that librt.so cannot be found. You can fix the issue by creating a symbolic link to the librt.so:</p> <pre><code>$ sudo ln -s /lib/x86_64-linux-gnu/librt.so.1 /usr/lib/x86_64-linux-gnu/librt.so\n</code></pre>"},{"location":"howtos/fix-rpi-locale-issue/","title":"Fix Raspberry Pi Locale Issue","text":"<p>To get rid of the locale warning on raspberry pi:</p> <pre><code>$ sudo sed -i \"s/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/g\" -i /etc/locale.gen\n$ sudo locale-gen en_US.UTF-8\n$ sudo update-locale en_US.UTF-8\n\n$ export LANGUAGE=en_US.UTF-8\n$ export LANG=en_US.UTF-8\n$ export LC_ALL=en_US.UTF-8\n</code></pre>"},{"location":"howtos/fix-rpi-locale-issue/#reference","title":"Reference","text":"<ul> <li>[1] https://gist.github.com/tkhduracell/f54734c18ef1a2fd99e9</li> </ul>"},{"location":"howtos/github-multi-account-ssh-config/","title":"GitHub Multi-Account SSH Configuration","text":"<p>If you have multiple Github accounts and want to use all of them on one computer, you would need to change the ssh config so that the git client will know which ssh key to use to access each of the account.</p> <pre><code>Host &lt;1st-name&gt;.github.com\n  HostName github.com\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/&lt;your-1st-ssh-key-file-name&gt;\n  IdentitiesOnly=yes\n\nHost &lt;2nd-name&gt;.github.com\n  HostName github.com\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/&lt;your-2nd-ssh-key-file-name&gt;\n  IdentitiesOnly=yes\n</code></pre> <p>Note in the above configuration:</p> <ul> <li>Host: you can give any name to differentiate the accounts</li> <li>IdentitiesOnly: you must set to yes. This argument specifies that ssh should only use the authentication identity files configured in the ssh_config files, not to use the default id_rsa key or the ones from the ssh-agent. </li> </ul>"},{"location":"howtos/github-multi-account-ssh-config/#reference","title":"Reference","text":"<ul> <li>[1] https://www.youtube.com/watch?v=6lA0oPoFCAE</li> </ul>"},{"location":"howtos/install-ubuntu22.04-on-pc-with-nv-5080/","title":"Install Ubuntu 22.04 on PC with Nvidia 50-series Graphic Card","text":"<p>Since Nvidia 50-series graphics cards are quite new and they require at least nvidia version 570 driver to work properly, the default Ubuntu 22.04.5 installation image (the newest version at the time of writing) won't work. It only gives you a black screen after the \"Try or Install Ubuntu\" step, making it impossible to continue with the installation. Before the next point release that bundles a newer nvidia driver comes out, an easy solution that you can use at the moment is to create a customized installation image.</p> <ul> <li>Download Ubuntu 22.04.5 iso image</li> <li>Install the Cubic Custom Ubuntu ISO Creator</li> </ul> <pre><code>sudo apt-add-repository universe\nsudo apt-add-repository ppa:cubic-wizard/release\nsudo apt update\nsudo apt install --no-install-recommends cubic\n</code></pre> <ul> <li>Start the customization process (you can refer to [2] for more detailed instructions) and install nvidia driver (refer to [3])</li> </ul> <pre><code>sudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\n\nsudo apt install nvidia-driver-570-server-open\n</code></pre> <ul> <li>After all the Cubic customization steps are finished, you will get a new iso image that you can use to install Ubuntu on your computer </li> </ul>"},{"location":"howtos/install-ubuntu22.04-on-pc-with-nv-5080/#reference","title":"Reference","text":"<ul> <li>[1] https://github.com/PJ-Singh-001/Cubic</li> <li>[2] https://www.makeuseof.com/create-custom-ubuntu-iso-cubic/</li> <li>[3] https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa</li> </ul>"},{"location":"howtos/nvidia-driver-with-secure-boot/","title":"NVIDIA Driver Installation with Secure Boot","text":"<p>When installing NVIDIA drivers on a system with Secure Boot enabled, you may encounter issues due to the kernel module not being signed. This guide will walk you through the steps to properly install NVIDIA drivers while ensuring compatibility with Secure Boot.</p> <p>It's assumed that the secure boot is already enabled in the BIOS settings. And you can boot into the Ubuntu system but the NVIDIA graphics driver is not working properly (nvidia-smi doesn't show any NVIDIA devices).</p>"},{"location":"howtos/nvidia-driver-with-secure-boot/#install-nvidia-driver","title":"Install NVIDIA Driver","text":"<p>Since driver version 515+, NVIDIA open-sourced their kernel module. This is generally preferable as it allows for easier integration with the Linux kernel and better support for Secure Boot.</p> <ol> <li> <p>Add the NVIDIA PPA (Personal Package Archive) to your system: <pre><code>sudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\n</code></pre></p> </li> <li> <p>Install the NVIDIA driver: <pre><code># open-source driver\nsudo apt install nvidia-driver-570-open\n\n# if you prefer the proprietary driver, use:\nsudo apt install nvidia-driver-570\n</code></pre></p> </li> <li> <p>Reboot your system: <pre><code>sudo reboot\n</code></pre></p> </li> <li> <p>After rebooting, check if the NVIDIA driver is working: <pre><code>nvidia-smi\n</code></pre></p> </li> </ol> <p>The installation process should automatically handle the signing of the kernel module for Secure Boot. But from my experience, the signing process may fail sometimes. If you encounter issues, you may need to manually sign the kernel module.</p>"},{"location":"howtos/nvidia-driver-with-secure-boot/#manually-sign-the-kernel-module","title":"Manually Sign the Kernel Module","text":"<pre><code>sudo mokutil --import /var/lib/shim-signed/mok/MOK.der\n</code></pre> <p>You will be prompted to create a password. This password will be used later in the MOK (Machine Owner Key) management during the next reboot.</p> <p>Sign the NVIDIA kernel module:</p> <pre><code>sudo /usr/src/linux-headers-$(uname -r)/scripts/sign-file sha256 \\\n  /var/lib/shim-signed/mok/MOK.priv \\\n  /var/lib/shim-signed/mok/MOK.der \\\n  $(modinfo -n nvidia)\n</code></pre> <p>Reboot your system again and follow the prompts to enroll the MOK key you created earlier. You will need to enter the password you set during the <code>mokutil</code> step.</p> <ul> <li>Select Enroll MOK</li> <li>Choose Continue</li> <li>Enter the password you set above</li> <li>Finish and reboot</li> </ul> <p>After rebooting, check if the NVIDIA driver is working:</p>"},{"location":"howtos/nvidia-driver-with-secure-boot/#reference","title":"Reference","text":"<ul> <li>NVIDIA Driver PPA</li> </ul>"},{"location":"howtos/pair-bt-device-from-terminal/","title":"Pair Bluetooth Device from a Terminal","text":"<p>Pairing and connecting to a bluetooth device from a terminal is useful when you are working with a single-board computer and you don't have a monitor connected to it.</p>"},{"location":"howtos/pair-bt-device-from-terminal/#start-the-bluetooth-control-utility","title":"Start the Bluetooth control utility","text":"<p>Install bluetooth tools if you haven't:</p> <pre><code>$ sudo apt -y install bluetooth bluez bluez-tools\n</code></pre> <p>Start the control utility:</p> <pre><code>$ bluetoothctl\n</code></pre> <p>You should get into the bluetoothctl prompt mode:</p> <pre><code>rdu@rpi4:~ $ bluetoothctl \nAgent registered\n</code></pre>"},{"location":"howtos/pair-bt-device-from-terminal/#commands-with-the-bluetoothctl-prompt","title":"Commands with the bluetoothctl prompt","text":"<ul> <li>Turn on Bluetooth</li> </ul> <pre><code>power on\n</code></pre> <ul> <li>Enable agent</li> </ul> <pre><code>agent on\n</code></pre> <ul> <li>Scan for nearby devices</li> </ul> <pre><code>scan on\n</code></pre> <p>Wait for the device you want to pair with to appear in the list. Once it appears, note down its MAC address.</p> <ul> <li>Pair with the device</li> </ul> <pre><code>pair &lt;MAC_ADDRESS&gt;\n</code></pre> <ul> <li>Connect to the device</li> </ul> <pre><code>connect &lt;MAC_ADDRESS&gt;\n</code></pre> <ul> <li>Exit the Bluetooth control utility (or simply use Ctrl + D)</li> </ul> <pre><code>exit\n</code></pre> <p>Note you can also use the above command from the normal terminal prompt in the form: <code>bluetoothctl + [command]</code>, such as </p> <pre><code>$ bluetoothctl power on\n</code></pre>"},{"location":"howtos/pair-bt-device-from-terminal/#reference","title":"Reference","text":"<ul> <li>[1] https://www.geeksforgeeks.org/connecting-to-bluetooth-devices-via-cli/</li> <li>[2] https://www.baeldung.com/linux/bluetooth-via-terminal</li> </ul>"},{"location":"howtos/recover-stm32-swd/","title":"Recover STM32 SWD","text":"<p>It's possible to disable the SWD pins by accident and the SWD interface will become unavailable after a successful flashing. This happened to me a few times when I used STM32CubeMX to generate driver code and forgot to enable the \"Serial Wire\" debug interface in the \"System Core/SYS\" section. The following solution is provided by Andre Belanger for solving the Apollo 2 EVB and it should also work for other similar MCUs. (Tested with STM32F405RG)</p> <p>The following is a summary of the solution (modified from Andre's answer):</p> <ol> <li>Power-down the board completely to get all registers reset</li> <li>Hold the nRST pin low to prevent code from executing</li> <li>Power-up the board while continuing to hold nRST low</li> <li>Use Segger J-link commander console (JLinkExe) to connect to the MCU (should connect even though nRST is asserted, but cannot program/erase while nRST is asserted)</li> <li>Type a long list of \u201chalt\u201d commands into a text editor, copy them into clipboard, then paste into the J-Link command window.  The halt commands that try to execute while nRST is held low will fail, and will execute quickly, so you need to paste a long list of halt commands (~ 100)</li> <li>Immediately release nRST while the halt commands are being processed (note that even 100 halt commands will execute in ~ 1 second so small but manageable window in which to release nRST)</li> <li>Debugger should reports that halt was successful, at which point the \"erase\" command can be used to remove the problem firmware</li> <li>If the halt commands fail, then the full procedure should be repeated starting from step #1 (simply asserting reset will not be sufficient for many issues, need to start from power-down).</li> </ol> <p>Sample halt commands, make sure you have enough of them to get you enough time</p> <pre><code>halt\nhalt\nhalt\nhalt\nhalt\nhalt\nhalt\nhalt\nhalt\nhalt\nhalt\nhalt\n</code></pre>"},{"location":"howtos/recover-stm32-swd/#reference","title":"Reference","text":"<ul> <li>[1] https://support.ambiqmicro.com/hc/en-us/community/posts/360030663231-What-to-do-if-firmware-disables-SWD-pins-Help-</li> </ul>"},{"location":"howtos/restore-ubuntu-kernel/","title":"Restore Ubuntu Kernel","text":"<p>If you accidentally removed or corrupted your Ubuntu kernel, you won't be able to boot into your system. This note documents the steps to restore the Ubuntu kernel.</p> <ul> <li>Boot from a Live USB</li> <li>Mount your root partition and chroot into it</li> <li>Reinstall the kernel</li> </ul>"},{"location":"howtos/restore-ubuntu-kernel/#recovery-steps","title":"Recovery Steps","text":"<p>First boot from a Live USB of Ubuntu. Then open a terminal and mount your root partition. If you have multiple Ubuntu installations, make sure to mount the correct one. You can identify your OS by checking the <code>/etc/os-release</code> file after mounting the partition.</p> <pre><code>cat /etc/os-release\n</code></pre> <p>Once confirmed, mount the root partition and bind the necessary filesystems, then chroot into it:</p> <ul> <li>Mount the root partition (replace <code>/dev/sdXY</code> with your actual root partition)</li> </ul> <pre><code>sudo mount /dev/sdXY /mnt\n</code></pre> <ul> <li>Prepare resolv.conf for resolving DNS inside the chroot environment</li> </ul> <pre><code>sudo cp /etc/resolv.conf /mnt/etc/resolv.conf\n</code></pre> <ul> <li>Bind necessary filesystems and chroot into the mounted partition</li> </ul> <pre><code>sudo mount --bind /dev /mnt/dev\nsudo mount --bind /proc /mnt/proc\nsudo mount --bind /sys /mnt/sys\nsudo chroot /mnt\n</code></pre> <pre><code># inside the chroot environment, update the package list and reinstall the kernel\napt update\napt install --reinstall linux-image-$(uname -r)\n\n# e.g. for ubuntu 22.04 in Oct 2025, you may install\napt install linux-image-6.8.0-85-generic\n\n# exit the chroot environment\nexit\n</code></pre> <ul> <li>Unmount the partitions and reboot</li> </ul> <pre><code>sudo umount /mnt/dev\nsudo umount /mnt/proc\nsudo umount /mnt/sys\nsudo umount /mnt\nsudo reboot\n</code></pre> <p>Now you should be able to boot into your Ubuntu system with the restored kernel. You may update/fix any other packages as needed.</p>"},{"location":"howtos/restore-ubuntu-kernel/#reference","title":"Reference","text":"<ul> <li>https://askubuntu.com/questions/28099/how-to-restore-a-system-after-accidentally-removing-all-kernels</li> </ul>"},{"location":"howtos/ubuntu2404-appimage-sandbox/","title":"Ubuntu 24.04 AppImage Sandbox","text":"<p>On Ubuntu 24.04, you may encounter the following error when running an AppImage:</p> <pre><code>$ ./Obsidian-1.8.7.AppImage \n[15810:0302/204155.842217:FATAL:setuid_sandbox_host.cc(163)] The SUID sandbox helper binary was found, but is not configured correctly. Rather than run without sandboxing I'm aborting now. You need to make sure that /tmp/.mount_ObsidinaDjMJ/chrome-sandbox is owned by root and has mode 4755.\nTrace/breakpoint trap (core dumped)\n</code></pre> <p>You can create a profile for the AppImage to allow it to run without sandboxing by creating a file at <code>/etc/apparmor.d/obsidian.appimage</code> with the following content:</p> <pre><code># This profile allows everything and only exists to give the\n# application a name instead of having the label \"unconfined\"\n\nabi &lt;abi/4.0&gt;,\ninclude &lt;tunables/global&gt;\n\nprofile obsidian.appimage /path/to/Obsidian-1.6.7.AppImage flags=(default_allow) {\n  userns,\n\n  # Site-specific additions and overrides. See local/README for details.\n  include if exists &lt;local/obsidian.appimage&gt;\n}\n</code></pre> <p>Lastly, restart the apparmor service:</p> <pre><code>sudo systemctl restart apparmor.service\n</code></pre>"},{"location":"howtos/ubuntu2404-appimage-sandbox/#references","title":"References","text":"<ul> <li>https://askubuntu.com/questions/1512287/obsidian-appimage-the-suid-sandbox-helper-binary-was-found-but-is-not-configu</li> <li>https://ubuntu.com/blog/ubuntu-23-10-restricted-unprivileged-user-namespaces</li> </ul>"},{"location":"howtos/xbox-controller-ubuntu-bluetooth/","title":"Connect Xbox One Controller to Ubuntu via Bluetooth","text":"<p>If the required driver module doesn't load automatically, the xbox one controller won't connect to Ubuntu reliably. In this case, you can load the module manually</p> <pre><code>$ sudo modprobe xpad\n</code></pre> <p>Then the controller should pair and get connected after you turn it on (pressing the xbox logo button), hold the bluetooth pairing button (the one beside the USB type-C port) until the logo light flashes fast. </p>"},{"location":"howtos/xbox-controller-ubuntu-bluetooth/#reference","title":"Reference","text":"<ul> <li>[1] https://www.reddit.com/r/linuxquestions/comments/cvtfbq/getting_my_wired_xbox_one_controllers_to_work_on/</li> </ul>"},{"location":"ml/llm/","title":"Large Language Model","text":""},{"location":"ml/llm/#open-source-projects","title":"Open-source Projects","text":"<ul> <li>https://homebrew.ltd/</li> <li>https://github.com/OpenBMB</li> <li>https://github.com/ggerganov/llama.cpp</li> </ul>"},{"location":"ml/segmentation/","title":"Segmentation","text":"<ul> <li>https://github.com/facebookresearch/sam2</li> <li>https://github.com/xushilin1/RAP-SAM</li> </ul>"},{"location":"programming/library/","title":"Library","text":""},{"location":"programming/library/#online-tools","title":"Online Tools","text":"<ul> <li>Online reStructuredText Editor - http://rst.ninjs.org/</li> <li>Online General Markdown Editor - https://stackedit.io/editor</li> <li>Online Kramdown Markdown Editor - http://kramdown.herokuapp.com/</li> <li>Online Drawing &amp; Figures - https://www.draw.io/</li> <li>Online Hex Converter - https://www.scadacore.com/tools/programming-calculators/online-hex-converter/</li> <li>Online Rotation Converter - https://www.andre-gaschler.com/rotationconverter/</li> <li>Online Logo Generator - https://www.freelogodesign.org/</li> </ul>"},{"location":"programming/library/#free-image-library","title":"Free Image Library","text":"<ul> <li>OpenclipArt - https://openclipart.org/</li> <li>Unsplash - https://unsplash.com/</li> </ul>"},{"location":"programming/library/#frameworkslibraries","title":"Frameworks/Libraries","text":"<p>Robotics</p> <ul> <li> <p>Robot Operating System (ROS) - ROS1, ROS2 \"ROS is a set of software libraries and tools that help you build robot applications.\"</p> </li> <li> <p>Dronecode Software Platform - https://www.dronecode.org  \"Dronecode encompasses open source projects that control flight, enable mission planning, and otherwise make drone flight and advanced functionality possible.\"</p> </li> <li> <p>The Open Motion Planning Library (OMPL) - http://ompl.kavrakilab.org/ \"OMPL, the Open Motion Planning Library, consists of many state-of-the-art sampling-based motion planning algorithms.\"</p> </li> <li> <p>Drake - https://drake.mit.edu/ \"A planning, control and analysis toolbox for nonlinear dynamical systems\"</p> </li> <li> <p>Control Toolbox - https://bitbucket.org/adrlab/ct/wiki/Home \"An open-source C++ library for efficient modelling, control, estimation, trajectory optimization and model predictive control.\"</p> </li> <li> <p>CARLA - http://carla.org/     \"Open-source simulator for autonomous driving research.\"</p> </li> <li> <p>SUMO - https://www.dlr.de/ts/en/desktopdefault.aspx/tabid-9883/16931_read-41000/     \"SUMO allows modelling of intermodal traffic systems including road vehicles, public transport and pedestrians.\"</p> </li> <li> <p>Additional robotics libraries: https://github.com/jslee02/awesome-robotics-libraries</p> </li> <li> <p>NtripCaster - https://github.com/baidu/ntripcaster</p> </li> </ul> <p>Communication</p> <ul> <li> <p>Lightweight Communications and Marshalling (LCM) - https://lcm-proj.github.io/ \"LCM is a set of libraries and tools for message passing and data marshalling, targeted at real-time systems where high-bandwidth and low latency are critical.\"</p> </li> <li> <p>FastRTPS - https://github.com/eProsima/Fast-RTPS \"eprosima Fast RTPS is a C++ implementation of the RTPS (Real Time Publish Subscribe) protocol, which provides publisher-subscriber communications over unreliable transports such as UDP, as defined and maintained by the Object Management Group (OMG) consortium\"</p> </li> </ul> <p>Scientific Computing</p> <ul> <li> <p>Eigen - http://eigen.tuxfamily.org/index.php?title=Main_Page \"Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms.\"</p> </li> <li> <p>GSL - GNU Scientific Library - http://www.gnu.org/software/gsl/ \"The GNU Scientific Library (GSL) is a numerical library for C and C++ programmers. It is free software under the GNU General Public License. The library provides a wide range of mathematical routines such as random number generators, special functions and least-squares fitting. There are over 1000 functions in total with an extensive test suite.\"</p> </li> <li> <p>CGAL - The Computational Geometry Algorithms Library - https://www.cgal.org/ \"CGAL is a software project that provides easy access to efficient and reliable geometric algorithms in the form of a C++ library.\"</p> </li> <li> <p>GNU Octave - https://www.gnu.org/software/octave/ \"GNU Octave is a high-level interpreted language, primarily intended for numerical computations. The Octave language is quite similar to Matlab so that most programs are easily portable.\"</p> </li> <li> <p>Matplotlib - https://matplotlib.org/ \"Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\"</p> </li> <li> <p>TBB - https://www.threadingbuildingblocks.org/ \"Threading Building Blocks (TBB) lets you easily write parallel C++ programs that take full advantage of multicore performance, that are portable and composable, and that have future-proof scalability.\"</p> </li> <li> <p>OpenMP - https://www.openmp.org/ \"The OpenMP API specification for parallel programming\"</p> </li> <li> <p>Heat Method for Distance Computation - http://www.cs.cmu.edu/~kmcrane/Projects/HeatMethod/index.html \"The heat method for solving the single- or multiple-source shortest path problem on both flat and curved domains.\"</p> </li> </ul> <p>Graphics</p> <ul> <li>Dear ImGui - https://github.com/ocornut/imgui \"Bloat-free Immediate Mode Graphical User interface for C++ with minimal dependencies\"</li> </ul> <p>Computer Vision</p> <ul> <li> <p>OpenCV - https://opencv.org/ \"OpenCV is an open source computer vision and machine learning software library.\"</p> </li> <li> <p>ViSP - http://visp.inria.fr/ \"ViSP standing for Visual Servoing Platform is a modular cross platform library that allows prototyping and developing applications using visual tracking and visual servoing technics at the heart of the researches done by Inria Lagadic team.\"</p> </li> </ul> <p>Operating Systems</p> <ul> <li> <p>PREEMPT_RT - https://wiki.linuxfoundation.org/realtime/start Patch to improve the realtime performance of Linux kernel</p> </li> <li> <p>Xenomai - https://xenomai.org/     \"Xenomai is about making various real-time operating system APIs available to Linux-based platforms. When the target Linux kernel cannot meet the requirements with respect to response time constraints, Xenomai can also supplement it for delivering stringent real-time guarantees.\"</p> </li> </ul> <p>Debugging</p> <ul> <li> <p>Valgrind - http://valgrind.org  \"Valgrind is an instrumentation framework for building dynamic analysis tools. There are Valgrind tools that can automatically detect many memory management and threading bugs, and profile your programs in detail. You can also use Valgrind to build new tools.\"</p> </li> <li> <p>Spdlog - https://github.com/gabime/spdlog \"Very fast, header only, C++ logging library.\"</p> </li> </ul>"},{"location":"programming/cpp/compiler/","title":"C/C++ Compiler","text":""},{"location":"programming/cpp/compiler/#gcc","title":"GCC","text":"<ul> <li>-fPIC flag</li> <li>Static vs. Dynamic Libraries</li> </ul>"},{"location":"programming/cpp/cpp_doc/","title":"Reference Documentation","text":"<ul> <li>C++ FAQ</li> <li>Asio Tutorial</li> <li>P2P Between Computers behind NAT</li> <li>Guide to Implementing Communication Protocols in C++ (for Embedded Systems)</li> <li>RedHat Developer Guide</li> <li>Oracle Linker and Libraries Guide </li> </ul>"},{"location":"programming/cpp/cpp_language/","title":"C++ Language","text":"<p>Language basics</p> <ul> <li>C++ Type Casting</li> </ul> <p>Practical use cases</p> <ul> <li>Convert C++ Function Pointer to C Function Pointer</li> </ul>"},{"location":"programming/cpp/cpp_library/","title":"Library","text":"<p>Process Management</p> <ul> <li>tiny process library</li> </ul> <p>Parallel Computing</p> <ul> <li>OpenACC: https://www.openacc.org/get-started</li> <li>Verifying Multi-threaded Software with Spin</li> </ul> <p>Video Streaming</p> <ul> <li>stun: A C++ STUN server and client to detect NAT mapping and external IP</li> <li>libnice: a library that implements the Interactive Connectivity Establishment (ICE) standard</li> <li>WebRTC</li> <li>Google WebRTC</li> <li>Open WebRTC Toolkit</li> <li>WebRTC streamer for Raspberry PI</li> <li>UV4L</li> </ul> <p>Communication</p> <ul> <li>libmodbuspp</li> </ul>"},{"location":"programming/cpp/cpp_tool/","title":"C++ Resource","text":""},{"location":"programming/cpp/cpp_tool/#debugging","title":"Debugging","text":"<ul> <li>GDB Notes</li> <li>Valgrind Notes</li> <li>RR</li> <li>LTTng</li> </ul>"},{"location":"programming/cpp/compiler/fpic_flag/","title":"-fPIC Flag","text":"<p>Info</p> <p>This note was written with the assistance of ChatGPT.</p> <p>There are different types of symbols in an object file, and their relocatability depends on their nature and usage within the code. Not every symbol inside an object file (.o) is relocatable. </p> <p>The following are the main categories:</p> <ul> <li> <p>Local Symbols: These are symbols that are only used within the object file. They are typically relocatable because their final addresses are not determined until the linker combines the object files into an executable or a shared library.</p> </li> <li> <p>Global Symbols: These symbols are meant to be visible to other object files. They can be either defined within the object file or undefined (to be resolved by other object files or libraries). The relocatability of these symbols depends on whether they are defined or undefined:</p> </li> <li> <p>Defined Global Symbols: These symbols are relocatable in the sense that their addresses can change when the final executable or shared library is created. Undefined Global Symbols: These symbols are resolved during the linking process. The linker will replace them with the actual addresses from other object files or libraries. Absolute Symbols: These symbols have fixed addresses and are not relocatable. Their values are absolute and will not change during the linking process.</p> </li> <li> <p>Section Symbols: These symbols refer to the beginning of sections within the object file (like .text, .data, .bss). They are relocatable in the sense that the entire section might be moved, but the relative offsets within the section remain fixed.</p> </li> <li> <p>Debug Symbols: These are used for debugging purposes and may not be directly involved in relocation. However, they might still reference relocatable addresses.</p> </li> </ul> <p>When compiling a static library with GCC, the -fPIC (Position Independent Code) flag affects how the code is generated. Here is a detailed explanation of the differences and implications:</p> <p>With -fPIC Flag:</p> <ul> <li>Position Independent Code: The -fPIC flag tells the compiler to generate position-independent code, which means the generated machine code does not depend on being located at a specific memory address.</li> <li>Shared Libraries: PIC is primarily used for creating shared libraries (dynamic libraries) since these libraries are loaded into different memory locations in different processes. Position-independent code can be relocated without modification. Performance: Generating position-independent code typically involves using an additional register to hold the address of the global offset table (GOT). This can introduce a slight performance overhead due to additional indirections.</li> <li>Usage: While it is not strictly necessary to use -fPIC for static libraries, doing so allows the same object files to be used to create both static and shared libraries without recompilation.</li> </ul> <p>Without -fPIC Flag:</p> <ul> <li>Position Dependent Code: Without the -fPIC flag, the compiler generates position-dependent code. This means the generated code expects to be loaded at a specific address in memory. Static Libraries: Position-dependent code is generally acceptable for static libraries because these libraries are linked directly into the executable, and the linker can resolve addresses at link time.</li> <li>Performance: Position-dependent code can be slightly more efficient than position-independent code since it does not require the extra indirections needed for position independence. Flexibility: Object files compiled without -fPIC cannot be used to create shared libraries without recompilation, limiting their flexibility.</li> </ul> <p>Key Differences:</p> <ul> <li>Relocability: Code compiled with -fPIC can be relocated at runtime, making it suitable for shared libraries, whereas code without -fPIC is fixed at link time.</li> <li>Performance: Position-independent code may have a slight performance penalty due to additional indirections.</li> <li>Flexibility: Using -fPIC makes the compiled object files more flexible, allowing them to be used in both static and shared libraries.</li> </ul> <p>Summary:</p> <ul> <li>Use -fPIC: When you intend to create shared libraries or want the flexibility of using the same object files for both static and shared libraries.</li> <li>Do Not Use -fPIC: When you are certain that the object files will only be used to create static libraries and you want to avoid the slight performance overhead.</li> </ul> <p>In practice, if you are working on a project that might require shared libraries in the future, it is generally a good idea to compile with -fPIC to keep your options open.</p>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/","title":"Static vs. Dynamic Libraries","text":"<p>Info</p> <p>This note was written with the assistance of ChatGPT.</p> <p>In C++, libraries are crucial for sharing code and functionalities across different programs. There are two main types of libraries: static and dynamic. Understanding the differences between them, how they manage symbols, and their respective advantages and disadvantages is essential for efficient C++ programming.</p>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#static-libraries","title":"Static Libraries","text":""},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#definition","title":"Definition","text":"<p>A static library is a collection of object files that are linked into the program during the build process. The linker combines the static library with the program's object files to create a single executable.</p>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#characteristics","title":"Characteristics","text":"<ul> <li>File Extension: Typically .a on Unix/Linux and .lib on Windows.</li> <li>Linking Time: Linked at compile-time.</li> <li>Symbol Resolution: Symbols are resolved during the linking stage, and the required code from the static library is copied into the executable.</li> <li>Portability: Resulting executable is self-contained, with no dependencies on external library files at runtime.</li> <li>Memory Usage: Can lead to larger executables since the library code is included in every executable that uses it.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#advantages","title":"Advantages","text":"<ul> <li>Performance: Slightly faster at runtime because all symbols are resolved during linking.</li> <li>Deployment: Easier deployment since there are no external dependencies.</li> <li>Stability: Less prone to issues caused by library version changes.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#disadvantages","title":"Disadvantages","text":"<ul> <li>Size: Larger executable size due to included library code.</li> <li>Update Complexity: Updating a library requires recompiling the entire application.</li> <li>Dynamic Libraries</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#symbol-visibility","title":"Symbol Visibility","text":"<p>In static libraries, all symbols from the object files are included in the library. The linker uses these symbols when creating an executable. By default, all non-static functions and global variables are visible and can be linked by other object files or libraries.</p> <ul> <li>Static Functions and Variables: Functions and variables declared with the static keyword are local to the translation unit (source file) and are not visible outside it.</li> <li>Anonymous Namespaces: In C++, an anonymous namespace can be used to achieve similar encapsulation for variables and functions.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#symbol-management","title":"Symbol Management","text":"<p>In static libraries, symbols are resolved during the linking stage. When a program depends on a static library, the linker copies the necessary symbols (functions, variables) from the library into the executable. This process includes:</p> <ul> <li>Symbol Table: The linker reads the symbol table of the library to identify required symbols. Copying Symbols: Only the used symbols are copied into the final executable, making it self-contained.</li> <li>Resolution: All external references to these symbols are resolved during the linking process, ensuring no unresolved symbols remain.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#dynamic-libraries","title":"Dynamic Libraries","text":""},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#definition_1","title":"Definition","text":"<p>A dynamic library (also known as shared library) is not included in the executable at compile-time. Instead, it is loaded at runtime by the operating system.</p>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#characteristics_1","title":"Characteristics","text":"<ul> <li>File Extension: Typically .so on Unix/Linux and .dll on Windows.</li> <li>Linking Time: Linked at runtime.</li> <li>Symbol Resolution: Symbols are resolved when the program loads the library.</li> <li>Portability: Requires the presence of the library file at runtime.</li> <li>Memory Usage: Multiple programs can share a single copy of the dynamic library, reducing overall memory usage.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#advantages_1","title":"Advantages","text":"<ul> <li>Size: Smaller executable size since the library code is not included.</li> <li>Flexibility: Easier to update as the library can be replaced without recompiling the executable.</li> <li>Memory Efficiency: Shared among multiple programs, saving memory.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#disadvantages_1","title":"Disadvantages","text":"<ul> <li>Performance: Slight overhead due to symbol resolution at runtime.</li> <li>Dependency Management: Requires careful management of library versions and dependencies.</li> <li>Stability: Potential issues with library version compatibility (DLL Hell).</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#symbol-visibility_1","title":"Symbol Visibility","text":"<p>Dynamic libraries have more sophisticated mechanisms to control symbol visibility. By default, all non-static symbols are visible, but this can be controlled using visibility attributes and export maps.</p> <ul> <li>Default Visibility: Functions and variables without any specific visibility attributes are visible to the dynamic linker.</li> <li>Hidden Visibility: Using compiler-specific attributes to hide symbols.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#symbol-management_1","title":"Symbol Management","text":"<p>In dynamic libraries, symbols are resolved at runtime. The process includes:</p> <ul> <li>Symbol Table: The dynamic linker/loader uses the symbol table in the dynamic library to resolve symbols when the program starts or when a library is explicitly loaded.</li> <li>Dynamic Linking: The operating system loads the dynamic library into memory and links the symbols dynamically.</li> <li>Lazy Binding: In some systems, symbols are resolved on the first use rather than at load time, optimizing startup time.</li> </ul>"},{"location":"programming/cpp/compiler/static_vs_dyanmic_libs/#dependency-between-libraries","title":"Dependency between Libraries","text":"<ul> <li>Static Library Depends on Static Library</li> </ul> <p>If a static library libA depends on another static library libB, the symbols from libB are not copied over to libA. Instead, when you build an executable that depends on libA, you will still need to link against both libA and libB.</p> <ul> <li>Dynamic Library Depends on Dynamic Library</li> </ul> <p>When a dynamic library libX depends on another dynamic library libY, libX will contain references to the symbols in libY, but the actual symbol resolution is deferred until runtime. You will need to ensure that both libX.so and libY.so are available at runtime.</p> <ul> <li>Dynamic Library Depends on Static Library</li> </ul> <p>If a dynamic library libX depends on a static library libY, the symbols from libY are included in libX during its creation. Therefore, you do not need libY when linking your executable against libX, as libX already contains all necessary symbols.</p> <ul> <li>Static Library Depends on Dynamic Library</li> </ul> <p>Static libraries cannot directly depend on dynamic libraries because static libraries are archives of object files that are linked at compile time, while dynamic libraries are linked at runtime. If you need to use symbols from a dynamic library in a static library, the executable or another dynamic library that includes the static library must also link against the dynamic library.</p> <p>The above 4 cases can be summarized as:</p> <ul> <li>Static Library A depends on Static Library B: You need both libA.a and libB.a at link time to create the executable.</li> <li>Dynamic Library X depends on Dynamic Library Y: You need libY.so at runtime to resolve the dependencies of libX.so.</li> <li>Dynamic Library X depends on Static Library Y: The symbols from libY.a are included in libX.so, so you only need libX.so at runtime.</li> <li>Static Library A depends on Dynamic Library Y: When linking an executable or another dynamic library that uses libA.a, you need libY.so to resolve symbols used by libA.a.</li> </ul>"},{"location":"programming/cpp/language/cpp_func_ptr_to_c_func_ptr/","title":"Convert C++ Function Pointer to C Function Pointer","text":"<p>Sometimes, you may want to pass a C++ member function as the callback function to a C library API function. Likely people will tell you it's only possible if the member function is static. But here is one possible solution  </p> <pre><code>template &lt;typename T&gt;\nstruct Callback;\n\ntemplate &lt;typename Ret, typename... Params&gt;\nstruct Callback&lt;Ret(Params...)&gt; {\n    template &lt;typename... Args&gt;\n    static Ret callback(Args... args) { return func(args...); }\n    static std::function&lt;Ret(Params...)&gt; func;\n};\n\n// Initialize the static member.\ntemplate &lt;typename Ret, typename... Params&gt;\nstd::function&lt;Ret(Params...)&gt; Callback&lt;Ret(Params...)&gt;::func;\n\n//////////////////////////////////////////////\n\nstruct Foo {\n    void print(int* x) { // Some member function.\n        std::cout &lt;&lt; *x &lt;&lt; std::endl;\n    }\n};\n\nint main() {\n    Foo foo; // Create instance of Foo.\n\n    // Store member function and the instance using std::bind.\n    Callback&lt;void(int*)&gt;::func = std::bind(&amp;Foo::print, foo, std::placeholders::_1);\n\n    // Convert callback-function to c-pointer.\n    void (*c_func)(int*) = static_cast&lt;decltype(c_func)&gt;(Callback&lt;void(int*)&gt;::callback);\n\n    // Use in any way you wish.\n    std::unique_ptr&lt;int&gt; iptr{new int(5)};\n    c_func(iptr.get());\n}\n</code></pre>"},{"location":"programming/cpp/language/cpp_func_ptr_to_c_func_ptr/#reference","title":"Reference","text":"<ul> <li>https://stackoverflow.com/a/19809787/2200873</li> </ul>"},{"location":"programming/cpp/language/type_casting/","title":"Type Casting","text":"<p>Info</p> <p>This note was written with the assistance of ChatGPT.</p> <p>In C++, <code>static_cast</code>, <code>dynamic_cast</code>, <code>reinterpret_cast</code> and <code>const_cast</code> serve different purposes for type conversion.</p>"},{"location":"programming/cpp/language/type_casting/#cast-types","title":"Cast Types","text":""},{"location":"programming/cpp/language/type_casting/#static_cast","title":"static_cast","text":"<p><code>static_cast</code> is used for conversions between types where the compiler can check the validity of the conversion at compile time. It is used for standard conversions of numeric types, such as converting an <code>int</code> to a <code>float</code>, and for converting between pointer types when there is a clear inheritance relationship.</p> <p>Use cases:</p> <ul> <li>Converting numerical types (e.g., <code>int</code> to <code>double</code>)</li> <li>Converting enums to integers or vice versa</li> <li>Upcasting: converting a derived class pointer or reference to a base class pointer or reference</li> <li>Note: downcasting can also be performed with static_cast, which avoids the cost of the runtime check, but it's only safe if the program can guarantee (through some other logic) that the object pointed to by expression is definitely derived</li> </ul> <p>Example:</p> <pre><code>int i = 10;\ndouble d = static_cast&lt;double&gt;(i);  // Convert int to double\n\nclass Base {};\nclass Derived : public Base {};\nDerived* derived = new Derived();\nBase* base = static_cast&lt;Base*&gt;(derived);  // Upcasting\n</code></pre>"},{"location":"programming/cpp/language/type_casting/#dynamic_cast","title":"dynamic_cast","text":"<p><code>dynamic_cast</code> is used for safe downcasting in class hierarchies, i.e., converting a base class pointer or reference to a derived class pointer or reference. It checks the type at runtime and returns <code>nullptr</code> (for pointers) or throws <code>std::bad_cast</code> (for references) if the conversion is not possible.</p> <p>Use cases:</p> <ul> <li>Downcasting in class hierarchies with polymorphic types (i.e., classes with virtual functions)</li> <li>Checking type at runtime in a class hierarchy</li> <li>Note: dynamic_cast may be used for upcasting, but unnecessary</li> </ul> <p>Example:</p> <pre><code>Base* base = new Derived();\nDerived* derived = dynamic_cast&lt;Derived*&gt;(base);  // Downcasting\n\nif (derived) {\n    // Successfully downcasted\n}\n</code></pre>"},{"location":"programming/cpp/language/type_casting/#reinterpret_cast","title":"reinterpret_cast","text":"<p><code>reinterpret_cast</code> is used for low-level casts that yield implementation-dependent results. It converts any pointer type to any other pointer type, even if the types are unrelated, without any runtime type check.</p> <p>Use cases:</p> <ul> <li>Converting pointers to and from integer types for low-level manipulation</li> <li>Treating a block of memory as an array of a different type</li> <li>Function pointer type conversions</li> </ul> <p>Example:</p> <pre><code>long p = 12345678;\nchar* cp = reinterpret_cast&lt;char*&gt;(&amp;p);  // Treat the long int as an array of chars\n\nvoid (*funcPtr)(int);\nvoid* ptr = reinterpret_cast&lt;void*&gt;(funcPtr);  // Convert function pointer to void pointer\n</code></pre>"},{"location":"programming/cpp/language/type_casting/#const_cast","title":"const_cast","text":"<p><code>const_cast</code> is used to add or remove the const qualifier from a variable, allowing for temporary changes in constness.</p> <p>Use Cases:</p> <ul> <li>Modifying a previously declared const variable</li> <li>Passing const objects to functions that require non-const parameters</li> </ul> <p>Example:</p> <pre><code>const int x = 10;\nint&amp; nonConstRef = const_cast&lt;int&amp;&gt;(x);\n</code></pre> <p>Each of these casts serves a specific purpose, and choosing the right one depends on the context and the level of safety and type checking required. <code>static_cast</code> is the safest and most commonly used for general type conversions. <code>dynamic_cast</code> is more specialized for safe downcasting in polymorphic class hierarchies. <code>reinterpret_cast</code> is the least safe and should be used sparingly, as it essentially allows treating any pointer as any other type of pointer.</p>"},{"location":"programming/cpp/language/type_casting/#dynamic-casting-safety","title":"Dynamic Casting Safety","text":"<p><code>dynamic_cast</code> can fail under certain conditions, typically when it's used for downcasting or sidecasting in class hierarchies. Here are the situations where <code>dynamic_cast</code> will not succeed:</p> <ol> <li> <p>Type is not polymorphic: If the type you're casting from does not have at least one virtual function, then <code>dynamic_cast</code> cannot be used. It relies on runtime type information (RTTI) to check the object's type at runtime, which is available only for polymorphic types.</p> </li> <li> <p>Invalid downcast or sidecast: <code>dynamic_cast</code> will fail if you attempt to cast to a type that is not the actual type of the object or a derived type thereof. For example, if you try to downcast a base class pointer to a derived class pointer, but the actual object is not of that derived class, the cast will fail.</p> </li> <li> <p>Casting away constness improperly: While <code>dynamic_cast</code> can be used to cast between types within an inheritance hierarchy, it cannot change the constness of the object being cast. If you need to cast away constness, <code>const_cast</code> must be used in conjunction.</p> </li> <li> <p>Cross-casting in multiple inheritance incorrectly: In cases of multiple inheritance, if you attempt to cast from one base class to another where neither is a base of the other (sidecasting), and the object is not actually an instance of the target class, <code>dynamic_cast</code> will fail.</p> </li> </ol> <p>Example</p> <ul> <li> <p>Polymorphic Base Required: <pre><code>class Base { /* no virtual functions */ };\nclass Derived : public Base { };\n\nBase* base = new Derived();\nDerived* derived = dynamic_cast&lt;Derived*&gt;(base);  // Fails, Base is not polymorphic\n</code></pre></p> </li> <li> <p>Invalid Downcast: <pre><code>class Base { virtual void func() {} };\nclass Derived1 : public Base { };\nclass Derived2 : public Base { };\n\nBase* base = new Derived1();\nDerived2* derived = dynamic_cast&lt;Derived2*&gt;(base);  // Fails, base is not a Derived2\n</code></pre></p> </li> <li> <p>Improper Constness Casting: <pre><code>const Base* base = new Derived();\nDerived* derived = dynamic_cast&lt;Derived*&gt;(base);  // Fails, const to non-const\n</code></pre></p> </li> </ul> <p>To ensure <code>dynamic_cast</code> succeeds, you must cast between compatible types within a polymorphic class hierarchy and adhere to the constness rules. When <code>dynamic_cast</code> fails during pointer casting, it returns <code>nullptr</code>, and when it fails during reference casting, it throws a <code>std::bad_cast</code> exception.</p>"},{"location":"programming/debugging/gdb/","title":"Using GDB Debugger","text":""},{"location":"programming/debugging/gdb/#introduction","title":"Introduction","text":"<p>GDB debugger can be a very powerful tool for finding the cause of unexpected behaviors of your program. In a GDB debugging session, you can step your code by line or by instruction and you can also stop your code at a specific line, a function or an address. When your program stops, you can check the values of the variables at that moment. You can even change a variable as you want. Moreover, it allows you to check the status of the stack and inspect how the function are called. The use of GDB may seem not to be as easy as printf() but it can be much more helpful when you're trying to find a deeply hidden bug. Actually it's not as difficut to learn as it seems to be.</p> <p>Here are a few good tutorials to get started:</p> <ul> <li>GDB Tutorial: A Walkthrough with Examples</li> <li>Using GNU's GDB Debugger</li> <li>Guide to Faster, Less Frustrating Debugging</li> <li>RMS's GDB Debugger Tutorial</li> <li>Debugging with GDB</li> </ul> <p>The official manual of GDB can be a good reference after you have already learned the basics and want to check more details of a feature:</p> <ul> <li>GDB Online Manual</li> </ul> <p>The following are my notes for quick reference of the most frequently used commands. Some of them are from the above materials.</p>"},{"location":"programming/debugging/gdb/#background-knowledge","title":"Background Knowledge","text":"<p>It can be very helpful to understand stack and stack frames when you use GDB for debugging. This page from the tutorial \"Using GNU's GDB Debugger\" gives good explanation about them.</p> <p>Briefly speaking, stack is a section of the memory and whenever there is a function call, a stack frame is created in the stack. This stack frame is used to store all related information about this call including the all the automatic variables of the newly called function, the return address and the arguments of the called function. In GDB, you can check how the functions are called from each other by inspecting the stack frames. By switching to a stack frame, you get access to variables in that scope, meaning you can check the values of local variables in the corresponding function. You cannot print or modify a variable if that variable doesn't exit in the current stack frame.</p> <p>In addition to stack and stack frames, check topic \"operating system\" for more information about virtual memory and memory layout.</p> <p>Another thing that you need to remember before starting a gdb debugging session is that you need to use \"-g\" flag when compiling your code to include debugging information in the generated executable file.</p>"},{"location":"programming/debugging/gdb/#frequently-used-commands","title":"Frequently Used Commands","text":"<ul> <li>Starting a debugging session</li> </ul> <pre><code>$ gdb &lt;name-of-executable&gt;\n(gdb) run arg1 arg2\n</code></pre> <p>Arg1 and arg2 will be remembered and used when you run again. If you want to reset or clear the arguments, use:</p> <pre><code>(gdb) set args &lt;arg1/arg2/.../or none to clear saved args&gt;\n</code></pre> <p>If your program is already running, you can still use gdb to debug it.</p> <pre><code>$ gdb &lt;name-of-executable&gt; &lt;process-id&gt;\n</code></pre> <p>Or you can use the attach command:</p> <pre><code>$ gdb\n(gdb) attach &lt;process-id&gt;\n</code></pre> <ul> <li>Using breakpoints and watchpoints</li> </ul> <pre><code>(gdb) break &lt;function-name&gt; # set break point by function name\n(gdb) break &lt;line-number&gt;\n(gdb) break &lt;file-name:line-number&gt;\n(gdb) break &lt;virtual-memory-address&gt;\n(gdb) break &lt;place-to-break&gt; if &lt;condition&gt;\n(gdb) info breakpoints  # list all all breakpoints and watchpoints\n(gdb) disable n     # n is the breakpoint/watchpoint identifier number from listed info\n(gdb) enable n\n(gdb) clear &lt;function-name&gt;/&lt;line-number&gt;/&lt;file-name:line-number&gt;/&lt;virtual-memory-address&gt;\n(gdb) delete &lt;breakpoint-identifier&gt;\n(gdb) delete        # delete all breakpoints\n(gdb) continue      # continue execution from breakpoint\n</code></pre> <ul> <li>Manipulating variables</li> </ul> <pre><code>(gdb) ptype &lt;var-name&gt;  # print data type\n(gdb) print &lt;var-name&gt;  # print data value\n(gdb) print /FMT &lt;var-name&gt; # o:octal,x:hex,d:decimal,u:unsigned decimal,t:binary,  f:float,a:address,c:char\n(gdb) set &lt;var-name&gt; = &lt;new-value&gt;\n(gdb) print &lt;var-name&gt; = &lt;new-value&gt;\n(gdb) display &lt;var-name&gt;/&lt;expression&gt;   # automatically display specified var once program is stopped\n(gdb) info display          # print the list of auto-display items\n(gdb) enable/disable &lt;display-item-num&gt; # enable or disable the display a var/exp\n(gdb) undisplay             # delete the item from display list\n</code></pre> <ul> <li>Stepping and resuming program</li> </ul> <pre><code>(gdb) step          # step by line\n(gdb) istep         # step by instruction\n(gdb) next          # continue to next line in current stack frame (including function)\n(gdb) continue\n(gdb) where         # show current line number\n(gdb) list &lt;none&gt;/&lt;line-num&gt;/&lt;range&gt;/&lt;function-name&gt;/&lt;*address&gt;\n</code></pre> <ul> <li>Checking stack and stack frames</li> </ul> <pre><code>(gdb) backtrace     # display the current stack status\n(gdb) frame         # show current stack frame\n(gdb) frame &lt;frame-num&gt; # switch to frame &lt;frame-num&gt;\n</code></pre>"},{"location":"programming/debugging/valgrind/","title":"Using Valgrind","text":"<p>Valgrind is a powerful toolset that can help to debug programs especially for memory-related issues.</p> <p>A few references:</p> <ul> <li>Valgrind Official Site</li> <li>Kcachegrind Project Site</li> <li>How to profile C++ application with Callgrind / KCacheGrind</li> </ul>"},{"location":"programming/debugging/valgrind/#frequently-used-commands","title":"Frequently Used Commands","text":"<ul> <li>Install the tool</li> </ul> <pre><code># valgrind \n$ sudo apt-get install valgrind\n# useful tools that can be used together with valgrind \n$ sudo apt-get install kcachegrind graphviz\n</code></pre> <ul> <li>Memory error check</li> </ul> <pre><code># quick check\n$ valgrind &lt;name-of-executable&gt;\n# full memory leak check\n$ valgrind --leak-check=full &lt;name-of-executable&gt;\n</code></pre> <ul> <li>Program profiling</li> </ul> <pre><code># profile program and get an output file like callgrind.out.xxxxxx\n$ valgrind --tool=callgrind &lt;name-of-executable&gt;\n# then you can load the file with Kcachegrind\n$ kcachegrind &lt;name-of-profiling-output-file&gt;\n</code></pre>"},{"location":"programming/gpu/cuda/","title":"Cuda","text":"<ul> <li>https://github.com/srush/GPU-Puzzles</li> </ul>"},{"location":"programming/graphics/resource/","title":"Resource","text":"<ul> <li>https://github.com/blend2d/blend2d</li> <li>https://www.cairographics.org/</li> </ul>"},{"location":"programming/opengl/resource/","title":"Reference","text":"<ul> <li>https://github.com/stevenlovegrove/Pangolin</li> </ul>"},{"location":"programming/python/python_resource/","title":"Python Resource","text":""},{"location":"programming/video_analytics/deepstream_concepts/","title":"DeepStream Concepts","text":"<p>DeepStream is NVIDIA's streaming analytics toolkit built on GStreamer. It provides a pipeline-based architecture for real-time video processing, computer vision, and AI inference. Understanding the core concepts of buffers, pads, and metadata flow is essential for effective DeepStream development.</p>"},{"location":"programming/video_analytics/deepstream_concepts/#pipeline-architecture","title":"Pipeline Architecture","text":""},{"location":"programming/video_analytics/deepstream_concepts/#pipeline-as-a-directed-graph","title":"Pipeline as a Directed Graph","text":"<p>DeepStream pipelines are implemented as directed graphs where:</p> <ul> <li>Elements are nodes that perform specific operations (decoding, inference, tracking, etc.)</li> <li>Pads are connection points between elements (source pads output data, sink pads receive data)</li> <li>Buffers carry data and metadata through the pipeline</li> </ul> <p>A typical DeepStream pipeline follows this pattern:</p> <pre><code>CameraSrc \u2192 Decoder \u2192 StreamMux \u2192 Inference \u2192 Tracker \u2192 OSD \u2192 Encoder/Sink\n</code></pre> <p>Each element consumes buffers from upstream elements and produces downstream buffers for downstream elements. In practice, buffers are often reused from a buffer pool, not always \u201cnew\u201d. Elements may modify the same GstBuffer in place, especially with GPU NVMM memory. Important nuance: the metadata is continuously accumulated on the same buffer object, not re-created fresh each time.</p>"},{"location":"programming/video_analytics/deepstream_concepts/#gstbuffer-structure","title":"GstBuffer Structure","text":"<p>A <code>GstBuffer</code> is the fundamental data container in GStreamer/DeepStream:</p> <ul> <li>Payload: The actual video frame data (typically stored in GPU memory for DeepStream)</li> <li>Metadata: Timestamps, format information (caps), and custom user data</li> <li>DeepStream Metadata: <code>NvDsBatchMeta</code> structures containing detection results, tracking information, and other analytics data</li> </ul> <p>The buffer acts as a carrier that maintains both the raw video data and all associated metadata as it flows through the pipeline.</p>"},{"location":"programming/video_analytics/deepstream_concepts/#pad-negotiation","title":"Pad Negotiation","text":"<p>Elements connect through pads, which must negotiate compatible data formats:</p> <ul> <li>Caps negotiation: Pads exchange capability information to determine compatible formats</li> <li>Format matching: Downstream elements must accept the format produced by upstream elements</li> <li>Example: <code>nvvideoconvert</code> might output <code>video/x-raw(memory:NVMM), format=NV12</code>; downstream elements must support this format</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#pad-probes","title":"Pad Probes","text":"<p>Pad probes provide a mechanism to intercept and inspect data at specific points in the pipeline:</p> <ul> <li>Installation: Probes are attached to specific pads (typically source pads)</li> <li>Callback execution: Every buffer passing through triggers the probe callback</li> <li>Capabilities:</li> <li>Inspect: Read metadata, timestamps, detection results</li> <li>Modify: Attach new metadata or modify buffer properties</li> <li>Control: Drop buffers or block data flow</li> </ul> <p>Pad probes are particularly useful for accessing inference results, as <code>nvinfer</code> elements attach detection metadata to buffers. But note that pad probes can also be installed for events or queries (not just buffers).</p>"},{"location":"programming/video_analytics/deepstream_concepts/#data-flow-and-element-interaction","title":"Data Flow and Element Interaction","text":""},{"location":"programming/video_analytics/deepstream_concepts/#buffer-processing-flow","title":"Buffer Processing Flow","text":"<p>The pipeline processes data through the following sequence:</p> <ol> <li>Buffer Creation: Upstream elements produce buffers containing video data</li> <li>Buffer Transmission: Data flows through source pads to sink pads of downstream elements</li> <li>Buffer Processing: Downstream elements transform or annotate the buffer content</li> <li>Metadata Accumulation: DeepStream elements attach metadata to the same buffer as it flows</li> <li>Buffer Reuse: The same buffer object is continuously reused, accumulating metadata from multiple elements</li> </ol> <p>Note that it is not literally the same buffer pointer for all frames. Each frame has its own buffer, but within that frame\u2019s life, the same buffer travels the whole pipeline, carrying more metadata as it goes. The pool recycles buffer objects across frames once released.</p>"},{"location":"programming/video_analytics/deepstream_concepts/#metadata-attachment-points","title":"Metadata Attachment Points","text":"<p>DeepStream elements add metadata at specific stages:</p> <ul> <li><code>nvstreammux</code>: Creates batch structure and adds <code>NvDsBatchMeta</code></li> <li><code>nvinfer</code>: Adds <code>NvDsObjectMeta</code> containing detection results to frame metadata</li> <li><code>nvtracker</code>: Adds object tracking IDs to existing object metadata</li> <li><code>nvdsosd</code>: Reads metadata for overlay rendering but preserves the original data</li> </ul> <p>All metadata remains attached to the same buffer object throughout the pipeline.</p>"},{"location":"programming/video_analytics/deepstream_concepts/#buffer-structure-visualization","title":"Buffer Structure Visualization","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GstBuffer                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Payload: Pixels (GPU/CPU mem)   \u2502 \u2190 Video frame data\n\u2502 Timestamp (PTS)                 \u2502 \u2190 Timing information\n\u2502 NvDsBatchMeta                   \u2502 \u2190 DeepStream metadata\n\u2502   \u2514\u2500 FrameMeta                  \u2502   \u2514\u2500 Per-stream information\n\u2502       \u2514\u2500 ObjectMeta             \u2502       \u2514\u2500 Detection/tracking data\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Each element can examine and add to the metadata \"clipboard\" attached to the buffer.</p>"},{"location":"programming/video_analytics/deepstream_concepts/#data-access-methods","title":"Data Access Methods","text":""},{"location":"programming/video_analytics/deepstream_concepts/#appsink-vs-pad-probe","title":"Appsink vs Pad Probe","text":"<p>Appsink: - Dedicated pipeline termination element - Pulls complete buffers (pixels + metadata) into application code - Suitable for CPU-based processing and final output</p> <p>Pad Probe: - Mid-pipeline interception mechanism - Non-destructive inspection of buffers - Ideal for metadata extraction and debugging</p>"},{"location":"programming/video_analytics/deepstream_concepts/#synchronization-considerations","title":"Synchronization Considerations","text":"<p>Since metadata is attached in-band to buffers, the most reliable approach for synchronized access is:</p> <ul> <li>Intercept the same buffer using either probes or appsink</li> <li>Access pixels and metadata together from the same buffer object</li> <li>Avoid splitting data flow, which would require manual synchronization</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#example-pipeline-walkthrough","title":"Example Pipeline Walkthrough","text":""},{"location":"programming/video_analytics/deepstream_concepts/#pipeline-structure","title":"Pipeline Structure","text":"<pre><code>CameraSrc \u2192 Decoder \u2192 StreamMux \u2192 Inference \u2192 Tracker \u2192 OSD \u2192 Convert \u2192 Appsink\n</code></pre>"},{"location":"programming/video_analytics/deepstream_concepts/#stage-by-stage-buffer-evolution","title":"Stage-by-Stage Buffer Evolution","text":""},{"location":"programming/video_analytics/deepstream_concepts/#1-camera-decoder","title":"1. Camera \u2192 Decoder","text":"<p>Input: Compressed video stream Output: Raw video frames</p> <pre><code>Buffer State:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pixels: Raw YUV (NV12, GPU)     \u2502\n\u2502 PTS: 1668338300000 ns           \u2502\n\u2502 Metadata: (empty)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Camera source creates initial buffer</li> <li>Decoder converts compressed frames to raw GPU surfaces</li> <li>No DeepStream-specific metadata yet</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#2-nvstreammux","title":"2. nvstreammux","text":"<p>Input: Multiple video streams Output: Batched frames</p> <pre><code>Buffer State:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pixels: Batch of N frames       \u2502\n\u2502 PTS: Per-frame timestamps       \u2502\n\u2502 NvDsBatchMeta                   \u2502\n\u2502   \u2514\u2500 FrameMeta (per stream)     \u2502\n\u2502       \u2022 source_id               \u2502\n\u2502       \u2022 width, height           \u2502\n\u2502       \u2022 buf_pts                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Combines multiple input streams into batches</li> <li>Adds <code>NvDsBatchMeta</code> structure for DeepStream processing</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#3-nvinfer-detection","title":"3. nvinfer (Detection)","text":"<p>Input: Batched frames Output: Frames with detection metadata</p> <pre><code>Buffer State:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pixels: Unchanged (GPU)         \u2502\n\u2502 NvDsBatchMeta                   \u2502\n\u2502   \u2514\u2500 FrameMeta                  \u2502\n\u2502       \u2514\u2500 ObjectMeta             \u2502\n\u2502           \u2022 class_id            \u2502\n\u2502           \u2022 bbox {x, y, w, h}   \u2502\n\u2502           \u2022 confidence          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Runs AI model inference on GPU</li> <li>Attaches detection results as <code>NvDsObjectMeta</code></li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#4-nvtracker","title":"4. nvtracker","text":"<p>Input: Frames with detections Output: Frames with tracking IDs</p> <pre><code>Buffer State:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pixels: Unchanged               \u2502\n\u2502 NvDsBatchMeta                   \u2502\n\u2502   \u2514\u2500 FrameMeta                  \u2502\n\u2502       \u2514\u2500 ObjectMeta             \u2502\n\u2502           \u2022 object_id (new)     \u2502\n\u2502           \u2022 class_id            \u2502\n\u2502           \u2022 bbox                \u2502\n\u2502           \u2022 confidence          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Associates tracking IDs with detected objects</li> <li>Enriches existing object metadata</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#5-nvdsosd-overlay","title":"5. nvdsosd (Overlay)","text":"<p>Input: Frames with tracking data Output: Frames with visual overlays</p> <pre><code>Buffer State:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pixels: + overlay graphics      \u2502\n\u2502 NvDsBatchMeta: Intact           \u2502\n\u2502   \u2514\u2500 FrameMeta                  \u2502\n\u2502       \u2514\u2500 ObjectMeta (unchanged) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Renders bounding boxes and labels</li> <li>Preserves all metadata</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#6-nvvideoconvert-appsink","title":"6. nvvideoconvert \u2192 Appsink","text":"<p>Input: GPU frames with overlays Output: CPU frames ready for application</p> <pre><code>Buffer State:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pixels: BGR (CPU memory)        \u2502\n\u2502 NvDsBatchMeta: Complete         \u2502\n\u2502   \u2514\u2500 All metadata preserved     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Converts from GPU to CPU memory</li> <li>Applications can access both pixels and metadata</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#probe-placement-strategy","title":"Probe Placement Strategy","text":"<pre><code>Camera \u2192 Decoder \u2192 StreamMux \u2192 Infer \u2192 Tracker \u2192 OSD \u2192 Convert \u2192 Appsink\n           \u2191         \u2191         \u2191       \u2191        \u2191\n        (probe)   (probe)   (probe)  (probe)  (probe)\n</code></pre> <p>Probe Locations: - After Decoder: Raw video data available - After StreamMux: Batch structure and frame metadata - After Infer: Detection results available - After Tracker: Complete object tracking data - After OSD: Final processed frames with overlays</p>"},{"location":"programming/video_analytics/deepstream_concepts/#key-implementation-considerations","title":"Key Implementation Considerations","text":"<ol> <li>Probe Selection: Choose probe location based on required metadata</li> <li>CPU Conversion: Only convert to CPU when necessary for application processing</li> <li>Synchronization: Always access pixels and metadata from the same buffer</li> <li>Memory Management: GPU memory is more efficient for pipeline processing</li> </ol>"},{"location":"programming/video_analytics/deepstream_concepts/#best-practices","title":"Best Practices","text":""},{"location":"programming/video_analytics/deepstream_concepts/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Minimize CPU-GPU transfers: Keep data in GPU memory as long as possible</li> <li>Batch processing: Use <code>nvstreammux</code> to process multiple streams efficiently</li> <li>Memory pools: Leverage GStreamer's buffer pool system for consistent performance</li> <li>Probe efficiency: Keep probe callbacks lightweight to avoid pipeline stalls</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#debugging-and-monitoring","title":"Debugging and Monitoring","text":"<ul> <li>Probe placement: Use probes strategically to inspect data at different pipeline stages</li> <li>Metadata inspection: Access <code>NvDsBatchMeta</code> to verify detection and tracking results</li> <li>Buffer analysis: Check buffer caps and timestamps for synchronization issues</li> <li>Pipeline state: Monitor element states and error messages for troubleshooting</li> </ul>"},{"location":"programming/video_analytics/deepstream_concepts/#common-pitfalls","title":"Common Pitfalls","text":"<ul> <li>Metadata loss: Avoid splitting data flow between separate branches</li> <li>Memory leaks: Properly release buffers and metadata when using appsink</li> <li>Synchronization errors: Always access pixels and metadata from the same buffer</li> <li>Format mismatches: Ensure proper caps negotiation between elements</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/","title":"DeepStream Service Maker API","text":"<p>DeepStream Service Maker (SM) is a higher-level C++ interface over GStreamer/DeepStream. It reduces boilerplate for building pipelines and gives clean hook points to read pixels + metadata\u2014while keeping the underlying DeepStream semantics (buffers, batching, <code>NvDs*</code> metadata) intact.</p>"},{"location":"programming/video_analytics/deepstream_servicemaker/#pipeline-construction","title":"Pipeline Construction","text":""},{"location":"programming/video_analytics/deepstream_servicemaker/#basic-pipeline-api-minimal-example","title":"Basic Pipeline API (minimal example)","text":"<pre><code>#include \"pipeline.hpp\"\n#include &lt;iostream&gt;\n\nusing namespace deepstream;\n\n#define CONFIG_FILE_PATH \"/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_infer_primary.yml\"\n\nint main(int argc, char* argv[]) {\n  try {\n    // argv[1] = \"file:///.../sample_720p.h264\"\n    Pipeline pipeline(\"sample-pipeline\");\n    pipeline\n      .add(\"nvurisrcbin\",   \"src\",  \"uri\", argv[1])\n      .add(\"nvstreammux\",   \"mux\",  \"batch-size\", 1, \"width\", 1280, \"height\", 720)\n      .add(\"nvinferbin\",    \"infer\",\"config-file-path\", CONFIG_FILE_PATH)\n      .add(\"nvosdbin\",      \"osd\")\n      .add(\"nveglglessink\", \"sink\");\n\n    // Link src\u2192mux; request pad only on mux (sink_%u)\n    pipeline.link({\"src\",\"mux\"}, {\"\", \"sink_%u\"})\n            .link(\"mux\",\"infer\",\"osd\",\"sink\");\n\n    pipeline.start().wait();\n  } catch (const std::exception&amp; e) {\n    std::cerr &lt;&lt; \"Error: \" &lt;&lt; e.what() &lt;&lt; \"\\n\";\n    return -1;\n  }\n  return 0;\n}\n</code></pre> <p>Notes</p> <ul> <li>Namespace and headers follow SM conventions: <code>using namespace deepstream;</code> and <code>\"pipeline.hpp\"</code>.</li> <li>OSD element in SM\u2019s factory naming is <code>nvosdbin</code> (the underlying plugin is <code>nvdsosd</code>).</li> <li>Prefer the YAML <code>config_infer_primary.yml</code> for <code>nvinferbin</code>.</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/#data-inspection-in-path","title":"Data Inspection (in-path)","text":"<p>SM exposes Buffer Probes for lightweight work on the hot path. Prefer metadata probes for speed and safety.</p>"},{"location":"programming/video_analytics/deepstream_servicemaker/#probe-interfaces-c","title":"Probe interfaces (C++)","text":"<ul> <li><code>BufferProbe::IBatchMetadataObserver</code> \u2013 read-only batch metadata</li> <li><code>BufferProbe::IBatchMetadataOperator</code> \u2013 read/write batch metadata</li> <li><code>BufferProbe::IBufferObserver</code> \u2013 read-only buffer view</li> <li><code>BufferProbe::IBufferOperator</code> \u2013 read/write buffer payload (use sparingly)</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/#read-only-metadata-probe-recommended","title":"Read-only metadata probe (recommended)","text":"<pre><code>#include \"pipeline.hpp\"\n#include \"buffer_probe.hpp\"\n#include &lt;iostream&gt;\n\nusing namespace deepstream;\n\nclass DetectionPrinter : public BufferProbe::IBatchMetadataObserver {\npublic:\n  probeReturn handleData(BufferProbe&amp; /*probe*/, const BatchMetadata&amp; batch) override {\n    batch.iterate([](const FrameMetadata&amp; frame) {\n      const int   sid = frame.sourceId();\n      const auto  pts = frame.bufPts();      // ns\n      int count = 0;\n\n      frame.iterate([&amp;](const ObjectMetadata&amp; obj) {\n        // Access classId, confidence, bbox, track id, etc.\n        // Example: just count objects\n        (void)obj;\n        ++count;\n      });\n\n      std::cout &lt;&lt; \"source_id=\" &lt;&lt; sid\n                &lt;&lt; \" pts=\" &lt;&lt; pts\n                &lt;&lt; \" objects=\" &lt;&lt; count &lt;&lt; \"\\n\";\n    });\n    return probeReturn::Probe_Ok;\n  }\n};\n\nint main(int argc, char* argv[]) {\n  Pipeline p(\"probe-pipeline\");\n  // ... add/link like in the minimal example ...\n  p.attach(\"infer\", new BufferProbe(\"post-infer\", new DetectionPrinter));\n  p.start().wait();\n}\n</code></pre> <p>Why metadata probes? They avoid CPU/GPU copies and keep the pipeline fast. Use them to read <code>BatchMetadata \u2192 FrameMetadata \u2192 ObjectMetadata</code> and attach small annotations if needed.</p>"},{"location":"programming/video_analytics/deepstream_servicemaker/#buffer-payload-probe-rare-keep-tiny","title":"Buffer payload probe (rare; keep tiny)","text":"<pre><code>class TouchBuffer : public BufferProbe::IBufferOperator {\npublic:\n  probeReturn handleData(BufferProbe&amp; /*probe*/, Buffer&amp; buf) override {\n    // If you must inspect pixels on-path, keep it minimal.\n    VideoBuffer vbuf = buf;  // cast to video view if available\n    vbuf.read([&amp;](const void* data, size_t nbytes) -&gt; size_t {\n      (void)data; (void)nbytes;  // e.g., quick checksum or header peek\n      return nbytes;\n    });\n    return probeReturn::Probe_Ok;\n  }\n};\n</code></pre>"},{"location":"programming/video_analytics/deepstream_servicemaker/#heavy-processing-off-path","title":"Heavy Processing (off-path)","text":"<p>Use DataReceiver at an element that emits signals (typically <code>appsink::new-sample</code>). This keeps heavy I/O, serialization, and conversions off the hot path.</p>"},{"location":"programming/video_analytics/deepstream_servicemaker/#graph-tail-cpu-handoff","title":"Graph tail (CPU handoff)","text":"<p>Ensure final caps drop GPU memory if you want CPU frames:</p> <pre><code>// ... earlier elements ...\n.add(\"nvvideoconvert\", \"cvt\")\n.add(\"capsfilter\",     \"caps\", \"caps\", \"video/x-raw,format=BGR\") // CPU BGR\n.add(\"appsink\",        \"sink\", \"emit-signals\", true, \"sync\", false);\n</code></pre>"},{"location":"programming/video_analytics/deepstream_servicemaker/#datareceiver-consumer","title":"DataReceiver consumer","text":"<pre><code>#include \"pipeline.hpp\"\n#include \"data_receiver.hpp\"\n#include &lt;opencv2/imgcodecs.hpp&gt;\n\nusing namespace deepstream;\n\nclass ExportConsumer : public DataReceiver::IDataConsumer {\npublic:\n  int consume(DataReceiver&amp; /*rx*/, Buffer buffer) override {\n    // 1) Metadata (if present)\n    if (buffer.hasBatchMetadata()) {\n      const BatchMetadata&amp; batch = buffer.getBatchMetadata();\n      batch.iterate([](const FrameMetadata&amp; f) {\n        // Walk objects, serialize dets/tracks, etc.\n        (void)f;\n      });\n    }\n\n    // 2) Pixels (CPU BGR negotiated upstream)\n    VideoBuffer vbuf = buffer;\n    const int w = vbuf.width();\n    const int h = vbuf.height();\n\n    vbuf.read([&amp;](const void* data, size_t size) -&gt; size_t {\n      // Assuming BGR8 tightly packed (verify stride in your caps if needed)\n      cv::Mat bgr(h, w, CV_8UC3, const_cast&lt;void*&gt;(data));\n      cv::imwrite(\"frame.jpg\", bgr);  // example: heavy I/O off-path\n      return size;\n    });\n\n    return 0; // success\n  }\n};\n\nint main(int argc, char* argv[]) {\n  Pipeline p(\"receiver-pipeline\");\n  // ... add/link, ending with \"sink\" appsink as above ...\n  p.attach(\"sink\", new DataReceiver(\"new-sample\", new ExportConsumer));\n  p.start().wait();\n}\n</code></pre> <p>Tips</p> <ul> <li><code>emit-signals=true</code> is required on <code>appsink</code> to fire <code>new-sample</code>.</li> <li>Do ROS 2 publishing, file/network export, JSON packing, etc. here.</li> <li>If you keep frames on GPU (no CPU caps), design your consumer accordingly.</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/#yaml-configuration","title":"YAML Configuration","text":""},{"location":"programming/video_analytics/deepstream_servicemaker/#declarative-pipeline-correct-schema","title":"Declarative pipeline (correct schema)","text":"<pre><code>deepstream:\n  nodes:\n    - type: nvurisrcbin\n      name: src\n      properties:\n        uri: \"file:///opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.h264\"\n\n    - type: nvstreammux\n      name: mux\n      properties:\n        batch-size: 1\n        width: 1280\n        height: 720\n\n    - type: nvinferbin\n      name: infer\n      properties:\n        config-file-path: /opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_infer_primary.yml\n\n    - type: nvosdbin\n      name: osd\n\n    - type: nveglglessink\n      name: sink\n\n  edges:\n    src: mux\n    mux: infer\n    infer: osd\n    osd: sink\n</code></pre>"},{"location":"programming/video_analytics/deepstream_servicemaker/#hybrid-yaml-c-hooks","title":"Hybrid: YAML + C++ hooks","text":"<pre><code>#include \"pipeline.hpp\"\n#include \"buffer_probe.hpp\"\n#include \"data_receiver.hpp\"\n\nusing namespace deepstream;\n\nint main() {\n  Pipeline p = Pipeline::fromYaml(\"pipeline.yaml\");\n\n  p.attach(\"infer\", new BufferProbe(\"post-infer\", new DetectionPrinter));\n  p.attach(\"sink\",  new DataReceiver(\"new-sample\", new ExportConsumer));\n\n  p.start().wait();\n}\n</code></pre>"},{"location":"programming/video_analytics/deepstream_servicemaker/#integration-points-best-practices","title":"Integration Points &amp; Best Practices","text":""},{"location":"programming/video_analytics/deepstream_servicemaker/#where-to-hook","title":"Where to hook","text":"Stage What you get Typical use After <code>nvinferbin</code> Detections (<code>ObjectMetadata</code>) Real-time det logic, counters After <code>nvtracker</code> Detections + track IDs Tracking/persistence analytics After <code>nvosdbin</code> Overlays drawn; metadata intact Final QA/telemetry At <code>appsink</code> Pixels (CPU or GPU) + full metadata off-path ROS bridge, archival, streaming"},{"location":"programming/video_analytics/deepstream_servicemaker/#metadata-classes-naming","title":"Metadata classes (naming)","text":"<ul> <li><code>BatchMetadata</code> \u2192 frames</li> <li><code>FrameMetadata</code> \u2192 per-frame info (<code>sourceId</code>, <code>bufPts</code>, etc.)</li> <li><code>ObjectMetadata</code> \u2192 per-object det/track (classId, confidence, bbox, objectId)</li> <li>(Also available when produced: <code>ClassifierMetadata</code>, <code>DisplayMetadata</code>, <code>TensorOutputUserMetadata</code>, \u2026)</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/#performance","title":"Performance","text":"<ol> <li>Keep probes light (log, small counters, tiny annotations).</li> <li>Do heavy work in DataReceiver (appsink), not on the hot path.</li> <li>CPU vs GPU explicitly: control with caps at the tail (<code>video/x-raw,format=BGR</code> for CPU; keep <code>memory:NVMM</code> if you want GPU).</li> <li>Batching: <code>nvstreammux</code> batch semantics and identity via <code>FrameMetadata.sourceId + bufPts</code> remain your sync keys.</li> </ol>"},{"location":"programming/video_analytics/deepstream_servicemaker/#debugging","title":"Debugging","text":"<ul> <li>You can still attach raw GStreamer pad probes to elements created by SM for exotic event/query timing or caps debugging.</li> <li>Validate caps at the tail (format, stride) to match your consumer assumptions.</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/#lifecycle-control","title":"Lifecycle control","text":"<pre><code>pipeline.start();     // start streaming\npipeline.wait();      // block until EOS or stop\npipeline.stop();      // stop and teardown\n\n// Advanced multi-pipeline bring-up:\npipeline.prepare();\npipeline.activate();\npipeline.wait();\n</code></pre>"},{"location":"programming/video_analytics/deepstream_servicemaker/#summary","title":"Summary","text":"<ul> <li>Build pipelines declaratively with Pipeline API (or YAML).</li> <li>Use metadata probes for fast, in-path inspection.</li> <li>Use DataReceiver at appsink for off-path heavy tasks (export, ROS, storage).</li> <li>Keep the classic DeepStream mental model: buffers carry pixels + <code>NvDs</code> metadata; batching and <code>sourceId + bufPts</code> drive synchronization.</li> </ul>"},{"location":"programming/video_analytics/deepstream_servicemaker/#references","title":"References","text":"<ul> <li>NVIDIA DeepStream Service Maker Documentation</li> </ul>"},{"location":"programming/video_analytics/gstreamer/","title":"GStreamer Reference","text":"<p>\"GStreamer is a pipeline-based multimedia framework that links together a wide variety of media processing systems to complete complex workflows.\"[1]</p>"},{"location":"programming/video_analytics/gstreamer/#installation","title":"Installation","text":"<p>On Ubuntu or Debian</p> <pre><code>$ sudo apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio\n</code></pre>"},{"location":"programming/video_analytics/gstreamer/#gstreamer-tools","title":"GStreamer Tools","text":"<p>You can use \"gst-launch-1.0\" to quickly test pipelines before trying to implement your application using the gstreamer API calls.</p>"},{"location":"programming/video_analytics/gstreamer/#gst-launch-10","title":"gst-launch-1.0","text":""},{"location":"programming/video_analytics/gstreamer/#command-pattern","title":"Command Pattern","text":"<p>A command with \"gst-launch-1.0\" generally has the following form:</p> <pre><code>$ gst-launch-1.0 element1 [property=value1] ! element2 [property=value2]\n</code></pre> <p>You could also name an element so that you can refer to it later</p> <pre><code>$ gst-launch-1.0 element1 [name=xyz] ! element2 xyz. ! element3\n</code></pre>"},{"location":"programming/video_analytics/gstreamer/#sample-usages","title":"Sample Usages","text":"<ul> <li>Display a test pattern</li> </ul> <pre><code># video test src\n$ gst-launch-1.0 videotestsrc ! videoconvert ! autovideosink\n# audio test src\n$ gst-launch-1.0 audiotestsrc ! autoaudiosink\n# combine both video and audio \n$ gst-launch-1.0 audiotestsrc ! autoaudiosink videotestsrc ! autovideosink\n</code></pre> <ul> <li>Play video from a file</li> </ul> <pre><code>$ gst-launch-1.0 playbin uri=https://gstreamer.freedesktop.org/data/media/sintel_trailer-480p.webm\n</code></pre> <ul> <li>Play video from a USB camera (v4l2)</li> </ul> <pre><code>$ gst-launch-1.0 v4l2src device=/dev/video0 ! videoconvert ! autovideosink\n</code></pre> <ul> <li>Play video from a RTSP stream</li> </ul> <pre><code>$ gst-launch-1.0 rtspsrc location=rtsp://&lt;rtsp-address&gt; latency=0 buffer-mode=auto ! decodebin ! autovideosink\n</code></pre>"},{"location":"programming/video_analytics/gstreamer/#gst-inspect-10","title":"gst-inspect-1.0","text":"<p>This tool is to inspect details of gstreamer plugins/elements</p> <pre><code># list all available elements\n$ gst-inspect-1.0\n# list information regarding an element\n$ gst-inspect-1.0 vp8dec\n</code></pre>"},{"location":"programming/video_analytics/gstreamer/#gst-discoverer-10","title":"gst-discoverer-1.0","text":"<p>This tool can be used to list information regarding the media that GStreamer can extract</p> <pre><code>$ gst-discoverer-1.0 https://gstreamer.freedesktop.org/data/media/sintel_trailer-480p.webm -v\n</code></pre>"},{"location":"programming/video_analytics/gstreamer/#reference","title":"Reference","text":"<ul> <li>[1] https://en.wikipedia.org/wiki/GStreamer</li> <li>[2] https://gstreamer.freedesktop.org/documentation/tutorials/basic/gstreamer-tools.html?gi-language=c</li> <li>[3] https://gstreamer.freedesktop.org/documentation/tools/gst-launch.html?gi-language=c</li> <li>[4] https://github.com/matthew1000/gstreamer-cheat-sheet/tree/master</li> <li>[5] https://www.wowza.com/blog/streaming-protocols</li> <li>[6] https://github.com/PhysicsX/Gstreamer-on-embedded-devices</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/","title":"WebRTC Connection Setup","text":""},{"location":"programming/webrtc/webrtc_connection_setup/#conceptual-layering","title":"Conceptual Layering","text":"<p>In WebRTC, establishing a real-time connection between peers involves multiple coordinated steps across different protocol layers. Understanding these layers helps clarify how media and data flow securely and efficiently from one device to another.</p> <p>You may think of the layers as follows:</p> <ul> <li>SDP: Configuration Layer<ul> <li>Describes media capabilities, codec preferences, transport parameters (ICE, DTLS), and negotiation state.</li> </ul> </li> <li>ICE: Connectivity Layer<ul> <li>Discovers possible network paths (host, STUN, TURN), performs connectivity checks, and selects a working route.</li> </ul> </li> <li>DTLS: Encryption Layer<ul> <li>Establishes a secure connection over the selected ICE path, negotiating keys for media and data encryption.</li> </ul> </li> <li>SRTP / SCTP: Transport Layers<ul> <li>SRTP: Securely carries audio/video streams.</li> <li>SCTP (over DTLS): Transports data channels with reliability and ordering options.</li> </ul> </li> </ul> <p>SDP configures the session, ICE connects the peers, DTLS secures the transport, and SRTP/SCTP transmit the media and data.</p>"},{"location":"programming/webrtc/webrtc_connection_setup/#peer-connection-components","title":"Peer Connection Components","text":"<p>The <code>RTCPeerConnection</code> object (in both browser/WebRTC native C++ API) encapsulates the full stack of components required to establish and manage a secure real-time connection. These components work together to handle signaling, connectivity, encryption, and media/data transmission.</p>"},{"location":"programming/webrtc/webrtc_connection_setup/#1-ice-agent","title":"1. ICE Agent","text":"<ul> <li>Gathers local ICE candidates (host, STUN, TURN)</li> <li>Performs STUN-based connectivity checks with the remote peer</li> <li>Selects and manages the most efficient and stable candidate pair</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#2-dtls-transport","title":"2. DTLS Transport","text":"<ul> <li>Manages DTLS certificates and handshakes</li> <li>Establishes a secure transport channel over the selected ICE candidate pair</li> <li>Derives session keys for SRTP (media) and SCTP (data)</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#3-srtpsctp-stack","title":"3. SRTP/SCTP Stack","text":"<ul> <li>SRTP: Encrypts and decrypts audio/video RTP streams using keys from DTLS</li> <li>SCTP (over DTLS): Transports WebRTC data channels with reliability, ordering, and stream multiplexing</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#4-media-transceiverstracks","title":"4. Media Transceivers/Tracks","text":"<ul> <li>Manages the sending and receiving of audio/video tracks</li> <li>Controls media direction (sendrecv, recvonly, inactive, etc.)</li> <li>Supports dynamic track replacement (e.g., switching cameras)</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#5-signaling-state-machine","title":"5. Signaling State Machine","text":"<ul> <li>Tracks the signaling flow (offer/answer negotiation)</li> <li>Manages state transitions (stable, have-local-offer, etc.)</li> <li>Triggers onnegotiationneeded when renegotiation is required</li> <li>Supports rollback in case of offer/answer conflicts or errors</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#visual-timeline","title":"Visual Timeline","text":"<pre><code>Time \u2192\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502   Caller   \u2502                                   \u2502   Answerer   \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     |                                                 |\n     | CreateOffer()                                   |\n     |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;|\n     |                                                 |\n     | SetLocalDescription(offer)                      |\n     | (starts local ICE gathering)                    |\n     |  \u2193                                              |\n     |  Emit local ICE candidates (trickle)            |\n     |  \u2193                                              |\n     |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[ Offer via Signaling ]\u2500\u2500\u2500\u2500&gt;|\n     |                                                 |\n     |                                    SetRemoteDescription(offer)\n     |                                    CreateAnswer()\n     |                                    SetLocalDescription(answer)\n     |                                    (starts ICE gathering) \n     |                                    \u2193\n     |                                    Emit answerer ICE candidates\n     |&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[ Answer via Signaling ]\u2500\u2500\u2500\u2500|\n     |                                                 |\n     | SetRemoteDescription(answer)                    |\n     |                                                 |\n     |&lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[ ICE candidates (from answerer) ]\u2500\u2500\u2500\u2500\u2500|\n     |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[ ICE candidates (to answerer) ]\u2500\u2500\u2500\u2500\u2500\u2500&gt;|\n     |                                                 |\n     |        Both sides perform ICE connectivity checks\n     |       (STUN binding requests, find valid pair)  |\n     |                                                 |\n     |        ICE state: checking \u2192 connected          |\n     |                                                 |\n     |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 DTLS Handshake Begins \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500|\n     |                                                 |\n     |    Secure transport established (SRTP/SCTP)     |\n     |                                                 |\n     |&lt;\u2500\u2500\u2500\u2500 onTrack / onDataChannel / onConnection \u2500\u2500\u2500&gt;|\n     |         Media and Data Channels Active          |\n</code></pre>"},{"location":"programming/webrtc/webrtc_connection_setup/#sdp-and-ice-roles","title":"SDP and ICE Roles","text":"<p>Both SDP and ICE are exchanged during WebRTC signaling to let peers agree on media format and how to reach each other.</p> <ul> <li>SDP (Session Description Protocol) defines the what (codecs, media, etc.).</li> <li>ICE (Interactive Connectivity Establishment) defines the how (network paths for connectivity).</li> </ul> <p>The SDP offer/answer model negotiates how peers want to communicate (media formats, ICE credentials, DTLS fingerprints, etc.), while the ICE process actually establishes the network path between them. Once ICE finds a valid candidate pair, DTLS sets up a secure transport, and SRTP/SCTP runs on top for media and data.</p> <p>Negotiation is triggered mostly by signaling state changes that affect the SDP. ICE restart is the only ICE-related action that requires renegotiation.</p> Event Triggers Negotiation? Why <code>addTrack()</code> \u2705 Yes Adds media to SDP <code>removeTrack()</code> \u2705 Yes Changes media config <code>addTransceiver()</code> \u2705 Yes Adds m-line in SDP <code>setCodecPreferences()</code> \u2705 Yes Modifies offer capabilities Changing direction (<code>sendonly</code>, <code>recvonly</code>) \u2705 Yes Affects media flow Updating <code>RTCRtpSender</code> parameters (e.g., <code>setParameters()</code>) \u274c No Local change only ICE candidate discovered \u274c No Doesn\u2019t affect media description ICE restart (<code>iceRestart: true</code>) \u2705 Yes Special case \u2014 described below ICE failure/reconnection \u274c No (handled internally) Unless manually restarted DTLS transport failure \u274c No (handled internally) App can react, but no auto-renegotiation"},{"location":"programming/webrtc/webrtc_connection_setup/#sdp-offeranswer-model","title":"SDP Offer/Answer Model","text":"<p>The SDP (Session Description Protocol) offer/answer model is a mechanism used in WebRTC to negotiate media parameters (such as codecs, IP addresses, ports, etc.) between two peers.</p>"},{"location":"programming/webrtc/webrtc_connection_setup/#1-creating-an-offer-caller","title":"1. Creating an Offer (caller)","text":"<ul> <li>The caller generates an SDP offer using the CreateOffer method of the webrtc::PeerConnectionInterface object.</li> <li>Once the offer is created, it is set as the local description using the SetLocalDescription method.</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#2-sending-the-offer-caller","title":"2. Sending the Offer (caller)","text":"<ul> <li>The SDP offer is sent to the other peer (the answerer) via a signaling server (e.g., WebSocket, SIP, etc.).</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#3-receiving-the-offer-answerer","title":"3. Receiving the Offer (answerer)","text":"<ul> <li>The answerer receives the SDP offer and sets it as their remote description using the SetRemoteDescription method.</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#4-creating-an-answer-answerer","title":"4. Creating an Answer (answerer)","text":"<ul> <li>The answerer generates an SDP answer in response to the received offer using the CreateAnswer method of the webrtc::PeerConnectionInterface object.</li> <li>Once the answer is created, it is set as the local description using the SetLocalDescription method.</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#5-sending-the-answer-answerer","title":"5. Sending the Answer (answerer)","text":"<ul> <li>The SDP answer is sent back to the caller via the signaling server.</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#6-receiving-the-answer-caller","title":"6. Receiving the Answer (caller)","text":"<ul> <li>The caller receives the SDP answer and sets it as their remote description using the SetRemoteDescription method.</li> </ul>"},{"location":"programming/webrtc/webrtc_connection_setup/#ice-candidate-exchange","title":"ICE Candidate Exchange","text":"<p>In parallel with the offer/answer exchange, both peers gather ICE (Interactive Connectivity Establishment) candidates. These candidates represent potential network paths (IP addresses and ports) that can be used to establish the media connection.</p> <p>ICE candidates are sent to the remote peer via the signaling server and added using the AddIceCandidate method.</p> <p>In Trickle ICE, a peer knows that all ICE candidates have been sent when it receives a special \"end-of-candidates\" signal. This can happen in two ways:</p> <ul> <li>ICE Candidate Event with null</li> <li>Signaling a Final Candidate (SDP or JSON)</li> </ul> <p>Without this final signal:</p> <ul> <li>The ICE agent may wait indefinitely for more candidates.</li> <li>The connection state may stall in \"checking\" or \"connecting\".</li> </ul> <pre><code>[Gathering ICE candidates...]\n   \u2193\nonicecandidate \u2192 send each candidate\n   \u2193\nonicecandidate \u2192 event.candidate === null\n   \u2193\nSend \"end-of-candidates\" marker\n   \u2193\nRemote peer: addIceCandidate(null)\n   \u2193\nICE completes (if a valid candidate pair found)\n</code></pre>"},{"location":"programming/webrtc/webrtc_connection_setup/#state-transitions-in-webrtc","title":"State Transitions in WebRTC","text":"<p>The RTCPeerConnection object maintains a signaling state to track the progress of the offer/answer exchange:</p> <ul> <li>stable: Initial state, no ongoing SDP exchange.</li> <li>have-local-offer: A local SDP offer has been created and set by the local peer.</li> <li>have-remote-offer: A remote SDP offer has been received and set by the local peer.</li> <li>have-local-pranswer: A local SDP provisional answer has been created and set in response to a remote offer.</li> <li>have-remote-pranswer: A remote SDP provisional answer has been received in response to a local offer.</li> <li>closed: The connection is closed.</li> </ul> <p>When the signaling state changes to stable, it indicates that:</p> <ul> <li>Both peers have successfully negotiated the SDP.</li> <li>The RTCPeerConnection is ready to proceed with media exchange.</li> <li>No pending offer/answer exchange is ongoing.</li> </ul> <p>The state follows the following patterns before reaching stable state:</p> <ul> <li>The transition from stable to have-local-offer happens when an SDP offer is created and set as the local description by the caller.</li> <li>The transition from stable to have-remote-offer happens when an SDP offer is received and set as the remote description by the answerer.</li> <li>The transition back to stable happens when the caller sets the remote description to the received answer or when the answerer sets the local description to the created answer.</li> </ul>"},{"location":"programming/webrtc/webrtc_reference/","title":"WebRTC Reference","text":"<ul> <li>WebRTC \u5b66\u4e60\u6307\u5357</li> <li>WebRTC/Mediasoup Youtube Channel</li> </ul>"},{"location":"resource/blog/","title":"Tech Blogs","text":""},{"location":"resource/blog/#robotics","title":"Robotics","text":"<ul> <li>Rodney Brooks: https://rodneybrooks.com/blog/</li> <li>Axel: https://axelsdiy.brinkeby.se/</li> </ul>"},{"location":"resource/blog/#programming","title":"Programming","text":"<ul> <li>Blog of Scott Meyers: http://scottmeyers.blogspot.com/</li> <li>Eli Bendersky's website: http://eli.thegreenplace.net/</li> <li>Fluent C++: https://www.fluentcpp.com/</li> </ul>"},{"location":"resource/blog/#embedded-system","title":"Embedded System","text":"<ul> <li>Jeff Geerling: https://www.jeffgeerling.com/blog</li> </ul>"},{"location":"resource/course/","title":"Online Courses","text":""},{"location":"resource/course/#open-course","title":"Open Course","text":"<ul> <li>Robotics<ul> <li>Underactuated Robotics, Russ Tedrake, MIT</li> <li>https://github.com/brunoeducsantos/robotics_master</li> <li>https://github.com/UMich-CURLY-teaching/UMich-ROB-530-public<ul> <li>Github</li> <li>Youtube</li> </ul> </li> </ul> </li> </ul>"},{"location":"resource/course/#university-course","title":"University Course","text":"<p>Mathematics</p> <ul> <li>Linear Algebra by Zhicheng Zhou: https://ccjou.wordpress.com/</li> </ul> <p>Computer Science</p> <ul> <li>IIT: CS 351: Systems Programming http://moss.cs.iit.edu/cs351/</li> <li>IIT: CS 450: Operating Systems http://moss.cs.iit.edu/cs450/</li> <li>Stanford: CS106L: Standard C++ Programming Laboratory http://web.stanford.edu/class/cs106l/</li> <li>CMU CS:APP http://csapp.cs.cmu.edu/3e/students.html</li> <li>CSE 373 - Analysis of Algorithms https://www3.cs.stonybrook.edu/~skiena/373/</li> </ul> <p>Electrical &amp; Computer Engineering</p> <ul> <li>Stanford: Convex Optimization http://stanford.edu/~boyd/cvxbook/</li> <li>Advanced Embedded System Design and Experiments http://wiki.csie.ncku.edu.tw/embedded/schedule</li> </ul> <p>Robotics</p> <ul> <li>Underactuated Robotics, Algorithms for Walking, Running, Swimming, Flying, and Manipulation http://underactuated.csail.mit.edu/underactuated.html</li> <li>Kalman and Bayesian Filters in Python https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python</li> <li>CMU: An Introduction to Physically Based Modeling http://www.cs.cmu.edu/~baraff/pbm/pbm.html</li> </ul>"},{"location":"resource/interview/","title":"Coding Interview Problems","text":""},{"location":"resource/interview/#reference","title":"Reference","text":"<ul> <li>https://cheonhyangzhang.gitbooks.io/leetcode-solutions/content/</li> <li>https://www.yuque.com/pikachuhy/leetcode</li> <li>http://www.cyc2018.xyz/</li> <li>https://github.com/CyC2018/CS-Notes</li> <li>https://github.com/gatieme/CodingInterviews</li> <li>https://github.com/gibsjose/cpp-cheat-sheet</li> <li>https://github.com/kamyu104/LeetCode-Solutions</li> </ul>"},{"location":"resource/tutorial/","title":"Tutorials","text":""},{"location":"resource/tutorial/#operating-system","title":"Operating System","text":"<ul> <li>Anatomy of a Program in Memory</li> <li>How the Kernel Manages Your Memory</li> <li>Operating Systems: Three Easy Pieces</li> </ul>"},{"location":"resource/tutorial/#c","title":"C++","text":"<ul> <li>Guide into OpenMP: Easy multithreading programming for C++</li> <li>lvalue and rvalue</li> </ul>"},{"location":"resource/tutorial/#robotics","title":"Robotics","text":"<p>Kinematics</p> <ul> <li>Representing Attitude: Euler Angles, Unit Quaternions, and Rotation Vectors</li> <li>Understanding Rotations</li> <li>Understanding Quaternions</li> <li>Quaternions and Rotations</li> <li>Quaternions: How</li> </ul> <p>Dynamics</p> <ul> <li>Rigid Body Dynamics, by Matthew T. Mason (CMU)</li> <li>Euler's Equations by Adrian Down (Duke U)</li> <li>Physically Based Modeling: Principles and Practice, by Andrew Witkin and David Baraff (CMU)</li> </ul> <p>Decision</p> <ul> <li>The POMDP Page</li> <li>Dimitri Ognibene's POMDP and MDP page</li> </ul>"},{"location":"resource/watchlist/","title":"Watchlist","text":""},{"location":"resource/watchlist/#network","title":"Network","text":"<ul> <li>zenoh: https://zenoh.io/</li> </ul>"},{"location":"resource/watchlist/#system-monitoring-administration","title":"System Monitoring &amp; Administration","text":"<ul> <li>webmin: https://www.webmin.com/</li> </ul>"},{"location":"robotics/control/","title":"Control","text":""},{"location":"robotics/control/#foundation","title":"Foundation","text":"<ul> <li>UMich Control Tutorials</li> <li>UMich Robotics 501: Mathematics for Robotics</li> </ul>"},{"location":"robotics/control/#kinematics-and-dynamics","title":"Kinematics and Dynamics","text":"<p>Kinematics and Dynamics for Robotics: https://github.com/ANYbotics/kindr</p>"},{"location":"robotics/control/#state-estimation","title":"State Estimation","text":"<ul> <li>Kalman Filter Book</li> <li>Tutorial: A practical approach to Kalman filter and how to implement it</li> <li>AHRS: Attitude and Heading Reference Systems: ahrs.readthedocs.io/</li> <li>MEKF: https://matthewhampsey.github.io/blog/2020/07/18/mekf</li> </ul>"},{"location":"robotics/control/#model-predictive-control","title":"Model Predictive Control","text":"<ul> <li>UC Berkeley MPC Book: http://www.mpc.berkeley.edu/mpc-course-material</li> <li>Model predictive control python toolbox: https://www.do-mpc.com/en/latest/index.html</li> </ul>"},{"location":"robotics/control/#optimal-control","title":"Optimal Control","text":"<ul> <li>Underactuated Robotics: http://underactuated.mit.edu/index.html</li> <li>PSOPT: https://github.com/PSOPT/psopt</li> </ul>"},{"location":"robotics/control/#control-librarytoolbox","title":"Control Library/Toolbox","text":""},{"location":"robotics/control/#numerical-optimization","title":"Numerical Optimization","text":"<ul> <li>SCS (splitting conic solver): https://github.com/cvxgrp/scs</li> <li>OSQP (Operator Splitting Quadratic Program): https://osqp.org/</li> <li>Ipopt (Interior Point Optimizer): https://coin-or.github.io/Ipopt/</li> </ul>"},{"location":"robotics/control/#optimal-control_1","title":"Optimal Control","text":"<ul> <li>PSOPT: https://github.com/PSOPT/psopt</li> </ul>"},{"location":"robotics/control/#control-toolbox","title":"Control Toolbox","text":"<ul> <li>ETH Control Toolbox: https://github.com/ethz-adrl/control-toolbox</li> <li>MIT Drake Toolbox: https://drake.mit.edu/</li> </ul>"},{"location":"robotics/perception/","title":"Perception","text":""},{"location":"robotics/perception/#calibration","title":"Calibration","text":"<ul> <li>https://github.com/acfr/cam_lidar_calibration</li> <li>https://github.com/ethz-asl/kalibr</li> <li>https://github.com/koide3/direct_visual_lidar_calibration</li> </ul>"},{"location":"robotics/perception/#detection","title":"Detection","text":"<ul> <li>https://github.com/amusi/awesome-lane-detection</li> </ul>"},{"location":"robotics/perception/#occupancy-mapping","title":"Occupancy Mapping","text":"<ul> <li>https://github.com/ethz-asl/voxblox</li> <li>https://github.com/HKUST-Aerial-Robotics/FIESTA</li> <li>https://github.com/facontidavide/Bonxai</li> <li>https://github.com/ethz-asl/wavemap</li> </ul>"},{"location":"robotics/perception/#bev","title":"BEV","text":"<ul> <li>https://github.com/mit-han-lab/bevfusion</li> <li>https://github.com/NVIDIA-AI-IOT/Lidar_AI_Solution/tree/master/CUDA-BEVFusion</li> <li>https://github.com/OpenDriveLab/Birds-eye-view-Perception</li> </ul>"},{"location":"robotics/perception/#slam","title":"SLAM","text":"<ul> <li>https://github.com/OpenVSLAM-Community/openvslam</li> <li>https://github.com/TixiaoShan/LIO-SAM</li> <li>https://github.com/hku-mars/FAST_LIO</li> <li>https://github.com/Livox-SDK/LIO-Livox</li> <li>https://github.com/PRBonn/kiss-icp</li> <li>https://github.com/gaoxiang12/slam_in_autonomous_driving</li> <li>https://github.com/SLAM-Handbook-contributors/slam-handbook-public-release</li> </ul>"},{"location":"robotics/perception/#localization","title":"Localization","text":"<ul> <li>https://github.com/koide3/hdl_localization</li> <li>https://github.com/HViktorTsoi/FAST_LIO_LOCALIZATION</li> <li>https://github.com/Gaochao-hit/LIO-SAM_based_relocalization</li> <li>https://github.com/AbangLZU/ndt_localizer</li> <li>https://github.com/melhousni/ndt_mapping_localization</li> <li>https://github.com/hku-mars/LiDAR_IMU_Init</li> </ul>"},{"location":"robotics/planning/","title":"Planning","text":""},{"location":"robotics/planning/#computational-geometry","title":"Computational Geometry","text":"<p>Lecture Notes on Differential Geometry</p>"},{"location":"robotics/planning/#behavior-planning","title":"Behavior Planning","text":"<ul> <li>Behavior Trees vs Finite-State Machines</li> <li>ETH: Applied Compositional Thinking for Engineers</li> <li>Forester: Behavior Tree Orchestration Engine</li> </ul>"},{"location":"robotics/planning/#motion-planning","title":"Motion Planning","text":""},{"location":"robotics/planning/#librarytoolbox","title":"Library/Toolbox","text":"<ul> <li>Nearest Neighbor (NN) search with KD-trees: https://github.com/jlblancoc/nanoflann</li> <li>Hybrid A* Path Planner: https://github.com/karlkurzer/path_planner</li> <li>Motion Planning for Autonomous Vehicles: https://github.com/zhm-real/MotionPlanning</li> <li> <p>Motion Planning: https://github.com/zhm-real/MotionPlanning</p> </li> <li> <p>Volumetric Data Representation and Manipulation on a 3D Grid: https://www.openvdb.org/</p> </li> </ul>"},{"location":"robotics/reference/","title":"Books in Robotics","text":""},{"location":"robotics/reference/#mathematics","title":"Mathematics","text":"<p>Linear Algebra </p> <ul> <li>Linear Algebra Done Right, by Axler, Sheldon </li> <li>Linear Algebra Done Wrong, by Sergei Treil</li> <li>Introduction to Applied Linear Algebra, by Stephen Boyd and Lieven Vandenberghe</li> </ul> <p>Analysis</p> <ul> <li>Principles of Mathematical Analysis, by Walter Rudin</li> <li>Introductory Functional Analysis with Applications, by Erwin Kreyszig</li> </ul> <p>Computational</p> <ul> <li>Numerical Analysis, by Richard L. Burden and J. Douglas Faires</li> <li>Convex Optimization, by Stephen Boyd and Lieven Vandenberghe</li> <li>Applied Mathematical Programming, by Bradley, Hax, and Magnanti</li> </ul>"},{"location":"robotics/reference/#systems-and-control","title":"Systems and Control","text":"<ul> <li>Calculus of Variations and Optimal Control Theory: A Concise Introduction, by Daniel Liberzon</li> <li> <p>Optimal Control Theory: An Introduction, by Donald E. Kirk</p> </li> <li> <p>Markov Models for Pattern Recognition: From Theory to Applications, by Fink, Gernot A.</p> </li> </ul>"},{"location":"robotics/reference/#robotics-and-artificial-intelligence","title":"Robotics and Artificial Intelligence","text":"<p>Introductory</p> <ul> <li>Modern Robotics</li> <li>Robot Modeling and Control, by Mark W. Spong, Seth Hutchinson, M. Vidyasagar</li> <li>Robotics: Modelling, Planning and Control, by Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani, Giuseppe Oriolo</li> <li>Introduction to Autonomous Mobile Robots, by Roland Siegwart, Illah R. Nourbakhsh, Davide Scaramuzza</li> <li>Control of Robot Manipulators in Joint Space, by Rafael Kelly, Victor Santib\u00e1\u00f1ez Davila, Julio Antonio Lor\u00eda Perez</li> <li>Artificial Intelligence: A Modern Approach, by Stuart J. Russell, Peter Norvig</li> </ul> <p>Perception &amp; Estimation</p> <ul> <li>Probabilistic Robotics, by Sebastian Thrun, Wolfram Burgard, Dieter Fox </li> <li>State Estimation for Robotics, by Tim Barfoot </li> <li>Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches, by Dan Simon</li> </ul> <p>Motion Planning</p> <ul> <li>Robot Motion Planning, by Latombe, Jean-Claude</li> <li>Principles of Robot Motion: Theory, Algorithms, and Implementations, by H. Choset, K. M. Lynch, S. Hutchinson, G. Kantor, W. Burgard, L. E. Kavraki and S. Thrun</li> <li>Planning Algorithms, by Steven M. LaValle</li> </ul> <p>Publications</p> <ul> <li>Top Publications of Robotics from Google Scholar</li> </ul>"},{"location":"robotics/reference/#machine-learning","title":"Machine Learning","text":"<ul> <li>Probabilistic Machine Learning</li> </ul>"},{"location":"robotics/reference/#programming","title":"Programming","text":"<p>Foundations</p> <ul> <li>Computer Systems: A Programmer's Perspective, by Randal E. Bryant and David R. O'Hallaron</li> <li>Data Structures and Algorithm Analysis in C++, 4th Edition, by Mark A. Weiss</li> <li>The Algorithm Design Manual, 2nd Edition, by Steven Skiena</li> </ul> <p>C++</p> <ul> <li>Effective Modern C++: 42 Specific Ways to Improve Your Use of C++11 and C++14, by Scott Meyers</li> <li>C++ Templates: The Complete Guide, 2nd Edition, by David Vandevoorde, Nicolai M. Josuttis, and Douglas Gregor</li> <li>The Definitive C++ Book Guide and List</li> </ul>"},{"location":"robotics/robot/","title":"Robot Implementation","text":""},{"location":"robotics/robot/#unmanned-aerial-vehicle-uav","title":"Unmanned Aerial Vehicle (UAV)","text":"<ul> <li>Gemoetric Control on SE(3): https://github.com/fdcl-gwu/uav_geometric_control</li> <li>F Prime (A flight software and embedded systems framework): https://github.com/nasa/fprime</li> <li>https://github.com/HKUST-Aerial-Robotics/OmniNxt</li> </ul>"},{"location":"robotics/robot/#unmanned-ground-vehicle-ugv","title":"Unmanned Ground Vehicle (UGV)","text":"<ul> <li>Ackerman Steering: https://www.xarg.org/book/kinematics/ackerman-steering/</li> <li>https://www.cmu-exploration.com/development-environment</li> </ul>"},{"location":"robotics/robot/#legged-robots","title":"Legged Robots","text":"<ul> <li>https://leggedrobotics.github.io/rl-blindloco/</li> <li>https://github.com/ShuoYangRobotics/A1-QP-MPC-Controller</li> <li>https://github.com/qiayuanl/legged_control</li> <li>https://github.com/qiayuanl/legged_perceptive</li> <li>https://github.com/iit-DLSLab/Quadruped-PyMPC</li> <li>https://github.com/robomechanics/quad-sdk</li> </ul>"},{"location":"robotics/robot/#hobby-robotos","title":"Hobby Robotos","text":"<ul> <li>Balance Bike: https://github.com/nicekwell/balance_bike</li> </ul>"},{"location":"robotics/robot/#robotics-algorithm-library","title":"Robotics Algorithm Library","text":"<ul> <li>Python Robotics: https://github.com/AtsushiSakai/PythonRobotics</li> <li>C++ Robotics: https://github.com/onlytailei/CppRobotics</li> </ul>"},{"location":"robotics/modeling/rigid_body_motion/","title":"Rigid-body Motion","text":""},{"location":"robotics/modeling/rigid_body_motion/#rigid-body-motion-representation","title":"Rigid-body Motion Representation","text":"<p>Notes in this section are mainly based on reference [1] and follow the same notations.</p> <p>Notations</p> <p>A superscript is used to denote the reference frame, for example</p> <ul> <li>The position of point 0 with respect to b frame: \\(p^b_0\\)</li> <li>The orientation of the body frame b with respect to the world frame w: \\(R^w_b\\)</li> </ul>"},{"location":"robotics/modeling/rigid_body_motion/#rigid-motion","title":"Rigid Motion","text":"<p>\"A rigid motion is an ordered pair \\((d, R)\\) where \\(d \\in \\mathcal{R}^3\\) and \\(R \\in \\mathcal{SO}(3)\\). The group of all rigid motions is known as the Special Euclidean Group and is denoted by \\(\\mathcal{SE}(3)\\).\" [1]  </p> \\[ \\mathcal{SE}(3) = \\mathcal{R}(3) \\times \\mathcal{SO}(3) \\] <p>The \\(d\\) part corresponds to a translation and the \\(R\\) part corresponds to a rotation.</p>"},{"location":"robotics/modeling/rigid_body_motion/#position-representation","title":"Position Representation","text":"<p>A position vector can be represented with a column vector. A point in space can be represented with different coordinates when the representations are with respect to different reference frames. For example, a point on a 2D plane can be represented as</p> \\[ p^0 =  \\begin{bmatrix} 1  \\\\ 1  \\end{bmatrix}, \\;\\;\\; p^1 =  \\begin{bmatrix} \\sqrt{2}  \\\\ 0  \\end{bmatrix} \\] <p>where reference frame 1 is rotated counter-clockwise by \\(45^{\\circ}\\) with respect to reference frame 0.</p> <p>Note that a column vector on the other hand may be the representation of different objects, not limited to a point:</p> <ol> <li>The position of a point</li> <li>The coordinates of a free vector, representing a translation</li> <li>The position of one coordinate system with respect to another</li> </ol> <p></p>"},{"location":"robotics/modeling/rigid_body_motion/#rotation-representation","title":"Rotation Representation","text":""},{"location":"robotics/modeling/rigid_body_motion/#rotation-matrix","title":"Rotation Matrix","text":"<p>A rotation is most commonly represented with a rotation matrix \\(R \\in \\mathcal{SO}(n)\\), where \\(\\mathcal{SO}(n)\\) denotes the Special Orthogonal group of order n. </p> <p>The properties of a rotation matrix \\(R\\):</p> <ul> <li>\\(R \\in \\mathcal{SO}(n)\\)</li> <li>\\(R^{-1} \\in \\mathcal{SO}(n)\\)</li> <li>\\(R^{-1} = R^T\\)</li> <li>The columns (and therefore the rows) of \\(R\\) are mutually orthogonal</li> <li>Each column (and therefore each row) of \\(R\\) is a unit vector</li> <li>\\(\\det{R} = 1\\)</li> </ul> <p>The rotation matrix on a 2D plane is given as </p> \\[ R^0_1 =  \\begin{bmatrix} \\cos\\theta &amp; -\\sin\\theta \\\\ \\sin\\theta &amp; \\cos\\theta \\end{bmatrix}, \\;\\;\\; R^1_0 =  \\begin{bmatrix} \\cos\\theta &amp; \\sin\\theta \\\\ -\\sin\\theta &amp; \\cos\\theta \\end{bmatrix} \\] <p></p> <p>Thus for a point \\(p^{0} = \\begin{bmatrix} 1 \\\\ 1\\end{bmatrix}\\) in reference frame 0, it can be represented with respect to reference frame 1</p> \\[ p^{1} = R^1_0p^0  = \\begin{bmatrix} \\cos\\theta &amp; \\sin\\theta \\\\ -\\sin\\theta &amp; \\cos\\theta \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1\\end{bmatrix}  = \\begin{bmatrix} \\cos\\theta + \\sin\\theta \\\\ -sin\\theta+\\cos\\theta\\end{bmatrix} \\] <p>In the case that \\(\\theta=\\pi/4\\), we get \\(p^1=\\begin{bmatrix} \\sqrt{2} \\\\ 0\\end{bmatrix}\\), which is the same with the example given above.</p> <p>A rotation matrix can also be interpreted in multiple ways [1]:</p> <ol> <li>A coordinate transformation relating the coordinates of a point \\(p\\) in two different frames</li> <li>The orientation of a transformed coordinate frame with respect to a fixed coordinate frame</li> <li>An operator taking a vector and rotating it to a new vector in the same coordinate system</li> </ol> <p>Note that applying a translation to a free vector won't change the vector (direction and magnitude), but applying a rotation may change the vector to be a new one. </p>"},{"location":"robotics/modeling/rigid_body_motion/#euler-angles","title":"Euler Angles","text":"<p>A rotation matrix can be specified by the composition of 3 consecutive rotations. Each of the rotation is represented by an angle (\\(\\psi/\\theta/\\phi\\)) around a specified main axis (\\(x/y/z\\)). There are many different combinations of Euler angles. For example, an ZYZ-Euler angle is given by \\(R_j{ZYZ} = R_{z,\\phi}R_{y,\\theta}R_{z,\\psi}\\).</p>"},{"location":"robotics/modeling/rigid_body_motion/#roll-pitch-yaw-angles","title":"Roll, Pitch, Yaw Angles","text":"<p>Roll, pitch, yaw angles can be seen as a special case of Euler angles. In robotics, the body coordinate frame fixed to the robot is usually defined as z-axis pointing up, x-axis pointing front and y-axis point left. In such a case, yaw angle cooresponds to the rotation around z-axis, pitch angle  cooresponds to the rotation around y-axis and roll angle  cooresponds to the rotation around x-axis. Note that different conventions do exist for defining the body reference frame and naming roll, pitch and yaw angles (e.g. in aerospace engineering literature).</p>"},{"location":"robotics/modeling/rigid_body_motion/#axisangle","title":"Axis/Angle","text":"<p>Axis/angle representation used the rotation angle around an arbitrary axis to represent a rotation and is often used to create other types of representations.</p>"},{"location":"robotics/modeling/rigid_body_motion/#quaternion","title":"Quaternion","text":"<p>Quaternion representation is widely used for computation of 3D rotations. It is given in the form </p> \\[     \\vec{q} = w + x\\vec{i} + y\\vec{j} + z\\vec{k}, \\textnormal{or}\\;\\; \\vec{q} = (w,x,y,z) = (w, \\vec{v}) \\] <p>The basis \\(\\vec{i},\\vec{j},\\vec{k}\\) follow the following rules:</p> \\[ \\begin{align*} ij &amp;= -ji = k \\\\ jk &amp;= -kj = i \\\\ ki &amp;= -ik = j \\\\ i^2 = j^2 &amp;= k^2 = ijk = -1 \\end{align*} \\] <p>Generally the quaternions we use to describe orientations are unit quaternions, i.e. \\(\\| q \\| = \\sqrt{w^2 + x^2 + y^2 + z^2} = 1\\). A non-unit quaternion can be normalized by </p> \\[     \\hat{q} = \\frac{q}{\\| q \\|} \\] <p>Note that \"matrices represent linear transforms; quaternions represent a special case of linear transform: rotations in 3 dimensions\"[4]. </p> <p>In addition to the quaternion itself, we have:</p> <ul> <li>Quaternion Conjugate: \\(q^{*} = (w, -\\vec{v})\\). Geometrically, the conjugate represents the inverse of the rotation that q represents. If q rotates a vector in 3D space in one direction, \\(q^{*}\\) rotates it back to the original position. In terms of rotation, if q rotates a coordinate frame from frame A to frame B, then \\(q^{*}\\) rotates it from frame B back to frame A.</li> <li>The negative of a quaternion q, denoted as \\(-q\\), is simply the quaternion with all the components negated: \\(q^{*} = (-w, -\\vec{v})\\). Geometrically, a quaternion and its negative represent the same rotation in 3D space. This is because a quaternion and its negative point to the same point on the 4D unit sphere, which corresponds to the same rotation in 3D space.</li> <li>Quaternion Inverse: \\(q^{-1} = \\frac{q^{*}}{{\\| q \\|}^2}\\), for unit quaternion, we have \\(q^{*} = q^{-1}\\)</li> </ul> <p>The following operations are frequently used:</p> <ul> <li>A point or vector \\(\\vec{v}\\) can be rotated by a quaternion \\(q\\) by operation</li> </ul> \\[ \\vec{v}^{\\prime} = q\\vec{v}q^{-1} \\] <ul> <li>An orientation \\(O\\) can be rotated by a quaterion \\(q\\) by operation</li> </ul> \\[ O^{\\prime} = qO \\] <ul> <li>Multiple rotations can be composed by multiply the quatenion from the left (pre-multiply), for example, \\(O^\\prime\\) is the orientation as if \\(q_1\\) were applied to \\(O\\), then \\(q_2\\), then \\(q_3\\)</li> </ul> \\[ O^{\\prime} = q_3q_2q_1O \\] <p>Quaternions can be used to do the calculation efficiently but are not so intuitive to understand. Reference [3] and [5] are highly recommended if more details are required. </p>"},{"location":"robotics/modeling/rigid_body_motion/#composition-of-rotations","title":"Composition of Rotations","text":"<p>A summary of the rule of composition of rotational transformations can be found in [1]:</p> <p>Given a fixed frame \\(o_0x_0y_0z_0\\), a current frame \\(o_1x_1y_1z_1\\), together with rotation matrix \\(R^0_1\\) relating them, </p> <ul> <li>if a third frame \\(o_2x_2y_2z_2\\) is obtained by a rotation \\(R\\) performed relative to the current frame then post-multiply \\(R^0_1\\) by \\(R=R^1_2\\) to obtain </li> </ul> \\[R^0_2 = R^0_1R^1_2\\] <ul> <li>if the second rotation is to be performed relative to the fixed frame, then pre-multiply \\(R^0_1\\) by \\(R\\) to obtain</li> </ul> \\[R^0_2 = RR^0_1\\] <p>The first case of composition is more commonly seen and it's also more intuitive to understand.</p> <p>The multiple meanings of a vector and matrix</p> <p>The multiple meanings a vector or a matrix can easily cause confusions when handling rigid-body motions. Interpretation 3 of a vector and interpretation 2 of a matrix listed above are often used when you're considering the relationship between two cooredinate frames in order to set up new frames. Interpretation 2 of a vector and interpretation 3 of a matrix are often used when you're handling the calculation of transformations in order to transform a pose from one coordinate frame to another.</p>"},{"location":"robotics/modeling/rigid_body_motion/#homogeneous-transformation","title":"Homogeneous Transformation","text":"<p>A homogeneous transformation matrix combines translation and rotation into one matrix and could be used to simplify the calculation of transformations.</p> \\[ H = \\begin{bmatrix} R &amp; d \\\\ 0 &amp; 1 \\end{bmatrix}; \\;\\;\\;  R \\in \\mathcal{SO}(3), d \\in \\mathcal{R}^3 \\] <p>Using the factor that \\(R\\) is orthogonal, we can get the inverse transformation as</p> \\[ H^{-1} = \\begin{bmatrix} R^T &amp; -R^Td \\\\ 0 &amp; 1 \\end{bmatrix} \\] <p>In order to apply a homogeneous transformation, a column vector must be augmented</p> \\[ P^0 = \\begin{bmatrix} p^0 \\\\ 1 \\end{bmatrix}, P^1 = \\begin{bmatrix} p^1 \\\\ 1 \\end{bmatrix} \\] <p>Then we have the equivalent calculation with </p> \\[p^0 = R^0_1p^1 + d^0_1\\] <p>in the matrix form</p> \\[ P^0 = H^0_1P^1 \\]"},{"location":"robotics/modeling/rigid_body_motion/#composition-rule-for-homogeneous-transformations","title":"Composition rule for homogeneous transformations","text":"<p>Given a homogeneous transformation \\(H^0_1\\) relating two frames [1]:</p> <ul> <li>if a second rigid motion, represented by \\(H \\in \\mathcal{SE}(3)\\) is performed to the current frame, then </li> </ul> \\[ H^0_2 = H^0_1H^1_2 \\] <ul> <li>if the second rigid motion is performed relative to the fixed frame, then </li> </ul> \\[ H^0_2 = HH^0_1    \\]"},{"location":"robotics/modeling/rigid_body_motion/#rigid-body-motion-calculation-with-eigen","title":"Rigid-body Motion Calculation with Eigen","text":"<p>More relevant details can be found from Eigen offical documentation page [6][7][8] and this tutorial [9]. Here I only keep the most frequently used use cases. Source code in this section can be found on this GitHub repo.</p>"},{"location":"robotics/modeling/rigid_body_motion/#basic-operations-of-matricesvectors","title":"Basic Operations of Matrices/Vectors","text":"<pre><code>// matrix transpose and inverse\nEigen::MatrixXd R(3, 3);\nR &lt;&lt; 1, 2, 1,\n    2, 3, 4,\n    3, 1, 5;\n\n// element access\n// note: matrix index (row, column), index starts from 0\nstd::cout &lt;&lt; \"R(0,0) = \" &lt;&lt; R(0, 0) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"R(1,2) = \" &lt;&lt; R(1, 2) &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"R(2,2) = \" &lt;&lt; R(2, 2) &lt;&lt; std::endl;\n\nEigen::MatrixXd R_block = R.block(1, 1, 2, 2);\nstd::cout &lt;&lt; \"Take sub-matrix: \\n\" &lt;&lt; R_block &lt;&lt; std::endl;\n\nEigen::MatrixXd R_row = R.row(1);\nstd::cout &lt;&lt; \"Take row: \\n\" &lt;&lt; R_row &lt;&lt; std::endl;\n\nEigen::MatrixXd R_col = R.col(0);\nstd::cout &lt;&lt; \"Take column: \\n\" &lt;&lt; R_col &lt;&lt; std::endl;\n\n// multiplication\nEigen::Matrix3d R2 = Eigen::Matrix3d::Identity();\nauto R3 = R * R2;\nstd::cout &lt;&lt; \"R * R2: \\n\" &lt;&lt; R3 &lt;&lt; std::endl;\n\n// transpose and inverse\nEigen::MatrixXd R_transpose = R.transpose();\nEigen::MatrixXd R_inverse = R.inverse();\n\nstd::cout &lt;&lt; \"R: \\n\" &lt;&lt; R &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"R_transpose: \\n\" &lt;&lt; R_transpose &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"R_inverse: \\n\" &lt;&lt; R_inverse &lt;&lt; std::endl;\n\n// dot product and cross product:\nEigen::Vector3d v(1, 2, 3);\nEigen::Vector3d w(0, 1, 2);\n\ndouble v_dot_w = v.dot(w);\nEigen::Vector3d v_cross_w = v.cross(w);\n\nstd::cout &lt;&lt; \"v: \\n\" &lt;&lt; v &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"w: \\n\" &lt;&lt; w &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"v_dot_w: \\n\" &lt;&lt; v_dot_w &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"v_cross_w: \\n\" &lt;&lt; v_cross_w &lt;&lt; std::endl;\n</code></pre>"},{"location":"robotics/modeling/rigid_body_motion/#pose-representation-with-eigen","title":"Pose Representation with Eigen","text":"<p>The type \"Vector3f\" is a column vector in Eigen, thus it can be used directly to represent a position. Eigen also provides data types to present a rotation matrix, axis-angle and quaternion.</p> <p>Examples for the pose (position and orientation) representation with Eigen:</p> <pre><code>Eigen::Vector2d p2d(1.0, 2.0);\nstd::cout &lt;&lt; \"A point in 2d: \\n\" &lt;&lt; p2d &lt;&lt; std::endl;\n\nEigen::Vector3d p3d(1.0, 2.0, 3.0);\nstd::cout &lt;&lt; \"A point in 3d: \\n\" &lt;&lt; p3d &lt;&lt; std::endl;\n\nEigen::Matrix3d R;\nR &lt;&lt; 0, -1, 0, 1, 0, 0, 0, 0, 1;\nstd::cout &lt;&lt; \"A rotation matrix: \\n\" &lt;&lt; R &lt;&lt; std::endl;\n\nEigen::Quaterniond q_from_R(R);\nstd::cout &lt;&lt; \"A quaternion from rotation matrix: \\n\" &lt;&lt; q_from_R.coeffs() &lt;&lt; std::endl;\n\nEigen::Quaterniond q_unit = Eigen::Quaterniond::Identity();\nstd::cout &lt;&lt; \"A unit quaternion: \\n\" &lt;&lt; q_unit.coeffs() &lt;&lt; std::endl;\n\nEigen::Quaterniond q(2, 0, 1, -3);\nstd::cout &lt;&lt; \"A non-normalized quaternion: \\n\" &lt;&lt; q.coeffs() &lt;&lt; std::endl;\n\nq.normalize();\nstd::cout &lt;&lt; \"A normalized quaternion: \\n\" &lt;&lt; q.w() &lt;&lt; std::endl &lt;&lt; q.vec() &lt;&lt; std::endl;\n\nEigen::Matrix3d R_from_q = q.toRotationMatrix();\nstd::cout &lt;&lt; \"A rotation matrix from quaternion: \\n\" &lt;&lt; R_from_q &lt;&lt; std::endl;\n\nEigen::Matrix3f R_from_angleaxis;\nR_from_angleaxis = Eigen::AngleAxisf(0.25 * M_PI, Eigen::Vector3f::UnitX())\n    * Eigen::AngleAxisf(0.5 * M_PI, Eigen::Vector3f::UnitY())\n    * Eigen::AngleAxisf(0.33 * M_PI, Eigen::Vector3f::UnitZ());\nstd::cout &lt;&lt; \"A rotation matrix from angle-axis: \\n\" &lt;&lt; R_from_angleaxis &lt;&lt; std::endl;\n\nEigen::Quaternionf q_from_angleaxis(Eigen::AngleAxisf(0.33 * M_PI, Eigen::Vector3f::UnitZ()));\nstd::cout &lt;&lt; \"A quaternion from angle-axis: \\n\" &lt;&lt; q_from_angleaxis.coeffs() &lt;&lt; std::endl;\n</code></pre>"},{"location":"robotics/modeling/rigid_body_motion/#transformation-with-eigen","title":"Transformation with Eigen","text":""},{"location":"robotics/modeling/rigid_body_motion/#reference","title":"Reference","text":"<ul> <li>[1] Spong, M.W. and Hutchinson, S. and Vidyasagar, M. (2005). Robot Modeling and Control. Wiley.</li> <li>[2] Lynch, K. M., &amp; Park, F. C. (2017). Modern Robotics: Mechanics, Planning, and Control. Cambridge Univeristy Press.</li> <li>[3] https://eater.net/quaternions</li> <li>[4] https://www.anyleaf.org/blog/quaternions:-a-practical-guide</li> <li>[5] https://www.3dgep.com/understanding-quaternions/</li> <li>[6] https://eigen.tuxfamily.org/dox/group__QuickRefPage.html</li> <li>[7] https://eigen.tuxfamily.org/dox/group__TutorialGeometry.html</li> <li>[8] https://eigen.tuxfamily.org/dox/group__TutorialMatrixClass.html</li> <li>[9] https://www.cc.gatech.edu/classes/AY2015/cs4496_spring/Eigen.html</li> </ul>"},{"location":"robotics/ros/cyclone_dds/","title":"CycloneDDS Settings","text":""},{"location":"robotics/ros/cyclone_dds/#cyclonedds-configuration","title":"CycloneDDS configuration","text":"<p>You can apply changes to the CycloneDDS configuration by creating a file at <code>/etc/cyclonedds.xml</code> (or any other path you prefer).</p> <pre><code>sudo nano /etc/cyclonedds.xml\n</code></pre> <p>Then you can set the <code>CYCLONEDDS_URI</code> environment variable to the path of the configuration file.</p> <pre><code>export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp\nexport CYCLONEDDS_URI=file:///etc/cyclonedds.xml/cyclonedds.xml\n</code></pre> <p>After the changes are applied, you need to restart the ROS daemon.</p> <pre><code>ros2 daemon stop\n</code></pre> <p>Alternatively, you can search the daemon process in <code>htop</code> and kill it.</p> <pre><code>$ htop\n\n# press F3 to search, use keyword ros2cli.daemon\n# trigger a kill signal with F9, then signal type 9\n</code></pre>"},{"location":"robotics/ros/cyclone_dds/#traffic-on-the-loopback-interface","title":"Traffic on the loopback interface","text":"<p>According to this issue, the <code>ROS_LOCALHOST_ONLY</code> environment variable is not supported in CycloneDDS and it should not be set in your <code>~/.bashrc</code> file when you try to limit the traffic to the loopback interface.</p> <p>You may achieve this by specifying the CycloneDDS to only listen to traffic from <code>localhost</code>.</p> <p>This can be done by specifying the <code>lo</code> interface in the <code>cyclonedds.xml</code> file.</p> <pre><code>&lt;Interfaces&gt;\n    &lt;NetworkInterface name=\"lo\" priority=\"default\" multicast=\"default\" /&gt;\n&lt;/Interfaces&gt;\n</code></pre> <p>You also need to enable multicast on the <code>lo</code> interface.</p> <pre><code>sudo ip link set lo multicast on\n</code></pre> <p>You can also persist the multicast setting on the <code>lo</code> interface by adding a systemd service.</p> <pre><code>sudo nano /etc/systemd/system/lo-multicast.service\n</code></pre> <pre><code>[Unit]\nDescription=Enable Multicast on Loopback\n\n[Service]\nType=oneshot\nExecStart=/usr/sbin/ip link set lo multicast on\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"robotics/ros/cyclone_dds/#system-wide-network-settings","title":"System-wide network settings","text":"<p>You need to increase the maximum receive buffer size for network packets and set the IP fragmentation settings before you can apply the suggested CycloneDDS configuration.</p> <pre><code>sudo nano /etc/sysctl.d/10-cyclone-max.conf\n</code></pre> <p>Add the following content to the file.</p> <pre><code># Increase the maximum receive buffer size for network packets\nnet.core.rmem_max=2147483647  # 2 GiB, default is 208 KiB\n\n# IP fragmentation settings\nnet.ipv4.ipfrag_time=3  # in seconds, default is 30 s\nnet.ipv4.ipfrag_high_thresh=134217728  # 128 MiB, default is 256 KiB\n</code></pre> <p>Then you can apply the changes with the following command.</p> <pre><code>sudo sysctl -p --system\n</code></pre> <p>If you only want to apply the changes to the current session, you can use the following command</p> <pre><code># Increase the maximum receive buffer size for network packets\nsudo sysctl -w net.core.rmem_max=2147483647  # 2 GiB, default is 208 KiB\n\n# IP fragmentation settings\nsudo sysctl -w net.ipv4.ipfrag_time=3  # in seconds, default is 30 s\nsudo sysctl -w net.ipv4.ipfrag_high_thresh=134217728  # 128 MiB, default is 256 KiB\n</code></pre> <p>You may validate the changes with the following command.</p> <pre><code>user@pc$ sysctl net.core.rmem_max net.ipv4.ipfrag_time net.ipv4.ipfrag_high_thresh\nnet.core.rmem_max = 2147483647\nnet.ipv4.ipfrag_time = 3\nnet.ipv4.ipfrag_high_thresh = 134217728\n</code></pre>"},{"location":"robotics/ros/cyclone_dds/#suggested-cyclonedds-configuration","title":"Suggested CycloneDDS configuration","text":"<p>The following is a configuration file that is suggested by the Autoare Network Settings documentation.</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;\n&lt;CycloneDDS xmlns=\"https://cdds.io/config\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://cdds.io/config https://raw.githubusercontent.com/eclipse-cyclonedds/cyclonedds/master/etc/cyclonedds.xsd\"&gt;\n  &lt;Domain Id=\"any\"&gt;\n    &lt;General&gt;\n      &lt;Interfaces&gt;\n        &lt;NetworkInterface autodetermine=\"false\" name=\"lo\" priority=\"default\" multicast=\"default\" /&gt;\n      &lt;/Interfaces&gt;\n      &lt;AllowMulticast&gt;default&lt;/AllowMulticast&gt;\n      &lt;MaxMessageSize&gt;65500B&lt;/MaxMessageSize&gt;\n    &lt;/General&gt;\n    &lt;Internal&gt;\n      &lt;SocketReceiveBufferSize min=\"10MB\"/&gt;\n      &lt;Watermarks&gt;\n        &lt;WhcHigh&gt;500kB&lt;/WhcHigh&gt;\n      &lt;/Watermarks&gt;\n    &lt;/Internal&gt;\n  &lt;/Domain&gt;\n&lt;/CycloneDDS&gt;\n</code></pre>"},{"location":"robotics/ros/cyclone_dds/#reference","title":"Reference","text":"<ul> <li>[1] Autoare Network Settings</li> <li>[2] ROS2 DDS Tuning</li> </ul>"},{"location":"robotics/ros/ros2_cli_ref/","title":"ROS2 CLI Reference","text":""},{"location":"robotics/ros/ros2_cli_ref/#environment-variables","title":"Environment Variables","text":"<p>The following environment variables should have been set properly after a successful installation:</p> <pre><code>ROS_VERSION=2\nROS_PYTHON_VERSION=3\nROS_DISTRO=humble\n</code></pre> <ul> <li>To use a different domain ID</li> </ul> <p><pre><code>$ export ROS_DOMAIN_ID=&lt;your_domain_id&gt;\n</code></pre> Due to platform-specific constrains, a safe option of a domain ID is between 0 and 101 inclusively. All ROS 2 nodes use domain ID 0 by default. [1]</p> <ul> <li>To limit the ROS2 communication to localhost</li> </ul> <pre><code>$ export ROS_LOCALHOST_ONLY=1\n````\n\n## CLI Tools\n\n### ROS pkg\n\n```bash\n$ ros2 pkg create &lt;package_name&gt;\n$ ros2 pkg list\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#ros-node","title":"ROS node","text":"<pre><code>$ ros2 run &lt;package_name&gt; &lt;executable_name&gt;\n$ ros2 node list\n$ ros2 node info &lt;node_name&gt;\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#ros-lifecycle","title":"ROS lifecycle","text":"<pre><code># output a list of nodes with lifecycle\n$ ros2 lifecycle nodes\n# output a list of available transitions for a node\n$ ros2 lifecycle list &lt;node_name&gt;\n# get lifecycle state of a node\n$ ros2 lifecycle get &lt;node_name&gt;\n# trigger lifecycle state transition of a node\n$ ros2 lifecycle set &lt;node_name&gt; &lt;transition&gt;\n</code></pre> <p>Possible transitions to invoke are [4]:</p> <ul> <li>configure</li> <li>activate</li> <li>deactivate</li> <li>cleanup</li> <li>shutdown</li> </ul>"},{"location":"robotics/ros/ros2_cli_ref/#ros-daemon","title":"ROS daemon","text":"<pre><code>$ ros2 daemon start/status/stop\n</code></pre> <p>The ROS2 daemon is a node that helps to accelerate the node discovery process. It is not required to run ROS2 nodes but it makes the newly started node to discover other nodes faster, which is especially useful for CLI commands like \"ros2 node list\".</p>"},{"location":"robotics/ros/ros2_cli_ref/#ros-topic","title":"ROS topic","text":"<pre><code>$ ros2 topic list\n$ ros2 topic echo &lt;topic_name&gt;\n$ ros2 topic info/type/hz/bw/delay &lt;topic_name&gt;\n$ ros2 topic pub &lt;topic_name&gt; &lt;msg_type&gt; [arguments]\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#ros-service","title":"ROS service","text":"<pre><code>$ ros2 service list -t\n$ ros2 service type &lt;service_name&gt;\n$ ros2 service call &lt;service_name&gt; &lt;service_type&gt; [arguments]\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#ros-interface","title":"ROS interface","text":"<p>This set of commands is to check the ROS messages and services (as the interface between nodes)</p> <p><pre><code>$ ros2 interface list\n$ ros2 interface proto/show &lt;msg_type&gt;\n</code></pre> An example: <pre><code>$ ros2 interface show geometry_msgs/msg/Twist\n# This expresses velocity in free space broken into its linear and angular parts.\n\nVector3  linear\n    float64 x\n    float64 y\n    float64 z\nVector3  angular\n    float64 x\n    float64 y\n    float64 z\n</code></pre></p>"},{"location":"robotics/ros/ros2_cli_ref/#ros-param","title":"ROS param","text":"<pre><code>$ ros2 param list\n$ ros2 param get &lt;node_name&gt; &lt;parameter_name&gt;\n$ ros2 param set &lt;node_name&gt; &lt;parameter_name&gt; &lt;value&gt;\n</code></pre> <p>To handle parameter files:</p> <pre><code>$ ros2 param dump &lt;node_name&gt;\n$ ros2 param load &lt;node_name&gt; &lt;parameter_file&gt;\n</code></pre> <pre><code># example: dump parameters of a node to file\n$ ros2 param dump /turtlesim &gt; turtlesim.yaml\n$ ros2 param load /turtlesim turtlesim.yaml\n</code></pre> <p>To start the same node using your saved parameter values, use:</p> <p><pre><code>$ ros2 run &lt;package_name&gt; &lt;executable_name&gt; --ros-args --params-file &lt;file_name&gt;\n</code></pre> <pre><code># example: start turtlesim_node with turtlesim.yaml\n$ ros2 run turtlesim turtlesim_node --ros-args --params-file turtlesim.yaml\n</code></pre></p>"},{"location":"robotics/ros/ros2_cli_ref/#ros-action","title":"ROS action","text":"<pre><code>$ ros2 action list [-t]\n$ ros2 action info &lt;action_name&gt;\n$ ros2 action send_goal &lt;action_name&gt; &lt;action_type&gt; &lt;values&gt;\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#ros-bag","title":"ROS bag","text":"<pre><code>$ ros2 bag record &lt;topic_name&gt;\n$ ros2 bag info &lt;bag_file_name&gt;\n$ ros2 bag play &lt;bag_file_name&gt;\n</code></pre> <pre><code># commonly used arguments\n$ ros2 bag record -a -o &lt;bag_file_name&gt;\n$ ros2 bag play -l &lt;bag_file_name&gt;\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#ros-multicast","title":"ROS multicast","text":"<pre><code>$ ros2 multicast receive/send\n</code></pre> <p>This command pair is useful for testing if UDP multicast is working properly. You open one terminal and run \"ros2 multicast receive\" and then open another terminal and run \"ros2 multicast send\". If the send command is successful, you should see the message in the receive terminal.</p> <p>On Linux, if the multicast communication is not successful, try to run the following command to enable multicast on the interface. </p> <pre><code>$ sudo ip link set &lt;interface_name&gt; multicast on\n</code></pre> <p>And you may also need to update the firewall rules to allow multicast traffic. [3]</p> <pre><code>$ sudo ufw allow in proto udp to 224.0.0.0/4\n$ sudo ufw allow in proto udp from 224.0.0.0/4\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#build-tools-colcon","title":"Build Tools: colcon","text":""},{"location":"robotics/ros/ros2_cli_ref/#build-workspace","title":"Build workspace","text":"<pre><code>$ colcon build --symlink-install\n# build the selected package only\n$ colcon build --symlink-install --packages-select &lt;package_name&gt;\n# build the selected package and its dependencies\n$ colcon build --symlink-install --packages-up-to &lt;package_name&gt;\n# build the selected package and packages that depends on it\n$ colcon build --symlink-install --packages-above &lt;package_name&gt;\n</code></pre> <p>The \"--symlink-install\" option is to create a symlink to the build directory instead of copying the files. \"This allows the installed files to be changed by changing the files in the source space (e.g. Python files or other not compiled resourced) for faster iteration.\"</p> <p>To print build output messages to stdout/stderr directly</p> <pre><code>$ colcon build --event-handlers console_direct+ --symlink-install \n$ colcon build --event-handlers console_cohesion+ --symlink-install \n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#check-dependencies","title":"Check dependencies","text":"<pre><code># generate a graph of package dependencies\n$ colcon graph --dot --packages-up-to &lt;package_name&gt; | dot -Tpng -o graph.png\n# generate a list of dependencies\n$ colcon list --packages-up-to &lt;package_name&gt; --names-only\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#run-tests","title":"Run tests","text":"<p>To run tests</p> <pre><code>$ colcon test --ctest-args tests [package_selection_args]\n# test selected package\n$ colcon test --ctest-args tests --packages-select my_package_to_test\n</code></pre> <p>To examine test results</p> <pre><code>$ colcon test-result --all\n$ colcon test-result --all --verbose\n</code></pre>"},{"location":"robotics/ros/ros2_cli_ref/#reference","title":"Reference","text":"<ul> <li>[1] https://docs.ros.org/en/humble/Concepts/About-Domain-ID.html</li> <li>[2] https://github.com/ubuntu-robotics/ros2_cheats_sheet</li> <li>[3] https://docs.ros.org/en/rolling/How-To-Guides/Installation-Troubleshooting.html#enable-multicast</li> <li>[4] https://github.com/ros2/demos/blob/humble/lifecycle/README.rst</li> </ul>"},{"location":"robotics/ros/ros2_code_sample/","title":"ROS2 Code Sample","text":"<p>This note contains code samples from ROS Humble for quick reference. The code can be found from the Github repository ros2_sample. Most of them are from the ROS official documentation. More references can be found from the official examples repository ros2/examples</p>"},{"location":"robotics/ros/ros2_code_sample/#python-launch-file","title":"Python Launch File","text":"<p>More information about ROS2 launch can be found at ROS2 Launch</p>"},{"location":"robotics/ros/ros2_code_sample/#sample-my_applaunchpy","title":"Sample my_app.launch.py","text":"<pre><code>from launch import LaunchDescription\n\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.actions import ExecuteProcess\nfrom launch_ros.actions import Node\n\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.launch_description_sources import FrontendLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration\nfrom launch.substitutions import PathJoinSubstitution\nfrom launch.substitutions import (EnvironmentVariable, FindExecutable)\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    ## arguments\n\n    ## local variables\n    map_path = PathJoinSubstitution([\n                    FindPackageShare('robot_map'),\n                    \"map\",\n                    \"my_office\"\n                ])\n\n    rviz_config_file = PathJoinSubstitution([\n                    FindPackageShare('robot_bringup'),\n                    \"rviz\",\n                    \"autoware_default_view.rviz\"\n                ])\n\n    ## actions\n    launch_py_launch = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n                PathJoinSubstitution([\n                    FindPackageShare('robot_module'),\n                    \"launch\",\n                    \"module_launch.launch.py\"\n                ])\n            ]),    \n        launch_arguments={\n            'start_rviz2': 'false'\n        }.items())\n\n    launch_xml_launch = IncludeLaunchDescription(\n        FrontendLaunchDescriptionSource([\n                PathJoinSubstitution([\n                    FindPackageShare('robot_nav'),\n                    \"launch\",\n                    'subsystem',\n                    \"map.launch.xml\"\n                ])\n            ]),    \n        launch_arguments={\n            'map_path': map_path,\n        }.items())\n\n    start_rviz_node = Node(\n        package='rviz2',\n        executable='rviz2',\n        name='rviz2_sample',\n        arguments=['-d', rviz_config_file],\n        output='screen')\n\n    ## LaunchDescription\n    return LaunchDescription([\n        launch_py_launch,\n        launch_xml_launch,\n        start_rviz_node\n    ])\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#cmake-with-ament_cmake","title":"Cmake with ament_cmake","text":""},{"location":"robotics/ros/ros2_code_sample/#sample-cmakeliststxt","title":"Sample CMakeLists.txt","text":"<p>ament_cmake has defined many extension functions to the standar CMake. In general, you should follow the template to make sure everything is set up properly.</p> <pre><code>cmake_minimum_required(VERSION 3.10.2)\nproject(my_project VERSION 0.1.0)\n\nif (CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif ()\n\n## Generate symbols for IDE indexer\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n\n## Set compiler to use c++ 14 features\nset(CMAKE_CXX_STANDARD 14)\nset(CMAKE_CXX_EXTENSIONS OFF)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\n\n## Additional cmake module path\nlist(APPEND CMAKE_PREFIX_PATH \"/usr/lib/${CMAKE_SYSTEM_PROCESSOR}-linux-gnu/cmake\")\nlist(APPEND CMAKE_PREFIX_PATH \"/opt/my_dep_lib/lib/cmake\")\n\n## Find depdenencies and add targets\n# standard cmake dependencies\nfind_package(Eigen3 REQUIRED)\n\n# ros2 dependencies\nfind_package(ament_cmake REQUIRED)\n\nset(ros_dependencies\n    rclcpp)\nforeach (dep IN ITEMS ${ros_dependencies})\n  find_package(${dep} REQUIRED)\nendforeach ()\n\n# my targets\nadd_library(my_library SHARED\n    src/my_source.cpp)\ntarget_link_libraries(my_library PUBLIC Eigen3::Eigen)\nament_target_dependencies(my_library PUBLIC ${ros_dependencies})\ntarget_include_directories(my_library PUBLIC\n    \"$&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include&gt;\"\n    \"$&lt;INSTALL_INTERFACE:include/${PROJECT_NAME}&gt;\")\n\nadd_executable(my_executable src/main.cpp)\ntarget_link_libraries(my_executable PUBLIC my_library)\n\n## The install and export configuration\n# library targets that external packages may use \ninstall(TARGETS my_library\n  EXPORT export_${PROJECT_NAME}\n  LIBRARY DESTINATION lib\n  ARCHIVE DESTINATION lib\n  RUNTIME DESTINATION bin)\n\ninstall(DIRECTORY include/\n  DESTINATION include/${PROJECT_NAME})\n\ninstall(DIRECTORY launch \n  DESTINATION share/${PROJECT_NAME})\n\n# executable targets that you want to start with \"ros2 run\"\ninstall(TARGETS my_executable\n    DESTINATION lib/${PROJECT_NAME})\n\nament_export_targets(export_${PROJECT_NAME} HAS_LIBRARY_TARGET)\nament_export_dependencies(${ros_dependencies} other_sys_dependencies)\n\nament_package()\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#publishersubscriber","title":"Publisher/Subscriber","text":""},{"location":"robotics/ros/ros2_code_sample/#create-a-ros2-publisher","title":"Create a ROS2 publisher","text":"<pre><code>#include &lt;chrono&gt;\n#include &lt;functional&gt;\n#include &lt;memory&gt;\n#include &lt;string&gt;\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/string.hpp\"\n\nusing namespace std::chrono_literals;\n\n/* This example creates a subclass of Node and uses std::bind() to register a\n * member function as a callback from the timer. */\n\nclass MinimalPublisher : public rclcpp::Node {\n public:\n  MinimalPublisher() : Node(\"minimal_publisher\"), count_(0) {\n    publisher_ = this-&gt;create_publisher&lt;std_msgs::msg::String&gt;(\"topic\", 10);\n    timer_ = this-&gt;create_wall_timer(\n        500ms, std::bind(&amp;MinimalPublisher::timer_callback, this));\n  }\n\n private:\n  void timer_callback() {\n    auto message = std_msgs::msg::String();\n    message.data = \"Hello, world! \" + std::to_string(count_++);\n    RCLCPP_INFO(this-&gt;get_logger(), \"Publishing: '%s'\", message.data.c_str());\n    publisher_-&gt;publish(message);\n  }\n  rclcpp::TimerBase::SharedPtr timer_;\n  rclcpp::Publisher&lt;std_msgs::msg::String&gt;::SharedPtr publisher_;\n  size_t count_;\n};\n\nint main(int argc, char* argv[]) {\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;MinimalPublisher&gt;());\n  rclcpp::shutdown();\n  return 0;\n}\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#create-a-ros2-subscriber","title":"Create a ROS2 subscriber","text":"<pre><code>#include &lt;memory&gt;\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/string.hpp\"\nusing std::placeholders::_1;\n\nclass MinimalSubscriber : public rclcpp::Node {\n public:\n  MinimalSubscriber() : Node(\"minimal_subscriber\") {\n    subscription_ = this-&gt;create_subscription&lt;std_msgs::msg::String&gt;(\n        \"topic\", 10, std::bind(&amp;MinimalSubscriber::topic_callback, this, _1));\n  }\n\n private:\n  void topic_callback(const std_msgs::msg::String&amp; msg) const {\n    RCLCPP_INFO(this-&gt;get_logger(), \"I heard: '%s'\", msg.data.c_str());\n  }\n  rclcpp::Subscription&lt;std_msgs::msg::String&gt;::SharedPtr subscription_;\n};\n\nint main(int argc, char* argv[]) {\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;MinimalSubscriber&gt;());\n  rclcpp::shutdown();\n  return 0;\n}\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#serviceclient","title":"Service/Client","text":""},{"location":"robotics/ros/ros2_code_sample/#create-a-ros2-server","title":"Create a ROS2 server","text":"<pre><code>#include \"rclcpp/rclcpp.hpp\"\n#include \"example_interfaces/srv/add_two_ints.hpp\"\n\n#include &lt;memory&gt;\n\nvoid add(\n    const std::shared_ptr&lt;example_interfaces::srv::AddTwoInts::Request&gt; request,\n    std::shared_ptr&lt;example_interfaces::srv::AddTwoInts::Response&gt; response) {\n  response-&gt;sum = request-&gt;a + request-&gt;b;\n  RCLCPP_INFO(rclcpp::get_logger(\"rclcpp\"),\n              \"Incoming request\\na: %ld\"\n              \" b: %ld\",\n              request-&gt;a, request-&gt;b);\n  RCLCPP_INFO(rclcpp::get_logger(\"rclcpp\"), \"sending back response: [%ld]\",\n              (long int)response-&gt;sum);\n}\n\nint main(int argc, char **argv) {\n  rclcpp::init(argc, argv);\n\n  std::shared_ptr&lt;rclcpp::Node&gt; node =\n      rclcpp::Node::make_shared(\"add_two_ints_server\");\n\n  rclcpp::Service&lt;example_interfaces::srv::AddTwoInts&gt;::SharedPtr service =\n      node-&gt;create_service&lt;example_interfaces::srv::AddTwoInts&gt;(\"add_two_ints\",\n                                                                &amp;add);\n\n  RCLCPP_INFO(rclcpp::get_logger(\"rclcpp\"), \"Ready to add two ints.\");\n\n  rclcpp::spin(node);\n  rclcpp::shutdown();\n}\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#create-a-ros2-client","title":"Create a ROS2 client","text":"<pre><code>#include \"rclcpp/rclcpp.hpp\"\n#include \"example_interfaces/srv/add_two_ints.hpp\"\n\n#include &lt;chrono&gt;\n#include &lt;cstdlib&gt;\n#include &lt;memory&gt;\n\nusing namespace std::chrono_literals;\n\nint main(int argc, char **argv) {\n  rclcpp::init(argc, argv);\n\n  if (argc != 3) {\n    RCLCPP_INFO(rclcpp::get_logger(\"rclcpp\"), \"usage: add_two_ints_client X Y\");\n    return 1;\n  }\n\n  std::shared_ptr&lt;rclcpp::Node&gt; node =\n      rclcpp::Node::make_shared(\"add_two_ints_client\");\n  rclcpp::Client&lt;example_interfaces::srv::AddTwoInts&gt;::SharedPtr client =\n      node-&gt;create_client&lt;example_interfaces::srv::AddTwoInts&gt;(\"add_two_ints\");\n\n  auto request =\n      std::make_shared&lt;example_interfaces::srv::AddTwoInts::Request&gt;();\n  request-&gt;a = atoll(argv[1]);\n  request-&gt;b = atoll(argv[2]);\n\n  while (!client-&gt;wait_for_service(1s)) {\n    if (!rclcpp::ok()) {\n      RCLCPP_ERROR(rclcpp::get_logger(\"rclcpp\"),\n                   \"Interrupted while waiting for the service. Exiting.\");\n      return 0;\n    }\n    RCLCPP_INFO(rclcpp::get_logger(\"rclcpp\"),\n                \"service not available, waiting again...\");\n  }\n\n  auto result = client-&gt;async_send_request(request);\n  // Wait for the result.\n  if (rclcpp::spin_until_future_complete(node, result) ==\n      rclcpp::FutureReturnCode::SUCCESS) {\n    RCLCPP_INFO(rclcpp::get_logger(\"rclcpp\"), \"Sum: %ld\", result.get()-&gt;sum);\n  } else {\n    RCLCPP_ERROR(rclcpp::get_logger(\"rclcpp\"),\n                 \"Failed to call service add_two_ints\");\n  }\n\n  rclcpp::shutdown();\n  return 0;\n}\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#custom-ros2-msgsrvaction","title":"Custom ROS2 msg/srv/action","text":"<p>By convension, the custom type definition files are put in msg/srv/action folder inside the package respectively.</p>"},{"location":"robotics/ros/ros2_code_sample/#nummsg","title":"Num.msg","text":"<pre><code>int64 num\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#addtreeintssrv","title":"AddTreeInts.srv","text":"<pre><code>int64 a\nint64 b\nint64 c\n---\nint64 sum\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#cmakeliststxt","title":"CMakeLists.txt","text":"<pre><code>find_package(geometry_msgs REQUIRED)\nfind_package(rosidl_default_generators REQUIRED)\n\n# the library name must match ${PROJECT_NAME}\nrosidl_generate_interfaces(${PROJECT_NAME}\n  \"msg/Num.msg\"\n  \"msg/Sphere.msg\"\n  \"srv/AddThreeInts.srv\"\n  DEPENDENCIES geometry_msgs # Add packages that above messages depend on, in this case geometry_msgs for Sphere.msg\n)\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#packagexml","title":"package.xml","text":"<pre><code>&lt;depend&gt;geometry_msgs&lt;/depend&gt;\n\n&lt;build_depend&gt;rosidl_default_generators&lt;/build_depend&gt;\n\n&lt;exec_depend&gt;rosidl_default_runtime&lt;/exec_depend&gt;\n\n&lt;member_of_group&gt;rosidl_interface_packages&lt;/member_of_group&gt;\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#handle-parameters","title":"Handle Parameters","text":""},{"location":"robotics/ros/ros2_code_sample/#sample-parameter-file","title":"Sample parameter file","text":"<pre><code>/lidar_ns:\n  lidar_node_name:\n    ros__parameters:\n      lidar_name: foo\n      id: 10\nimu:\n  ros__parameters:\n    ports: [2438, 2439, 2440]\n/**:\n  ros__parameters:\n    debug: true\n</code></pre> <p>The use of wildcards (/**) to indicate that the parameters listed in this section are set on any node in any namespace.</p>"},{"location":"robotics/ros/ros2_code_sample/#set-parameters-from-command-line","title":"Set parameters from command line","text":"<pre><code>$ ros2 run package_name executable_name --ros-args -p param_name:=param_value\n# example\n$ ros2 run demo_nodes_cpp parameter_blackboard --ros-args -p some_int:=42 -p \"a_string:=Hello world\" -p \"some_lists.some_integers:=[1, 2, 3, 4]\" -p \"some_lists.some_doubles:=[3.14, 2.718]\"\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#set-parameters-from-launch-file","title":"Set parameters from Launch file","text":"<pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package=\"params\",\n            executable=\"param_node\",\n            name=\"param_node\",\n            output=\"screen\",\n            emulate_tty=True,\n            parameters=[\n                {\"my_parameter\": \"my_value\"}\n            ]\n        )\n    ])\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#load-parameter-file-on-node-startup","title":"Load parameter file on node startup","text":"<pre><code>$ ros2 run &lt;package_name&gt; &lt;executable_name&gt; --ros-args --params-file &lt;file_name&gt;\n# example\n$ ros2 run turtlesim turtlesim_node --ros-args --params-file turtlesim.yaml\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#load-parameter-file-from-launch-file","title":"Load parameter file from Launch file","text":"<pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\nfrom launch.substitutions import PathJoinSubstitution\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n\n    vesc_config=PathJoinSubstitution([\n        FindPackageShare('vesc_driver'),\n        \"params\",\n        \"vesc_config.yaml\"\n    ])\n\n    return LaunchDescription([\n        Node(\n            package='vesc_driver',\n            executable='vesc_driver_can_node',\n            name='vesc_driver_can_node',\n            parameters=[vesc_config]\n        )\n    ])\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#use-parameters-in-a-c-class","title":"Use parameters in a C++ class","text":"<pre><code>#include &lt;chrono&gt;\n#include &lt;functional&gt;\n#include &lt;string&gt;\n\n#include &lt;rclcpp/rclcpp.hpp&gt;\n\nusing namespace std::chrono_literals;\n\nclass MinimalParam : public rclcpp::Node\n{\npublic:\n  MinimalParam()\n  : Node(\"minimal_param_node\")\n  {\n    // simple paramter\n    this-&gt;declare_parameter(\"my_parameter\", \"world\");\n\n    // specify parameter descriptor\n    auto param_desc = rcl_interfaces::msg::ParameterDescriptor{};\n    param_desc.description = \"This parameter is mine!\";\n\n    this-&gt;declare_parameter(\"my_parameter2\", \"world\", param_desc);\n\n    timer_ = this-&gt;create_wall_timer(\n      1000ms, std::bind(&amp;MinimalParam::timer_callback, this));\n  }\n\n  void timer_callback()\n  {\n    std::string my_param =\n      this-&gt;get_parameter(\"my_parameter\").get_parameter_value().get&lt;std::string&gt;();\n\n    RCLCPP_INFO(this-&gt;get_logger(), \"Hello %s!\", my_param.c_str());\n\n    std::vector&lt;rclcpp::Parameter&gt; all_new_parameters{rclcpp::Parameter(\"my_parameter\", \"world\")};\n    this-&gt;set_parameters(all_new_parameters);\n  }\n\nprivate:\n  rclcpp::TimerBase::SharedPtr timer_;\n};\n\nint main(int argc, char ** argv)\n{\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;MinimalParam&gt;());\n  rclcpp::shutdown();\n  return 0;\n}\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#composable-nodes","title":"Composable Nodes","text":""},{"location":"robotics/ros/ros2_code_sample/#create-a-composable-publisher","title":"Create a composable publisher","text":"<pre><code>#ifndef MINIMAL_COMPOSITION__PUBLISHER_NODE_HPP_\n#define MINIMAL_COMPOSITION__PUBLISHER_NODE_HPP_\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/string.hpp\"\n#include \"minimal_composition/visibility.h\"\n\nclass PublisherNode : public rclcpp::Node\n{\npublic:\n  PublisherNode(rclcpp::NodeOptions options);\n\nprivate:\n  void on_timer();\n  size_t count_;\n  rclcpp::Publisher&lt;std_msgs::msg::String&gt;::SharedPtr publisher_;\n  rclcpp::TimerBase::SharedPtr timer_;\n};\n\n#endif  // MINIMAL_COMPOSITION__PUBLISHER_NODE_HPP_\n</code></pre> <pre><code>#include &lt;chrono&gt;\n\n#include \"minimal_composition/publisher_node.hpp\"\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/string.hpp\"\n\nusing namespace std::chrono_literals;\n\nPublisherNode::PublisherNode(rclcpp::NodeOptions options)\n: Node(\"publisher_node\", options), count_(0)\n{\n  publisher_ = create_publisher&lt;std_msgs::msg::String&gt;(\"topic\", 10);\n  timer_ = create_wall_timer(\n    500ms, std::bind(&amp;PublisherNode::on_timer, this));\n}\n\nvoid PublisherNode::on_timer()\n{\n  auto message = std_msgs::msg::String();\n  message.data = \"Hello, world! \" + std::to_string(count_++);\n  RCLCPP_INFO(this-&gt;get_logger(), \"Publisher: '%s'\", message.data.c_str());\n  publisher_-&gt;publish(message);\n}\n\n#include \"rclcpp_components/register_node_macro.hpp\"\n\nRCLCPP_COMPONENTS_REGISTER_NODE(PublisherNode)\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#packagexml-for-the-package","title":"Package.xml for the package","text":"<pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;?xml-model href=\"http://download.ros.org/schema/package_format2.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?&gt;\n&lt;package format=\"2\"&gt;\n  &lt;name&gt;examples_rclcpp_minimal_composition&lt;/name&gt;\n  &lt;version&gt;0.15.1&lt;/version&gt;\n  &lt;description&gt;Minimalist examples of composing nodes in the same\n  process&lt;/description&gt;\n  &lt;maintainer email=\"sloretz@openrobotics.org\"&gt;Shane Loretz&lt;/maintainer&gt;\n  &lt;maintainer email=\"aditya.pande@openrobotics.org\"&gt;Aditya Pande&lt;/maintainer&gt;\n  &lt;license&gt;Apache License 2.0&lt;/license&gt;\n  &lt;author&gt;Mikael Arguedas&lt;/author&gt;\n  &lt;author&gt;Morgan Quigley&lt;/author&gt;\n  &lt;author email=\"jacob@openrobotics.org\"&gt;Jacob Perron&lt;/author&gt;\n\n  &lt;buildtool_depend&gt;ament_cmake&lt;/buildtool_depend&gt;\n\n  &lt;build_depend&gt;rclcpp&lt;/build_depend&gt;\n  &lt;build_depend&gt;rclcpp_components&lt;/build_depend&gt;\n  &lt;build_depend&gt;std_msgs&lt;/build_depend&gt;\n\n  &lt;exec_depend&gt;rclcpp&lt;/exec_depend&gt;\n  &lt;exec_depend&gt;rclcpp_components&lt;/exec_depend&gt;\n  &lt;exec_depend&gt;std_msgs&lt;/exec_depend&gt;\n\n  &lt;test_depend&gt;ament_lint_auto&lt;/test_depend&gt;\n  &lt;test_depend&gt;ament_lint_common&lt;/test_depend&gt;\n\n  &lt;export&gt;\n    &lt;build_type&gt;ament_cmake&lt;/build_type&gt;\n  &lt;/export&gt;\n&lt;/package&gt;\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#cmakeliststxt-for-the-package","title":"CMakeLists.txt for the package","text":"<p>The below cmake file provides a complete example of how to build composable nodes. Please refer to <code>Sample CMakeLists.txt</code> above for the general cmake setup for ROS2 packages.</p> <pre><code>cmake_minimum_required(VERSION 3.5)\nproject(examples_rclcpp_minimal_composition)\n\n# Default to C++14\nif(NOT CMAKE_CXX_STANDARD)\n  set(CMAKE_CXX_STANDARD 14)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\nfind_package(rclcpp_components REQUIRED)\nfind_package(std_msgs REQUIRED)\n\ninclude_directories(include)\n\nadd_library(composition_nodes SHARED\n            src/publisher_node.cpp\n            src/subscriber_node.cpp)\ntarget_compile_definitions(composition_nodes\n  PRIVATE \"MINIMAL_COMPOSITION_DLL\")\nament_target_dependencies(composition_nodes rclcpp rclcpp_components std_msgs)\n\nrclcpp_components_register_node(composition_nodes\n  PLUGIN \"PublisherNode\"\n  EXECUTABLE publisher_node\n)\n\ninstall(TARGETS\n  composition_nodes publisher_node\n  ARCHIVE DESTINATION lib\n  LIBRARY DESTINATION lib\n  RUNTIME DESTINATION bin)\n\ninstall(TARGETS\n  composition_publisher\n  composition_subscriber\n  composition_composed\n  DESTINATION lib/${PROJECT_NAME})\n\nif(BUILD_TESTING)\n  find_package(ament_lint_auto REQUIRED)\n  ament_lint_auto_find_test_dependencies()\nendif()\n\nament_package()\n</code></pre>"},{"location":"robotics/ros/ros2_code_sample/#reference","title":"Reference","text":"<ul> <li>https://docs.ros.org/en/humble/How-To-Guides/Ament-CMake-Documentation.html</li> </ul>"},{"location":"robotics/ros/ros2_control/","title":"ROS2 Control","text":"<ul> <li>https://github.com/ros-controls/roadmap/tree/master/design_drafts</li> <li>https://github.com/ros-controls/roscon2022_workshop/tree/5-simulation</li> <li>https://github.com/ros-controls/ros2_control_demos</li> </ul>"},{"location":"robotics/ros/ros2_launch/","title":"ROS2 Launch","text":""},{"location":"robotics/ros/ros2_launch/#concepts","title":"Concepts","text":"<p>The launch and launch_ros packages provide a set of API to model the configuration and starting of ROS2 nodes. The \"launch\" package provides the base classes and the \"launch_ros\" package provides ROS2 specific extensions.</p> <ul> <li>launch.LaunchDescription: this is the main class used to describe the launch configuration. It is a list of \"actions\" that are executed sequentially. The launch configuration is executed by the launch service.</li> <li>launch.Action: this class represents the various user intentions.<ul> <li>launch.actions.IncludeLaunchDescription: the action to include another launch file</li> <li>launch.actions.DeclareLaunchArgument: the action to declare a launch argument</li> <li>launch.actions.SetEnvironmentVariable: the action to set an environment variable by name</li> <li>launch.actions.AppendEnvironmentVariable: the action to append a value to an environment variable</li> <li>launch.actions.GroupAction: the action to group other actions, and it can be associated with conditions</li> <li>launch.actions.TimerAction: the action to start other actions after a specified amount of time</li> <li>launch.actions.ExecuteProcess: the action to execute a process with path and argutments</li> </ul> </li> </ul> <p>There are a few more actions defined in the launch package and you can find more information in the documentation. A commonly used action extended from launch and implemented in launch_ros is from launch_ros.actions.Node. You can express the intention of starting a ROS node with this action.</p> <p>You can expect the outline of a typical ROS2 launch file to be like: </p> <pre><code>from launch import LaunchDescription\nfrom launch.actions import ABC\nfrom launch.actions import XYZ\n\ndef generate_launch_description():\n    action_abc = ABC()\n    action_xyz = XYZ()\n\n    ld = LaunchDescription()\n    ld.add_action(action_abc)\n    ld.add_action(action_xyz)\n\n    return ld\n</code></pre> <ul> <li>launch.Substitution: this class represents the various ways to substitute a string. The substitution is performed when the launch configuration is executed by the launch service. Substitutions can help to make the launch configuration more flexible and easier to be reused.<ul> <li>launch.substitutions.Text: the substitution to get the given string when evaluated</li> <li>launch.substitutions.LaunchConfiguration: the substitution to get the value of a launch argument</li> <li>launch.substitutions.EnvironmentVariable: the substitution to get the value of an environment variable</li> </ul> </li> </ul> <p>In most cases, what you need to do to create a launch file is to use substitutions to construct actions and then use actions to construct the launch description.</p> <ul> <li>launch.LaunchService: \"Launch descriptions, and the actions contained therein, can either be introspected directly or launched by a launch.LaunchService. A launch service is a long running activity that handles the event loop and dispatches actions.\"[3] This means other than creating a LaunchDescription() object and launching with \"ros2 launch\", you can also manually create a LaunchService object and run with the LaunchDescription object from a plain Python script.</li> <li>launch.EventHandler: \"Event handlers can be registered for specific events and can be useful for monitoring the state of processes.\" [4] Predefined event handlers from the launch package includes (but not limited to):<ul> <li>launch.event_handlers.OnExecutionComplete</li> <li>launch.event_handlers.OnProcessStart</li> <li>launch.event_handlers.OnProcessExit</li> <li>launch.event_handlers.OnProcessIO</li> <li>launch.event_handlers.OnShutdown</li> </ul> </li> </ul>"},{"location":"robotics/ros/ros2_launch/#sample-launch","title":"Sample Launch","text":"<p>The following launch file is copied from the ROS2 documentation [5] with minor modifications.</p> <pre><code># example.launch.py\n\nimport os\n\nfrom launch import LaunchDescription\n\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.actions import GroupAction\n\nfrom launch.substitutions import LaunchConfiguration\nfrom launch.substitutions import TextSubstitution\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom ament_index_python import get_package_share_directory\n\nfrom launch_ros.actions import Node\nfrom launch_ros.actions import PushRosNamespace\n\n\ndef generate_launch_description():\n\n    # args that can be set from the command line or a default will be used\n    background_r_launch_arg = DeclareLaunchArgument(\n        \"background_r\", default_value=TextSubstitution(text=\"0\")\n    )\n    background_g_launch_arg = DeclareLaunchArgument(\n        \"background_g\", default_value=TextSubstitution(text=\"255\")\n    )\n    background_b_launch_arg = DeclareLaunchArgument(\n        \"background_b\", default_value=TextSubstitution(text=\"0\")\n    )\n    chatter_ns_launch_arg = DeclareLaunchArgument(\n        \"chatter_ns\", default_value=TextSubstitution(text=\"my/chatter/ns\")\n    )\n\n    # include another launch file\n    launch_include = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource(\n            os.path.join(\n                get_package_share_directory('demo_nodes_cpp'),\n                'launch/topics/talker_listener.launch.py'))\n    )\n    # include another launch file in the chatter_ns namespace\n    launch_include_with_namespace = GroupAction(\n        actions=[\n            # push_ros_namespace to set namespace of included nodes\n            PushRosNamespace('chatter_ns'),\n            IncludeLaunchDescription(\n                PythonLaunchDescriptionSource(\n                    os.path.join(\n                        get_package_share_directory('demo_nodes_cpp'),\n                        'launch/topics/talker_listener.launch.py'))\n            ),\n        ]\n    )\n\n    # start a turtlesim_node in the turtlesim1 namespace\n    turtlesim_node = Node(\n            package='turtlesim',\n            namespace='turtlesim1',\n            executable='turtlesim_node',\n            name='sim'\n        )\n\n    # start another turtlesim_node in the turtlesim2 namespace\n    # and use args to set parameters\n    turtlesim_node_with_parameters = Node(\n            package='turtlesim',\n            namespace='turtlesim2',\n            executable='turtlesim_node',\n            name='sim',\n            parameters=[{\n                \"background_r\": LaunchConfiguration('background_r'),\n                \"background_g\": LaunchConfiguration('background_g'),\n                \"background_b\": LaunchConfiguration('background_b'),\n            }]\n        )\n\n    # perform remap so both turtles listen to the same command topic\n    forward_turtlesim_commands_to_second_turtlesim_node = Node(\n            package='turtlesim',\n            executable='mimic',\n            name='mimic',\n            remappings=[\n                ('/input/pose', '/turtlesim1/turtle1/pose'),\n                ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n            ]\n        )\n\n    return LaunchDescription([\n        background_r_launch_arg,\n        background_g_launch_arg,\n        background_b_launch_arg,\n        chatter_ns_launch_arg,\n        launch_include,\n        launch_include_with_namespace,\n        turtlesim_node,\n        turtlesim_node_with_parameters,\n        forward_turtlesim_commands_to_second_turtlesim_node,\n    ])\n</code></pre>"},{"location":"robotics/ros/ros2_launch/#typical-use-cases","title":"Typical Use Cases","text":""},{"location":"robotics/ros/ros2_launch/#launch-a-node","title":"Launch a node","text":"<pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='turtlesim',\n            namespace='turtlesim1',\n            executable='turtlesim_node',\n            name='sim',\n            output='screen',\n            remapping=[\n                ('origin1', 'other1'),\n                ('origin2', 'other2')\n            ]\n        )\n    ])\n</code></pre> <p>You can find more arguments to the Node() class in the source code [7].</p>"},{"location":"robotics/ros/ros2_launch/#launch-a-launch-file","title":"Launch a launch file","text":"<pre><code>from launch import LaunchDescription\n\nfrom launch.actions import IncludeLaunchDescription\n\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import PathJoinSubstitution, TextSubstitution\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    colors = {\n        'background_r': '200'\n    }\n\n    return LaunchDescription([\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource([\n                PathJoinSubstitution([\n                    FindPackageShare('launch_tutorial'),\n                    'example_substitutions.launch.py'\n                ])\n            ]),\n            launch_arguments={\n                'turtlesim_ns': 'turtlesim2',\n                'use_provided_red': 'True',\n                'new_background_r': TextSubstitution(text=str(colors['background_r']))\n            }.items()\n        )\n    ])\n</code></pre>"},{"location":"robotics/ros/ros2_launch/#reference","title":"Reference","text":"<ul> <li>[1] https://docs.ros.org/en/humble/Concepts/About-Domain-ID.html</li> <li>[2] https://github.com/chargerKong/learning_ros2_launch_by_example</li> <li>[3] https://github.com/ros2/launch/blob/humble/launch/doc/source/architecture.rst</li> <li>[4] https://docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Using-Event-Handlers.html#</li> <li>[5] https://docs.ros.org/en/humble/How-To-Guides/Launch-file-different-formats.html</li> <li>[6] https://answers.ros.org/question/322874/ros2-what-is-different-between-declarelaunchargument-and-launchconfiguration/</li> <li>[7] https://github.com/ros2/launch_ros/blob/humble/launch_ros/launch_ros/actions/node.py#L187</li> </ul>"},{"location":"robotics/ros/ros2_rmw/","title":"ROS2 RMW","text":""},{"location":"robotics/ros/ros2_rmw/#communication-monitoring","title":"Communication Monitoring","text":"<ul> <li>https://docs.ros.org/en/foxy/Concepts/About-Internal-Interfaces.html</li> <li>https://github.com/BonsaiRobotics/rmw_implementation</li> <li>https://github.com/BonsaiRobotics/ros_health_components</li> <li>https://github.com/open-rmf/rmf_ros2</li> <li>https://design.ros2.org/articles/qos_deadline_liveliness_lifespan.html</li> <li>https://docs.ros.org/en/rolling/Concepts/Intermediate/About-Topic-Statistics.html</li> </ul>"},{"location":"robotics/ros/ros2_rmw/#performance","title":"Performance","text":"<ul> <li>https://github.com/tier4/caret</li> </ul>"},{"location":"robotics/ros/ros2_special_topics/","title":"ROS2 Special Topics","text":""},{"location":"robotics/ros/ros2_special_topics/#executor","title":"Executor","text":"<ul> <li>https://github.com/ros2/rclcpp/issues/1618</li> <li>https://github.com/ros2/rclcpp/issues/1637</li> <li>https://github.com/ros2/rclcpp/issues/1642</li> <li>https://github.com/ros2/design/pull/305</li> <li>https://github.com/ros2/rclcpp/pull/1416</li> <li>https://discourse.ros.org/t/ros2-middleware-change-proposal/15863</li> <li>https://discourse.ros.org/t/singlethreadedexecutor-creates-a-high-cpu-overhead-in-ros-2/10077</li> <li> <p>https://discourse.ros.org/t/reducing-ros-2-cpu-overhead-by-simplifying-the-ros-2-layers/13808</p> </li> <li> <p>https://micro.ros.org/docs/concepts/client_library/execution_management/</p> </li> <li>https://docs.ros.org/en/humble/How-To-Guides/Using-callback-groups.html</li> </ul>"},{"location":"robotics/ros/ros2_special_topics/#performance","title":"Performance","text":"<ul> <li>https://github.com/irobot-ros/ros2-performance</li> <li>https://github.com/ros2/ros2_tracing</li> <li>https://github.com/irobot-ros/events-executor/</li> <li>https://robocup.informatik.uni-hamburg.de/en/2022/07/experiences-with-ros-2-on-our-robots/</li> </ul>"},{"location":"robotics/ros/ros2_special_topics/#practical-issues","title":"Practical Issues","text":"<ul> <li>https://robocup.informatik.uni-hamburg.de/en/2022/07/experiences-with-ros-2-on-our-robots/</li> </ul>"},{"location":"robotics/ros/ros2_with_clion/","title":"ROS2 Development with CLion","text":"<p>This is a quick reference note on how to develop ROS2 packages with CLion IDE. The main reference is the official documentation[1].</p> <ul> <li>Create your ROS2 workspace and package as usual</li> </ul> <pre><code>$ mkdir -p ros2_ws/src &amp;&amp; cd ros2_ws/src\n$ ros2 pkg create --build-type ament_cmake sample_package\n</code></pre> <ul> <li>Build the workspace with the \"CMAKE_EXPORT_COMPILE_COMMANDS\" option ON. This will generate a JSON compilation database which can be used by CLion to find the dependent files.</li> </ul> <pre><code>$ cd ros2_ws\n$ colcon build --symlink-install --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -G Ninja\n</code></pre> <ul> <li>Source the colcon workspace and launch CLion from the same terminal</li> </ul> <pre><code>$ cd ros2_ws\n$ source install/setup.bash\n$ clion \n</code></pre> <ul> <li>Open the project and adjust root directory in CLion, from the main menu</li> </ul> <pre><code>File | Open -&gt; Open File or Project \n-&gt; Select the \"compile_commands.json\" file -&gt; Open as Project\n</code></pre> <pre><code>Tools | Compilation Database | Change Project Root\n</code></pre>"},{"location":"robotics/ros/ros2_with_clion/#reference","title":"Reference","text":"<ul> <li>[1] https://www.jetbrains.com/help/clion/ros2-tutorial.html</li> </ul>"},{"location":"robotics/ros/ros_inside_docker/","title":"ROS inside Docker Containers","text":"<p>Tier-1 support of a specific ROS release is limited to one or two Ubuntu releases, for exmaple, ROS Melodic on Ubuntu 18.04, ROS Foxy on Ubuntu 20.04 and ROS Humble on Ubuntu 22.04. It's inconvenient to install multiple distributions and switch between each other when your projects rely on different ROS versions. </p> <p>In fact, you may also face similar issues when doing other kinds of development where setting up the development environment is non-trivial. In such case you can consider build and run your application in a container. You can follow normal Docker configuration steps to acheive this, but the VSCode with the Remote - Containers plugin makes the process very handy. The following figure from the official documentation clearly illustrates how this works.</p> <p></p>"},{"location":"robotics/ros/ros_packages/","title":"ROS Resource","text":"<ul> <li>docker-run</li> <li>docker-ros2-desktop-vnc</li> <li> <p>docker-ubuntu-sweb</p> </li> <li> <p>fuse</p> </li> </ul>"},{"location":"robotics/simulation/gazebo_sim/","title":"Gazebo Simulator","text":"<p>Info</p> <p>This note was written with the assistance of ChatGPT.</p> <p>Gazebo can be used as a standalone robot simulator. But in practice, it's mostly used together with ROS. The setup described in this note is mainly in the ROS context.</p> <ul> <li>Gazebo: Ignition Gazebo (Fortress or later)</li> <li>ROS: Humble or later</li> </ul>"},{"location":"robotics/simulation/gazebo_sim/#robot-kinematics","title":"Robot Kinematics","text":"<p>Robot kinematics is handled with TF in ROS. During the real robot and simulation setup, the following ROS nodes may be used and often get confused:</p> <ul> <li><code>robot_state_publisher</code>: subscribes to joint_states and uses the robot\u2019s URDF to compute and publish the TF transforms of each link in the robot.</li> <li><code>joint_state_publisher</code>: publishes the values of each joint (positions, optionally velocities/efforts) on the <code>joint_states</code> topic.</li> <li><code>joint_state_broadcaster</code>: publishes the values of joint position, velocity, and/or effort on the <code>joint_states</code> topic</li> </ul> <p>Differences between <code>joint_state_publisher</code> and <code>joint_state_broadcaster</code>:</p> <ul> <li>The <code>joint_state_broadcaster</code> is used in a ros2_control-based setup:<ul> <li>Real joint states come from your hardware drivers (or simulation).</li> <li>Those are read by the ros2_control infrastructure.</li> <li>The joint_state_broadcaster publishes them on /joint_states.</li> </ul> </li> <li>The <code>joint_state_publisher</code> node (and its GUI version <code>joint_state_publisher_gui</code>) is generally used for simpler, static, or manually-driven demos rather than for reading real hardware data. It doesn't have the knowledge of the real or simulated robot and it just publishes the specified or default values from the configuration file or ROS parameters.</li> </ul> <p>Relationship between <code>robot_state_publisher</code> and <code>joint_state_publisher</code>/<code>joint_state_broadcaster</code>:</p> <p></p> <ul> <li>Both <code>joint_state_publisher</code> and <code>joint_state_broadcaster</code> can publish to the /joint_states topic but they have different use cases:<ul> <li>The <code>joint_state_publisher</code> reads the <code>robot_description</code> parameter from the parameter server or configuration file, finds all of the non-fixed joints and publishes a JointState message with all those joints defined. It's often used during the development of the robot model (i.e. writing the urdf/xacro).</li> <li>The <code>joint_state_broadcaster</code> works as part of the ros2_control framework and publish to the /joint_states topic with information acquired from the real robot or the simulator.</li> <li>In general, you don't need both in one setup. <code>joint_state_broadcaster</code> can dynamically update and publish joint states, while <code>joint_state_publisher</code> mainly publishes configurable but mostly static joint states. </li> </ul> </li> <li>If no one is publishing joint states, the <code>robot_state_publisher</code> can\u2019t do much as its TF frames will be at default or uninitialized states.</li> </ul>"},{"location":"robotics/simulation/gazebo_sim/#robot-model","title":"Robot Model","text":"<p>Gazebo uses <code>SDF</code> to describe the robot and the simulation environment. In the ROS ecosystem, <code>URDF</code> and <code>xacro</code> are more commonly used to describe the robot links and joints.</p> <ul> <li>SDF Specifications</li> <li>URDF Specifications</li> <li>xacro Specifications</li> </ul> <p>xacro provides features such as macro/property/expression/condition to make it easier to write shorter and more readable description of the robot. A xacro XML file can be easily converted to a URDF XML file without loosing information. Tags supported by xacro/URDF is more or less a subset of thoese in SDF. SDF also allows you to specify properties of the environment, physics, scene etc. You can also convert a URDF file to SDF file.</p> <pre><code># xacro to urdf\n$ xacro robot.xacro &gt; robot.xacro.urdf \n\n# urdf to sdf\n$ ign sdf -p ./robot.xacro.urdf  &gt; robot.urdf.sdf\n</code></pre> <p>Some general guidelines for choosing the most suitable format:</p> <ul> <li>If your development is mainly around Gazebo, SDF may be the best choice since you can easily configure both the robot and simulation setup.</li> <li>If your simulation setup is tightly coupled with ROS, for example, when you use ros2_control framework, xacro is the preferred choice, as it's well supported both by Gazebo and ROS. Gazebo support spawning a robot defined by URDF into an environment defined by SDF.</li> </ul>"},{"location":"robotics/simulation/gazebo_sim/#gazebo-interface","title":"Gazebo Interface","text":"<p>Gazebo contains a set of components that handles robot/environment model management and dynamic simulation with a physics engine. It's built with a plugin system, which integrates all the components into a complete system that can be easily extended. The architecture diagram can be found in the official documentation.</p> <p>There are multiple ways you can interact with simulation entities (e.g. robot, sensors).</p> <p></p> <p>As shown in the above diagram, green blocks 1-4 represent user code that may interact with the simulated environment. </p> <ul> <li>Block 1 is a Gazebo plugin completely implemented by the user, in which you can define what you want to do before/during/after each simulation update.</li> <li>Block 4 is a plugin provided by the ros2_control project. You configure the joints and supported sensors in the URDF and  the plugin will create a controller manager that connects the controllers to the hardware interfaces. You can use both the controllers implemented in ros2_controllers or implement your own controller.</li> <li>Block 2 adds a layer of separation by utilizing the Gazebo transport. Unlike the plugin method in which the plugins run in the same process with the Gazebo simulator, user code runs in a separate process and communicates with the simulator via the Gazebo transport. You can check the topics using <code>ign topic list</code> or <code>gz topic list</code>.</li> <li>Block 3 is a normal ROS node and it can only communicate with the simulator if the Gazebo transport topics are translated to ROS topics using ros_gz_bridge or a user-implemented node. </li> </ul> <p>In general, you should consider the best interfacing method based on your use cases:</p> <ul> <li>If you're following the ros2_control workflow to implement a controller for your robot, method 4 might be most suitable.</li> <li>If you want to implement a custom sensor/device, method 1 is straightforward.</li> <li>If you just try to add a built-in sensor (such as Lidar/Camera) provided by Gazebo, you may simply configure the sensor in the URDF and use the ros_gz_bridge to expose the sensor data to the ROS network.</li> <li>If you want something less coupled with Gazebo, method 2 and/or 3 can be considered.</li> </ul> <p>You may find the following GitHub repositories useful when developing applications that interface with the Gazebo simulator:</p> <ul> <li>https://github.com/gazebosim/gz-sim</li> <li>https://github.com/gazebosim/ros_gz</li> <li>https://github.com/ros-controls/gz_ros2_control</li> <li>https://github.com/ros-controls/ros2_controllers</li> </ul> <p>A project template for creating Gazebo plugins can be found in the repository with documentation: </p> <ul> <li>https://github.com/gazebosim/ros_gz_project_template</li> </ul>"},{"location":"robotics/simulation/gazebo_sim/#reference","title":"Reference","text":"<ul> <li>https://gazebosim.org/docs/fortress/ros2_interop/</li> </ul>"},{"location":"robotics/simulation/geometry/","title":"Resource","text":""},{"location":"robotics/simulation/geometry/#geometry","title":"Geometry","text":"<ul> <li>https://www.open3d.org/docs/latest/index.html</li> <li>http://www.wykobi.com/features.html</li> <li>https://libigl.github.io/</li> </ul>"},{"location":"robotics/simulation/mujoco_sim/","title":"Mujoco Simulator","text":""},{"location":"robotics/simulation/mujoco_sim/#reference","title":"Reference","text":"<ul> <li>Issue #399: Some details and questions about the force-aspect sensors</li> </ul>"},{"location":"robotics/simulation/reference/","title":"Reference","text":""},{"location":"robotics/simulation/reference/#reference_1","title":"Reference","text":""},{"location":"robotics/simulation/reference/#physics-engine","title":"Physics Engine","text":"<ul> <li>Chipmunk2D: https://github.com/slembcke/Chipmunk2D</li> <li>Box2D: https://github.com/erincatto/box2d</li> <li>O3DE: https://o3de.org/</li> </ul>"},{"location":"robotics/simulation/reference/#computational-gemoetry-library","title":"Computational Gemoetry Library","text":"<ul> <li>Wykobi: a C++ 2D/3D oriented computational geometry library</li> <li>libigl: A simple C++ geometry processing library</li> </ul>"},{"location":"robotics/simulation/reference/#graphics","title":"Graphics","text":"<ul> <li>OpenGL Tutorial: https://learnopengl.com/Getting-started/OpenGL</li> <li>TinyRayCaster: https://github.com/ssloy/tinyraycaster/wiki</li> <li>Magnum: https://magnum.graphics/</li> </ul>"},{"location":"robotics/simulation/simulator/","title":"Robot Simulator","text":""},{"location":"robotics/simulation/simulator/#simulation-process","title":"Simulation Process","text":"<p>The process of robot simulation is essentially calculating the system state using it's mathematic model with given initial conditions and inputs. Generally we use ordinary differential equations (ODEs) to describe our robots. By solving for the system states from the set of ODEs at discrete time \\(0, t_s, 2t_s, ...\\), we can get the simulated behavior of the robot during the simulated period.</p> <p>Similarly a physics engine can calculate the state of a system using numerical methods. (Read about ODE/Bullet for more information). We can set a step size (t_phy_s) for the physics engine so that we can get the calculated system state at time \\(t_{phy_s}, 2t_{phy_s}, 3t_{phy_s} ...\\) consecutively when we call the physics engine to do the calculation. If we invoke the calculation at \\(f_{phy}\\) Hz with the step size of t_phy_s, it means we will have the system state simulated from time 0 to \\(f_{phy} \\cdot t_{phy_s}\\) in 1 second. For example \\(f_{phy} = 1kHz\\), and \\(t_{phy_s} = 1ms\\), after the last calculation iteration we will get the system state at \\(t = 1k \\cdot 1ms = 1s\\). Since the wall time of the real world elapses for 1s and the simulated system state also advances for 1s, we can say that the real-time factor is 1.</p> <p>In an extreme condition, if we call the physics engine to calculate very fast and we use a big step size, then by the end of the 1s simulation period, we will get the calculated system state at time \\(t_s &gt; 1s\\). This means time in the simulator elapses faster than time in the real world, thus real-time factor is greater than 1.</p> <p>Of course, limited by the computational power of the computer, the update rate of the physics engine cannot be infinitely high. If a system is extremely complex and the the physics engine cannot get a solution within 1s, then even if we set the step size to be 1s (which is pretty large when simulating a process), we still cannot get a real time factor to be equal or greater than 1.</p> <p>As to the simulation step, it involves sensing and rendering. The physics engine can run at a much higher rate while we don't necessarily update the result to the user at each step. Hence we may have the physics engine run at 1kHz in the background and only refresh the simulation scene for the user at 50Hz.</p>"},{"location":"robotics/simulation/simulator/#reference","title":"Reference:","text":"<ul> <li>Gazebo Document</li> <li>V-REP Document - Simulation</li> </ul>"},{"location":"robotics/simulation/vrep_sim/","title":"CoppeliaSim (V-REP) Simulator","text":""},{"location":"robotics/simulation/vrep_sim/#robot-simulation-in-v-rep","title":"Robot Simulation in V-REP","text":"<p>V-REP (virtual robot experimentation platform) is a dual-licensed software. It provides free educational license for the pro-edu version and source code with GNU GPL license. Compared to Gazebo, V-REP is self-contained (meaning less dependencies), cross-platform (linux/windows/mac) and feature rich (more robots/sensors usable out-of-box). Moreover it's more user-friendly and requires less time to set up your customized robot.</p> <p>Before starting working with V-REP, I would suggest you to \"play with\" it for a while. Try out different mobile/non-mobile robots and explore what's available from the \"Model Browser\". Watch this video. But at this point don't try to grasp every detail yet. Just get yourself familiar with the UI and learn how to change the position/orientation of the robot/component inside the simulation scene.</p>"},{"location":"robotics/simulation/vrep_sim/#key-components-of-a-simulation-in-v-rep","title":"Key components of a simulation in V-REP","text":"<p>There are mainly two parts that you need to take care of for setting up a simulator of your robot. The first part is about the robot. What you need to prepare include the dynamic model (not the mathematic one, but a simplified geometrical model for the physics engine) and the robot mechanical model (a more detailed one compared to the dynamic model for visualization). If you want your robot look better in the simulator, you may also want to prepare texture files, extra 3D components (for example better-looking wheels for your mobile robot).</p> <p>The second part is the simulated environment. In V-REP, a simulated environment is called a scene. A scene may include robots, sensors and other elements like furniture, office items. Each one of them is called an object. V-REP makes heavy use of Lua scripts. Almost all objects in the simulation scene are attached with one or more scripts, which are coordinated by the main script which is attached to the scene. The main script controls the \"actuation\"-\"sensing\"-\"display\" process of each object in a simulation step repeatedly to get the simulation running. It also invokes the physics engine to advance in time. Refer to this article for more details. As mentioned before, each object is attached with a script. V-REP supports two types of scripts: threaded and non-threaded. In most cases a non-threaded script is used and this type of scripts follows the \"actuation\"-\"sensing\"-\"display\" steps, controlled by the main script. If you want to have more control in addition to the these controlled steps and do something in parallel with the main simulation process, you can do that in a threaded script. Read this article about child scripts.</p> <p>After getting these two ready, the next thing you need to figure out is how to interface with the simulation scene, such as acquiring sensor data and sending motor commands. Once your robot is simulated in a scene and you can also talk with your robot, you can play with it for whatever purposes, like implementing your dynamic control algothrim or testing the mapping and localization function of your robot, just like you do with your real robot.</p> <p>At this point, you should have got a rough idea about how V-REP works. For most of the components provided by V-REP, if they don't behave as you desire it to be. Probably you will just need to tweak the attached script. For example, if you want to change the behavior of the propeller module, you just need to open the script, locate to the actuation part and adjust the force/torque formula it use.</p>"},{"location":"robotics/simulation/vrep_sim/#create-a-robot-model","title":"Create a robot model","text":"<p>If your robot is very simple (say it only consists of a few primitive shapes - cube, cylinder, sphere ...), you can start creating your robot right in V-REP. And you can use these shapes for both visualization and dynamics simulation. But if your robot is more complicated, you might want to import your mechanical models (.stl/.obj/.dxf files) to V-REP. In this case, the visualization part should be straightforward since your simulated robot is created from the design file of the real robot. However for the physics engine, these (usually non-convex) shapes can be computational in-efficient and potentially unstable. So it's preferred that you can create a simplified geometrical model for the dynamics calculation. Refer to this article for more details.</p> <p>In V-REP, you can use put visualization models and dynamics models in different layers so that you can just inspect the part that you're interested in. In V-REP, you need to decide two properties for all parts of your robot: static/non-static, respondable/non-respondable. The basic idea is that non-static (dynamic) parts are considered in the calculation of the physics engine and respondable parts are considered in the collision checking, sensor detection etc. The article \" Designing dynamic simulations\" describes this in details. In general, you should set your dynamic models to be non-static and respondable, while for the more detailed visualization models they should be static and non-respondable. In addition, you should also set parameters such as mass/inertia properly to the dynamics models. This may require you to know the mathematic model of your robot.</p>"},{"location":"robotics/simulation/vrep_sim/#set-up-a-simulation-scene","title":"Set up a simulation scene","text":"<p>Once your robot is set up, you can now add more sensors to it. And according to your application, you can even set up different environments such as an office room or a dessert area. Again you may need to tweak the script of the object you add to the scene to make it behave like what you want.</p>"},{"location":"robotics/simulation/vrep_sim/#connect-v-rep-with-your-application","title":"Connect V-REP with your application","text":"<p>Now you've got a robot simulated and running in V-REP. What's next? You probably want to read sensor data from the simulated robot and do control over it. That's the main point you want to set up a simulator for it.</p> <p>V-REP provides a few methods to do so. Basically there are two types of interfacing methods: internal communication and inter-process communication. Refer to this * tutorial to know more about the advantages and disadvantages of each method. If you want to use similar code to control both the simulated robot and the real robot, the remote API may be the best one to use. The work flow is that you first start a server when you start the simulation, then call the remote API functions in your normal control code to read sensor data and send motor commands. Your code acts as a client respect to the server. Watch this nice video for an example and read this article to know more about the remote API. At this point, you should be able to have a much better understanding of these articles: article1, article2.</p> <p>Another point that's worthy of mentioning is that there are different ways of communication between sensors and actuators as discussed in \"Means of communication in and around V-REP\". The regular API provides support for all of them, but it's not the case for the remote API. If a sensor is using tube to publish its data and you want to get the data via the remote API. One easy solution is that you can just modify the script of that sensor and use signals to send out data, which is a way that both regular API and remote API support.</p> <p>Reference</p> <ul> <li>Youtube Video - Line-Following Robot V-Rep Tutorial</li> <li>V-REP Doc - The main script</li> <li>V-REP Doc - Child scripts</li> <li>V-REP Doc - Designing dynamic simulations</li> <li>V-REP Tutorial - Importing and preparing rigid bodies tutorial</li> <li>V-REP Tutorial - External controller</li> <li>Youtube Video - Connect V-REP and Python through Remote API</li> <li>V-REP Doc - Remote API modus operandi</li> <li>V-REP Doc - Means of communication in and around V-REP</li> <li>V-REP Doc - Writing code in and around V-REP</li> </ul>"},{"location":"robotics/simulation/vrep_sim/#case-study-create-a-quadrotor-simulation-in-v-rep","title":"Case Study: Create a Quadrotor Simulation in V-REP","text":"<p>In this case study, you will see how to create the simulation of the AscTec Hummingbird Quadrotor.</p> <p>Components for the simulation:</p> <ul> <li>Quadrotor main frame</li> <li>4 propellers</li> <li>IMU sensor(gyro + accelerometer)</li> </ul> <p>It's highly recommended to read this official tutorial and follow the steps by yourself before you start creating a simulation of your own robot. This case study assumes you've already read the contents of this tutorial and the previous sections of this wiki. The goal is only to show you the work flow of using V-REP with a more specific example, thus a lot of operation details are omitted. If you get any problems in the process, always remember to check the official documentation and the official forum. In most cases you should be able to find the answer. It's also very common that you check the implementation of a existing robot model to get an idea of how to implement a specific feature on your own robot. The example robot models and scenes provided by V-REP are very good resources for you to learn V-REP. In addition, you can try to post your question on the forum. According to my experience, they respond to questions very fast.</p>"},{"location":"robotics/simulation/vrep_sim/#prepare-the-robot-model","title":"Prepare the robot model","text":"<p>You need to prepare the mechanical model file(.stl, .obj) to create the body of your robot. If you just want to do experiments with a simulated robot and don't really want to design the mechanical structure by yourself, this website is a good place for you to look for existing 3d models. People share mechanical designs like RC-Cars, Quarotors on this site and you can use them to create the simulation. Also get yourself familiar with the robot library of V-REP. It's very helpful if you know what components are already available so that you can reuse them conveniently. Actuators and sensors are two types of the most commonly used components from V-REP to build your customized robot.</p> <p>V-REP provides a very powerful tool to create and modify mechanical model. It's recommended that you assemble all the parts together in Solidworks(or other software you prefer) first and export the robot model into a single stl file. You can import this stl to V-REP and divide the model into smaller parts later. Comparatively it can be very tedious and difficult if you import all parts (a set of .stl files) into V-REP directly and then try to assemble them to the right place, especially if your robot consists of a lot of parts.</p> <p>Download the stl file for the hummingbird quadrotor from the AscTec wiki. Import the model into V-REP.</p> <p></p> <p>If you want the simulated quadrotor to look better, you can now divide the model into smaller parts and apply textures to different parts.</p> <p></p>"},{"location":"robotics/simulation/vrep_sim/#create-a-simplified-dynamic-model-for-simulation","title":"Create a simplified dynamic model for simulation","text":"<p>For this imported stl model, it's usually non-convex and not proper for dynamic simulation in terms of performance and stability. It's a good practice to create a simpler dynamic model from the original stl model for the simulation. This simplified model is the one actually used by the physics engine to do calculation. In other words, the stl model is mainly used to help create the dynamic model, for example, you can extract a pure shape with similar geometrical characters from the stl model to get the dynamic model of a specific part. And after this process, the stl model is mainly for visual effects.</p> <p>In this example, the quadrotor frame is abstracted as a sphere with four cuboid shapes.</p> <p></p> <p>Don't forget the adjust the properties of the dynamic model, such as mass, inertia.</p>"},{"location":"robotics/simulation/vrep_sim/#add-propellers-and-sensors-to-the-quadrotor","title":"Add propellers and sensors to the quadrotor","text":"<p>V-REP provides the model of a propeller with particle simulation so you can use it directly on the quadrotor. You can find the model from /components/locomotion in the model browser. Add four of the propeller into the scene and adjust the position of each.</p> <p></p> <p>If you want the simulated Hummingbird to be more like the real one in appearance, you can hide the visible parts of the provided propeller model and use a better-looking propeller model. For example, you can download this propeller model from GrabCAD site.</p> <p>V-REP also provides models for the sensors. Simply drag a gyro and a accelerometer into the scene and place them at a proper position on the quadrotor. The final quadrotor model is shown in the image below. You can also check the hierarchy structure of the simulated robot in this screenshot.</p> <p></p>"},{"location":"robotics/simulation/vrep_sim/#write-code-to-interface-with-the-quadrotor","title":"Write code to interface with the quadrotor","text":"<p>By now you should have got a working simulated Hummingbird qaudrotor in V-REP. You need to write code to communicate with it(read sensor data from it and send motor commands to it). Here is an example of using the remoteAPI.</p> <p>On the V-REP side, add a threaded-script file to the quadrotor model and add the following scripts in it:</p> <p>(Lua script omitted, refer to VREP sample)</p> <p>The above script can start a service when you start the simulation and then you can use remoteAPI functions in your C/C++ program to communicate with the simulation. The code below only shows the general structure to establish a connection between a client and a server.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;iostream&gt;\n#include &lt;unistd.h&gt;\n\nextern \"C\" {\n    #include \"extApi.h\"\n/*  #include \"extApiCustom.h\" // custom remote API functions */\n}\n\nusing namespace RobotToolkitRIVeR;\n\nint main(int argc,char* argv[])\n{\n    if (argc&gt;=1)\n    {\n        portNb=atoi(argv[1]);\n    }\n    else\n    {\n        printf(\"Please indicate following argument(s): 'portNumber'!\\n\");\n        extApi_sleepMs(5000);\n        return 0;\n    }\n\n    // start a connection with the server\n    simxInt clientID = simxStart((simxChar*)\"127.0.0.1\",portNb,true,true,2000,5);\n\n    if (clientID!=-1)\n    {\n        std::cout &lt;&lt; \"INFO: Connected to server.\" &lt;&lt; std::endl;\n\n        std::cout &lt;&lt; \"INFO: Enter control loop.\" &lt;&lt; std::endl;\n\n            // the control loop starts here\n        while (simxGetConnectionId(clientID)!=-1)\n        {\n            // 1. receive data from robot\n                    // remoteAPI function calls\n\n            // 2. process data and do calculation\n                    // custom function calls\n\n            // 3. send command to robot\n                    // remoteAPI function calls\n\n            extApi_sleepMs(2);\n        }\n\n        std::cout &lt;&lt; \"INFO: Exit control loop.\" &lt;&lt; std::endl;\n\n            // close the connection with server\n        simxFinish(clientID);\n    }\n    else\n    {\n        std::cout &lt;&lt; \"ERROR: Failed to connect to server\" &lt;&lt; std::endl;\n    }\n\n    return(0);\n}\n</code></pre> <p>Refer to the tutorials and example scenes to learn how to use remoteAPI, as well as ROS, Matlab interfaces. The \"controlTypeExamples\" scene provided by V-REP is extremely useful for you to learn how each of the interfaces work, both on the V-REP side and on your own code side. You can find more information from this page.</p> <p>A demonstration video can be found here. In this video, direct motor commands were sent to the quadrotor and the quadrotor lift up right after receiving the commands.</p>"},{"location":"system/basics/endianness/","title":"Endianness","text":"<p>Big-endian systems store the most significant byte of a word in the smallest address and the least significant byte is stored in the largest address. Little-endian systems, in contrast, store the least significant byte in the smallest address.[1]</p> <p>For example, there is a number in hexadecimal: 0x01234567, with the most significant byte 0x01 and least significant byte 0x67. It is stored within the address range 0x100 through 0x103.[2]</p> <p>Big-endian:</p> Address 0x100 0x101 0x102 0x103 Value 0x01 0x23 0x45 0x67 <p>Little-endian:</p> Address 0x100 0x101 0x102 0x103 Value 0x67 0x45 0x23 0x01 <p>Different processors may follow different conventions. For example the Intel x86 and x86-64 series of processors use the little-endian format while the Motorola 6800 and 68k series of processors use the big-endian format. And newer versions of ARM processors support bi-endian.[1] The most important thing is the consistency. One should keep the used convention in mind when (1) binary data are communicated over a network  between different machines; (2) looking at the byte sequences representing integer data, say inspecting machine-level code generated by a disassembler; (3) programs are written that circumvent the normal type system, say using a data type cast in C.</p>"},{"location":"system/cloud/cncf_projects/","title":"CNCF Projects","text":"<ul> <li>CNCF Projects</li> </ul>"},{"location":"system/cloud/wireguard-on-aws/","title":"Wireguard Setup on AWS","text":""},{"location":"system/cloud/wireguard-on-aws/#tested-environment","title":"Tested Environment","text":"<ul> <li>Debian 10.5 on AWS</li> <li>Ubuntu 20.04/22.04/24.04 on AWS</li> </ul>"},{"location":"system/cloud/wireguard-on-aws/#install-wireguard-on-server","title":"Install wireguard on server","text":"<pre><code>$ sudo apt-get install wireguard-dkms wireguard-tools linux-headers-$(uname -r)\n</code></pre> <p>Note that the package \"linux-headers-$(uname -r)\" is necessary to run wireguard.</p> <p>Next we need to enable IP Forwarding. Open \"/etc/sysctl.conf\" and search for the line \"#net.ipv4.ip_forward\". Uncomment this line by removing the # at the beginning. It should look like this: </p> <pre><code>net.ipv4.ip_forward=1\n</code></pre>"},{"location":"system/cloud/wireguard-on-aws/#generate-server-and-client-keys","title":"Generate server and client keys","text":"<p>You will need root privilege to manipuate the \"/etc/wireguard\" directory</p> <pre><code>$ sudo -i \n$ cd /etc/wireguard\n$ umask 077\n$ wg genkey | tee server_private_key | wg pubkey &gt; server_public_key\n</code></pre> <p>You will need to create a key pair for each client  (more deails below, not needed for now)</p> <pre><code>$ wg genkey | tee &lt;client_private_key_name&gt; | wg pubkey &gt; &lt;client_public_key_name&gt;\n</code></pre>"},{"location":"system/cloud/wireguard-on-aws/#create-server-configuration-file","title":"Create server configuration file","text":"<p>Create a file \"/etc/wireguard/wg0.conf\" with the following content</p> <pre><code>[Interface]\nAddress = 10.200.200.1/24\nSaveConfig = true\nPostUp = /etc/wireguard/iptable-set.sh\nPostDown = /etc/wireguard/iptable-reset.sh\nListenPort = 51820\nPrivateKey = &lt;insert server_private_key\\&gt;\n\n[Peer]\nPublicKey = &lt;insert client_public_key\\&gt;\nAllowedIPs = 10.200.200.2/32\n</code></pre> <p>Note in the above example,  </p> <ul> <li> <p>\"10.200.200.0\" range is used for the VPN network. You can change it to other preferred ranges</p> </li> <li> <p>The ListenPort has to be accesible and you will need to add a rule in your Firewall to allow \"UDP:&lt;ListenPort&gt;\"</p> </li> <li> <p>Two scripts are used to set up or recover the routing table when you bring up or down the VPN network</p> </li> </ul> <p>The setup script: </p> <pre><code>#!/bin/bash\n\n# Reference:\n#  [1] https://www.ckn.io/blog/2017/11/14/wireguard-vpn-typical-setup/\n#  [2] https://www.cyberciti.biz/faq/how-to-set-up-wireguard-firewall-rules-in-linux/\n\nIN_FACE=\"eth0\"                   # NIC connected to the internet\nWG_FACE=\"wg0\"                    # WG NIC \nSUB_NET=\"10.200.200.0/24\"            # WG IPv4 sub/net aka CIDR\nWG_PORT=\"51820\"                  # WG udp port\n\n# track VPN connection\n/sbin/iptables -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n/sbin/iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n\n# allow incoming VPN traffic on the listening port\n/sbin/iptables -A INPUT -p udp -m udp --dport $WG_PORT -m conntrack --ctstate NEW -j ACCEPT\n# allow both TCP and UDP recursive DNS traffic\n/sbin/iptables -A INPUT -s $SUB_NET -p tcp -m tcp --dport 53 -m conntrack --ctstate NEW -j ACCEPT\n/sbin/iptables -A INPUT -s $SUB_NET -p udp -m udp --dport 53 -m conntrack --ctstate NEW -j ACCEPT\n# allow forwarding of packets between interfaces\n/sbin/iptables -A FORWARD -i $WG_FACE -o $WG_FACE -m conntrack --ctstate NEW -j ACCEPT\n/sbin/iptables -A FORWARD -i $IN_FACE -o $WG_FACE -m conntrack --ctstate NEW -j ACCEPT\n/sbin/iptables -A FORWARD -i $WG_FACE -o $IN_FACE -m conntrack --ctstate NEW -j ACCEPT\n# set up nat\n/sbin/iptables -t nat -A POSTROUTING -s $SUB_NET -o $IN_FACE -j MASQUERADE\n</code></pre> <p>The recovery script:</p> <pre><code>#!/bin/bash\n\nIN_FACE=\"eth0\"                   # NIC connected to the internet\nWG_FACE=\"wg0\"                    # WG NIC \nSUB_NET=\"10.200.200.0/24\"            # WG IPv4 sub/net aka CIDR\nWG_PORT=\"51820\"                  # WG udp port\n\n# allow incoming VPN traffic on the listening port\n/sbin/iptables -D INPUT -p udp -m udp --dport $WG_PORT -m conntrack --ctstate NEW -j ACCEPT\n# allow both TCP and UDP recursive DNS traffic\n/sbin/iptables -D INPUT -s $SUB_NET -p tcp -m tcp --dport 53 -m conntrack --ctstate NEW -j ACCEPT\n/sbin/iptables -D INPUT -s $SUB_NET -p udp -m udp --dport 53 -m conntrack --ctstate NEW -j ACCEPT\n# allow forwarding of packets between interfaces\n/sbin/iptables -D FORWARD -i $WG_FACE -o $WG_FACE -m conntrack --ctstate NEW -j ACCEPT\n/sbin/iptables -D FORWARD -i $IN_FACE -o $WG_FACE -m conntrack --ctstate NEW -j ACCEPT\n/sbin/iptables -D FORWARD -i $WG_FACE -o $IN_FACE -m conntrack --ctstate NEW -j ACCEPT\n# set up nat\n/sbin/iptables -t nat -D POSTROUTING -s $SUB_NET -o $IN_FACE -j MASQUERADE\n</code></pre>"},{"location":"system/cloud/wireguard-on-aws/#configure-dns","title":"Configure DNS","text":"<p>Here \"ubound\" is used to provide DNS </p> <pre><code>$ apt-get install unbound unbound-host dnsutils\n</code></pre> <p>Download the list of root DNS servers</p> <pre><code>$ curl -o /var/lib/unbound/root.hints https://www.internic.net/domain/named.cache\n$ chown -R unbound:unbound /var/lib/unbound\n$ cd /etc/unbound/unbound.conf.d\n$ nano unbound_srv.conf\n</code></pre> <p>Add the following content</p> <pre><code>server:\n\n  num-threads: 4\n\n  #Enable logs\n  verbosity: 1\n\n  #list of Root DNS Server\n  root-hints: \"/var/lib/unbound/root.hints\"\n\n  #Use the root servers key for DNSSEC\n  #auto-trust-anchor-file: \"/var/lib/unbound/root.key\"\n\n  #Respond to DNS requests on all interfaces\n  interface: 0.0.0.0\n  max-udp-size: 3072\n\n  #Authorized IPs to access the DNS Server\n  access-control: 0.0.0.0/0                 refuse\n  access-control: 127.0.0.1                 allow\n  access-control: 10.200.200.0/24               allow\n\n  #not allowed to be returned for public internet  names\n  private-address: 10.200.200.0/24\n\n  # Hide DNS Server info\n  hide-identity: yes\n  hide-version: yes\n\n  #Limit DNS Fraud and use DNSSEC\n  harden-glue: yes\n  harden-dnssec-stripped: yes\n  harden-referral-path: yes\n\n  #Add an unwanted reply threshold to clean the cache and avoid when possible a DNS Poisoning\n  unwanted-reply-threshold: 10000000\n\n  #Have the validator print validation failures to the log.\n  val-log-level: 1\n\n  #Minimum lifetime of cache entries in seconds\n  cache-min-ttl: 1800\n\n  #Maximum lifetime of cached entries\n  cache-max-ttl: 14400\n  prefetch: yes\n  prefetch-key: yes\n\n  module-config: \"iterator\"\n</code></pre> <p>Now restart unbound service and enable it to autostart</p> <pre><code>$ systemctl restart unbound\n$ systemctl enable unbound\n</code></pre> <p>You may need to disable the default DNS resolver if unbound fails to start with an error message saying port 53 has been binded to another process [8][9][10]</p> <pre><code>% use netstat to check whether port 53 has been binded \n$ netstat -lutnp\n\n% disable systemd-resolved\n$ sudo systemctl stop systemd-resolved\n$ sudo systemctl disable systemd-resolved\n</code></pre> <p>If you get error message about unknown hostname, you may add the following line to \"/etc/hosts\" file</p> <pre><code># add one line to /etc/hosts\n127.0.0.1 &lt;your-hostname&gt;\n</code></pre> <p>After that, your \"/etc/hosts\" file should look like this</p> <pre><code>127.0.0.1 localhost\n127.0.0.1 &lt;your-hostname&gt;\n\n# The following lines are desirable for IPv6 capable hosts\n::1 ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\nff02::3 ip6-allhosts\n</code></pre> <p>You can test your DNS setup with the following commands and you should expect to see similar results returned</p> <pre><code>$ nslookup www.google.com. 10.200.200.1\nServer:     10.8.6.1\nAddress:    10.8.6.1#53\n\nNon-authoritative answer:\nName:   www.google.com\nAddress: 74.125.200.99\nName:   www.google.com\nAddress: 74.125.200.106\nName:   www.google.com\nAddress: 74.125.200.103\nName:   www.google.com\nAddress: 74.125.200.105\nName:   www.google.com\nAddress: 74.125.200.104\nName:   www.google.com\nAddress: 74.125.200.147\nName:   www.google.com\nAddress: 2404:6800:4003:c00::68\nName:   www.google.com\nAddress: 2404:6800:4003:c00::67\nName:   www.google.com\nAddress: 2404:6800:4003:c00::63\nName:   www.google.com\nAddress: 2404:6800:4003:c00::93\n\n$ unbound-host -C /etc/unbound/unbound.conf -v ietf.org\n[1599212188] libunbound[2097:0] notice: init module 0: validator\n[1599212188] libunbound[2097:0] notice: init module 1: iterator\nietf.org has address 4.31.198.44 (secure)\nietf.org has IPv6 address 2001:1900:3001:11::2c (secure)\nietf.org mail is handled by 0 mail.ietf.org. (secure)\n</code></pre> <p>Additionally you can use http://dnsleak.com/ to test DNS leakage.</p>"},{"location":"system/cloud/wireguard-on-aws/#start-wireguard-service-on-server","title":"Start wireguard service on server","text":"<p>Now you're ready to start the wireguard service on your server</p> <pre><code>$ sudo wg-quick up wg0\n$ sudo systemctl enable wg-quick@wg0.service \n</code></pre> <p>Use the following command to bring down the service</p> <pre><code>$ sudo wg-quick down wg0\n</code></pre>"},{"location":"system/cloud/wireguard-on-aws/#setup-clients","title":"Setup clients","text":""},{"location":"system/cloud/wireguard-on-aws/#server-side","title":"Server side","text":"<p>As mentioned above, you will have create a key pair for each client, for example:</p> <pre><code>$ wg genkey | tee rdu_acer_private.key | wg pubkey &gt; rdu_acer_public.key\n</code></pre> <p>Register the client on the server</p> <pre><code>$ wg set wg0 peer &lt;new_client_public_key&gt; allowed-ips &lt;new_client_vpn_IP&gt;/32\n</code></pre> <p>In the following client setup part, we will assume you've assigned 10.200.200.2/32 to the client rdu-acer. </p> <p>You need to restart the \"wg0\" interface to make this change into effect.</p>"},{"location":"system/cloud/wireguard-on-aws/#client-side","title":"Client side","text":"<p>You can either set up the VPN profile on your device manually or from a QR code</p> <p>Manual setup on Linux</p> <pre><code>$  sudo apt-get install wireguard-dkms wireguard-tools linux-headers-$(uname -r)\n</code></pre> <p>Create the configuration file</p> <pre><code>$ sudo -i\n$ nano /etc/wireguard/wg0-acer.conf\n</code></pre> <pre><code>[Interface]\nAddress = 10.200.200.2/32\nPrivateKey = &lt;insert client_private_key&gt;\nDNS = 10.200.200.1\n\n[Peer]\nPublicKey = &lt;insert server_public_key&gt;\nEndpoint = &lt;VPN-Server-Public-IP&gt;:&lt;ListenPort&gt;\nAllowedIPs = 0.0.0.0/0\nPersistentKeepalive = 25\n</code></pre> <p>Now you can bring up the connection</p> <pre><code>$ sudo wg-quick up wg0-acer\n$ sudo systemctl enable wg-quick@wg0-acer.service\n</code></pre> <p>QR code setup on Android</p> <p>Instead of manually typing in the VPN information on the phone, you can generate a QR code on the server and setup your phone with this QR code.</p> <pre><code>$ cd /etc/wireguard/\n$ nano rdu_acer_qr.conf\n</code></pre> <pre><code>[Interface]\nAddress = 10.200.200.2/32\nPrivateKey = client_private_key\nDNS = 10.200.200.1\n\n[Peer]\nPublicKey = server_public_key\nAllowedIPs = 0.0.0.0/0\nEndpoint = &lt;VPN-Server-Public-IP&gt;:&lt;ListenPort&gt;\nPersistentKeepalive = 25\n</code></pre> <p>Then generate the QR code:</p> <pre><code>$ apt install qrencode\n$ qrencode -t ansiutf8 &lt; rdu_acer_qr.conf\n</code></pre> <p>Now you can scan the QR code on your phone to setup the VPN connection.</p>"},{"location":"system/cloud/wireguard-on-aws/#reference","title":"Reference","text":"<ul> <li>[1] https://golb.hplar.ch/2018/10/wireguard-on-amazon-lightsail.html</li> <li>[2] https://www.ckn.io/blog/2017/11/14/wireguard-vpn-typical-setup/</li> <li>[3] https://www.cyberciti.biz/faq/how-to-set-up-wireguard-firewall-rules-in-linux/</li> <li>[4] https://stackoverflow.com/questions/37570910/rtnetlink-answers-operation-not-supported</li> <li>[5] https://emanuelduss.ch/2018/09/wireguard-vpn-road-warrior-setup/</li> <li>[6] https://engineerworkshop.com/blog/how-to-set-up-a-wireguard-vpn-server-on-ubuntu-linux/</li> <li>[7] https://www.zahradnik.io/wireguard-a-vpn-with-real-world-usage-in-mind</li> <li>[8] https://askubuntu.com/questions/907246/how-to-disable-systemd-resolved-in-ubuntu</li> <li>[9] https://blobfolio.com/2017/05/fix-linux-dns-issues-caused-by-systemd-resolved/</li> <li>[10] https://askubuntu.com/questions/59458/error-message-sudo-unable-to-resolve-host-none</li> <li>[11] https://www.linuxbabe.com/ubuntu/set-up-local-dns-resolver-ubuntu-20-04-bind9</li> <li>[12] https://nlnetlabs.nl/documentation/unbound/howto-anchor/</li> </ul>"},{"location":"system/docker/docker-advanced-build/","title":"Advanced Docker Build","text":""},{"location":"system/docker/docker-advanced-build/#conditional-build","title":"Conditional Build","text":"<p>Sometimes you may need to build the image with different sets of commands for a small part of the build process. You can choose which set to use by passing in user-defined arguments. There are two ways to handle this: </p> <ul> <li>Use if/else condition from bash</li> <li>Use multi-stage build</li> </ul> <p>If the number of different conditions is small and the command for each condition is short, using bash may be simpler. But generally, it's cleaner to use multi-stage build:</p> <pre><code># control argument\nARG MY_ARG\n\n# common tasks\nFROM ubuntu:focal AS base\nRUN echo \"do common stuffs\"\n\n# condition 1\nFROM base AS branch-arg1\nRUN echo \"this is the stage for MY_ARG=arg1\"\n\n# condition 2\nFROM base AS branch-arg2\nRUN echo \"this is the stage for MY_ARG=arg2\"\n\n# more common tasks\nFROM branch-${MY_ARG} AS final\nRUN echo \"more common stuffs\"\n</code></pre> <p>Then you can build with command:</p> <pre><code>$ docker build --build-arg MY_ARG=arg1 .\n</code></pre>"},{"location":"system/docker/docker-advanced-build/#build-multi-platform-images","title":"Build Multi-platform Images","text":"<p>You can use the buildx CLI plugin to create multi-platform images. It's a two-step process:</p> <ul> <li>Create a builder instance</li> </ul> <p>Here you will create a builder with name \"multi-platform\" that supports \"linux/amd64\" and \"linux/arm64\":</p> <pre><code>$ sudo docker buildx create \\\n    --name multi-platform \\\n    --platform linux/amd64,linux/arm64 \\\n    --driver docker-container\n</code></pre> <ul> <li>Use the builder instance to build the images</li> </ul> <p>The following command will build the image for both \"linux/amd64\" and \"linux/arm64\" platforms and will push the image to the docker registry:</p> <pre><code>$ sudo docker buildx build \\\n        --build-arg MY_ARG=arg1 \\\n        --builder multi-platform \\\n        --output \"type=image,push=true\" \\\n        --platform linux/amd64,linux/arm64 \\\n        -t registry/image_name:tag \\\n        . -f ./Dockerfile\n</code></pre>"},{"location":"system/docker/docker-advanced-build/#reference","title":"Reference","text":"<ul> <li>https://stackoverflow.com/questions/43654656/dockerfile-if-else-condition-with-external-arguments</li> <li>https://docs.docker.com.xy2401.com/buildx/working-with-buildx/</li> <li>https://blog.k4nz.com/5ec72c881c5ef14c740f876d7e26b9cd/</li> <li>https://www.docker.com/blog/faster-multi-platform-builds-dockerfile-cross-compilation-guide/</li> </ul>"},{"location":"system/docker/docker-cmdref/","title":"Docker Command Reference","text":""},{"location":"system/docker/docker-cmdref/#createstartstop-a-container","title":"Create/start/stop a Container","text":"<ul> <li>Create and run a container</li> </ul> <pre><code>$ sudo docker run -it --rm &lt;target-container&gt; bash\n</code></pre> <ul> <li>List all (running and stopped) containers</li> </ul> <pre><code>$ sudo docker ps -a\n</code></pre> <ul> <li>Run a command in a running container</li> </ul> <pre><code>$ sudo docker exec -it &lt;target-container&gt; bash\n</code></pre> <ul> <li>Stop/start/restart/remove a container</li> </ul> <pre><code>$ sudo docker stop &lt;target-container&gt;\n$ sudo docker start &lt;target-container&gt;\n$ sudo docker restart &lt;target-container&gt;\n$ sudo docker rm &lt;target-container&gt;\n</code></pre> <ul> <li>Check resource usage statistics of a container</li> </ul> <pre><code>$ sudo docker stats &lt;target-container&gt;\n</code></pre> <ul> <li>Check log output of a running container</li> </ul> <pre><code>$ sudo docker logs -f &lt;target-container&gt;\n</code></pre>"},{"location":"system/docker/docker-cmdref/#advanced-configurations","title":"Advanced Configurations","text":"<ul> <li>Map persistent storage volume</li> </ul> <pre><code># host-src: an absolute path or a name value\n# options: rw, ro\n$ sudo docker run --rm \\\n    -v [host-src:]container-dest[:&lt;options&gt;] \\\n    &lt;target-container&gt;\n</code></pre>"},{"location":"system/docker/docker-cmdref/#manage-docker-images","title":"Manage Docker Images","text":"<ul> <li>Create a docker image</li> </ul> <pre><code>$ sudo docker build . -t &lt;image-name&gt;:&lt;tag&gt; -f ./Dockerfile\n# Do not use cache when building the image\n$ sudo docker build . -t &lt;image-name&gt;:&lt;tag&gt; -f ./Dockerfile --no-cache\n</code></pre> <ul> <li>List all images</li> </ul> <pre><code>$ sudo docker image list\n</code></pre> <ul> <li>Remove a docker image</li> </ul> <pre><code>$ sudo docker image rm &lt;image-name&gt;:&lt;tag&gt;\n$ sudo docker rmi &lt;image-name&gt;:&lt;tag&gt;\n</code></pre> <ul> <li>Tag a docker image</li> </ul> <pre><code>$ sudo docker tag &lt;image-id-or-name&gt; &lt;image-name&gt;:&lt;tag&gt;\n</code></pre> <ul> <li>Create a new image from a container\u2019s changes</li> </ul> <pre><code># first check changes\n$ sudo docker diff &lt;target-container&gt;\n# if all changes are okay, commit changes\n$ sudo docker commit -a \"author-name\" -m \"change msg\" &lt;target-container&gt; &lt;image-name&gt;:&lt;tag&gt;\n</code></pre> <ul> <li>Push/pull image from/to a docker registry</li> </ul> <pre><code>$ sudo docker pull &lt;image-name&gt;:&lt;tag&gt;\n$ sudo docker push &lt;image-name&gt;:&lt;tag&gt;\n</code></pre>"},{"location":"system/docker/docker-cmdref/#docker-compose","title":"Docker Compose","text":"<p>Sample compose</p> <pre><code>version: '3'\nservices:\n  service_one:\n    privileged: true\n    devices: \n      - /dev/video0:/dev/video101\n    image: \"sample-image:latest\"\n    mem_limit: 512m\n    mem_reservation: 128M\n    logging:\n        driver: \"json-file\"\n        options:\n            max-file: \"5\"\n            max-size: \"10m\"\n    network_mode: \"host\"\n    volumes:\n      - \"/opt/config.yaml:/config.yaml\"\n    command: [\"arg1\", \"/config.yaml\"]\n    restart: unless-stopped\n  service_two:\n    image: \"sample-image:latest\"\n    user: root\n    logging:\n        driver: \"json-file\"\n        options:\n            max-file: \"5\"\n            max-size: \"10m\"\n    network_mode: \"host\"\n    command: [\"arg1\", \"arg2\", \"arg3\"]\n    restart: unless-stopped\n</code></pre> <p>Note that you need to enable cgroup function for resource limit (ram/cpu). The reservation memory size should be smaller than the memory limit. [3]</p>"},{"location":"system/docker/docker-cmdref/#check-resource-usage","title":"Check Resource Usage","text":"<pre><code>$ sudo docker stats\n</code></pre>"},{"location":"system/docker/docker-cmdref/#nvidia-docker","title":"Nvidia Docker","text":"<p>You may need to pass in additional arguments to use the nvidia runtime:</p> <pre><code>$ sudo docker run --runtime=nvidia --network host -it &lt;image-name&gt;:&lt;tag&gt;\n</code></pre> <p>Allow containers to communicate with Xorg</p> <pre><code>$ sudo xhost +\n$ sudo docker run -it --rm --net=host --runtime nvidia -e DISPLAY=$DISPLAY -v /tmp/.X11-unix/:/tmp/.X11-unix nvcr.io/nvidia/l4t-base:r34.1\n</code></pre> <p>Option explained:</p> <ul> <li>-it means run in interactive mode</li> <li>--rm will delete the container when finished</li> <li>--runtime nvidia will use the NVIDIA container runtime while running the l4t-base container</li> <li>-v is the mounting directory, and used to mount host\u00c2\u0092s X11 display in the container filesystem to render output videos</li> </ul>"},{"location":"system/docker/docker-cmdref/#reference","title":"Reference","text":"<ul> <li>[1] https://docs.docker.com/engine/reference/commandline/run/</li> <li>[2] https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-base</li> <li>[3] https://docs.docker.com/config/containers/resource_constraints/</li> </ul>"},{"location":"system/docker/docker-multi-platform/","title":"Docker Multi-platform Build","text":"<ul> <li>https://www.docker.com/blog/faster-multi-platform-builds-dockerfile-cross-compilation-guide/</li> </ul>"},{"location":"system/docker/docker-platform-emulation/","title":"Docker Platform Emulation","text":"<p>In some cases, it's convenient to build and run non-x64 container images on a x64 computer. An example is to build docker images for raspberry pi or jetson on your host computer, which has a more powerful CPU.</p>"},{"location":"system/docker/docker-platform-emulation/#install-tools","title":"Install Tools","text":"<pre><code>$ sudo apt install qemu qemu-user-static binfmt-support\n$ docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n</code></pre>"},{"location":"system/docker/docker-platform-emulation/#run-the-container","title":"Run the Container","text":"<p>For a multi-arch image hosted on container registry (such as Docker Hub), you can explicitly specify which platform of the image you want to pull or run:</p> <pre><code># run arm64\n$ docker pull --platform linux/arm64 alpine:latest\n</code></pre> <p>If you don't specify the platform, docker will try to pull the image for the same platform of your host computer. It will fail if the image is just for a different platform, giving you error messages similar to</p> <pre><code>no matching manifest for linux/amd64 in the manifest list entries\n</code></pre>"},{"location":"system/docker/docker-platform-emulation/#reference","title":"Reference","text":"<ul> <li>https://www.stereolabs.com/docs/docker/building-arm-container-on-x86</li> </ul>"},{"location":"system/docker/docker-special-topics/","title":"Docker Special Topics","text":"<ul> <li>\u7406\u89e3 docker \u5bb9\u5668\u4e2d\u7684 uid \u548c gid</li> <li>Linux Namespace : User</li> </ul>"},{"location":"system/docker/docker-volume-backup/","title":"Docker Volume Backup and Restore","text":"<p>Info</p> <p>This note was written with the assistance of ChatGPT.</p> <p>At the core, Docker volumes are just directories managed by Docker (often under <code>/var/lib/docker/volumes/&lt;volume_name&gt;/_data/</code> on Linux). To export and import a volume properly and portably, the most robust way is to tar the contents, then copy and restore.</p>"},{"location":"system/docker/docker-volume-backup/#to-export-backup-a-docker-volume","title":"To Export (Backup) a Docker Volume","text":"<p>Suppose your volume is called <code>my_volume</code>.</p> <pre><code>docker run --rm -v my_volume:/volume -v $(pwd):/backup busybox tar czf /backup/my_volume.tar.gz -C /volume .\n</code></pre> <ul> <li><code>my_volume:/volume</code> mounts your volume into the container.</li> <li><code>$(pwd):/backup</code> mounts your current directory for output.</li> <li>It creates a <code>my_volume.tar.gz</code> in your current directory containing all the files inside the volume.</li> </ul> <p>Example:</p> <pre><code># specify which volume to backup\nVOLUME_NAME=my_volume\n\n# create tarball of the volume\ndocker run --rm -v ${VOLUME_NAME}:/volume -v $(pwd):/backup busybox tar czf /backup/${VOLUME_NAME}.tar.gz -C /volume .\n</code></pre>"},{"location":"system/docker/docker-volume-backup/#to-import-restore-the-volume-on-another-computer","title":"To Import (Restore) the Volume on Another Computer","text":"<p>First, make sure the volume exists on the new machine:</p> <pre><code>docker volume create my_volume\n</code></pre> <p>Then, use a temporary container again to extract the tarball:</p> <pre><code>docker run --rm -v my_volume:/volume -v $(pwd):/backup busybox sh -c \"cd /volume &amp;&amp; tar xzf /backup/my_volume.tar.gz\"\n</code></pre> <ul> <li>Here, <code>/backup/my_volume.tar.gz</code> is the file you copied over from the first machine.</li> </ul> <p>Example:</p> <pre><code># specify which volume to restore\nVOLUME_NAME=my_volume\n\n# optional (if the volume doesn't exist yet)\ndocker volume create ${VOLUME_NAME}\n\n# Overwrite the volume with the contents of the tarball\ndocker run --rm -v ${VOLUME_NAME}:/volume -v $(pwd):/backup busybox sh -c \"cd /volume &amp;&amp; tar xzf /backup/${VOLUME_NAME}.tar.gz\"\n</code></pre>"},{"location":"system/docker/docker-volume-backup/#some-extra-thoughts","title":"Some Extra Thoughts:","text":"<ul> <li>If your volume is large, you can compress even further or split the file (<code>split</code> command).</li> <li>If you want a full automated backup/restore, you can script this process.</li> <li>For highly dynamic data (e.g., database volumes), consider snapshotting while container is paused to avoid inconsistency.</li> <li>For critical applications, it's better to have an application-level export (e.g., MySQL dump) rather than filesystem snapshotting.</li> </ul>"},{"location":"system/kubernetes/k3s/","title":"K3S","text":"<p>K3S is a lightweight distribution of Kubernetes and it's tailored for hardware with limited resources. It's easy to set up on embedded computers and stuiable for use in small-scale applications.</p>"},{"location":"system/kubernetes/k3s/#install-k3s-cluster","title":"Install K3S cluster","text":"<ul> <li>Install master</li> </ul> <pre><code>$ curl -sfL https://get.k3s.io | sh -\n</code></pre> <ul> <li>Install agent node</li> </ul> <pre><code>$ curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh -\n\n# or if you want to install a specific version \n$ curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=\"v1.30.6+k3s1\" K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh -\n\n# you may check version your existing nodes\n$ kubectl version\n</code></pre> <p>Note that you need to update <code>myserver</code> to your actual server address. <code>mynodetoken</code> can be found at <code>/var/lib/rancher/k3s/server/node-token</code> on the server node.</p>"},{"location":"system/kubernetes/k3s/#uninstall-k3s-cluster","title":"Uninstall K3S cluster","text":"<ul> <li>Uninstall the master node</li> </ul> <pre><code>$ /usr/local/bin/k3s-uninstall.sh\n</code></pre> <ul> <li>Uninstall the agent node</li> </ul> <pre><code>$ /usr/local/bin/k3s-agent-uninstall.sh\n</code></pre>"},{"location":"system/kubernetes/k3s/#reset-k3s-cluster","title":"Reset K3S cluster","text":"<ul> <li>For the master node</li> </ul> <pre><code>$ sudo systemctl stop k3s\n$ sudo rm -rf /var/lib/rancher/k3s\n$ sudo rm -rf /etc/rancher/k3s\n$ sudo systemctl start k3s\n</code></pre> <ul> <li>For the agent nodes</li> </ul> <pre><code>$ sudo systemctl stop k3s-agent\n$ sudo rm -rf /var/lib/rancher/k3s/agent\n$ sudo rm -rf /etc/rancher/k3s/agent\n$ sudo systemctl start k3s-agent\n</code></pre>"},{"location":"system/kubernetes/k3s/#reset-the-certificates","title":"Reset the certificates","text":"<pre><code>$ sudo rm /var/lib/rancher/k3s/server/tls/dynamic-cert.json\n$ sudo kubectl --insecure-skip-tls-verify=true delete secret -n kube-system k3s-serving\n$ sudo systemctl restart k3s\n</code></pre> <p>To verify that all K3S internal certificates are valid:</p> <pre><code>$ sudo su\n$ for i in `ls /var/lib/rancher/k3s/server/tls/*.crt`; do echo $i; openssl x509 -enddate -noout -in $i; done\n\n$ curl -v -k https://localhost:6443\n</code></pre>"},{"location":"system/kubernetes/k3s/#remove-a-client-node","title":"Remove a client node","text":"<pre><code>$ kubectl drain &lt;node-name&gt;\n\n# you may need to ignore daemonsets and delete local-data\n$ kubectl drain &lt;node-name&gt; --ignore-daemonsets --delete-local-data\n\n$ kubectl delete node &lt;node-name&gt;\n</code></pre>"},{"location":"system/kubernetes/k3s/#purge-a-namespace","title":"Purge a namespace","text":"<pre><code># delete by type\n$ kubectl delete all --all -n mynamespace\n$ kubectl delete configmaps --all -n mynamespace\n$ kubectl delete secrets --all -n mynamespace\n$ kubectl delete pvc --all -n mynamespace\n$ kubectl delete ingress --all -n mynamespace\n$ kubectl delete namespace mynamespace\n\n# or combine into one command\n$ kubectl api-resources --verbs=list --namespaced -o name \\\n  | xargs -n 1 kubectl delete --all -n mynamespace\n</code></pre> <p>If the command to delete the namespace get stuck:</p> <pre><code>$ kubectl edit namespace &lt;namespace&gt;\n</code></pre> <p>Remove the finalizers section and save. Then try to delete the namespace again:</p> <pre><code>$ kubectl delete namespace arc-runners\n</code></pre>"},{"location":"system/kubernetes/k3s/#manage-images-of-the-cluster","title":"Manage images of the cluster","text":"<p>To see what images have been pulled locally</p> <pre><code>sudo k3s crictl images \n</code></pre> <p>To delete any images no currently used by a running container</p> <pre><code>sudo k3s crictl rmi --prune \n</code></pre>"},{"location":"system/kubernetes/k3s/#check-status-of-pods","title":"Check status of pods","text":"<p>If a pod fails to start, you may get information about the error:</p> <pre><code>$ kubectl describe pod &lt;podname&gt; -n &lt;namespace&gt;\n</code></pre> <p>You may also check logs of the pod</p> <pre><code>$ kubectl logs -f &lt;podname&gt;\n</code></pre> <p>To get an overview of all pods in the cluster:</p> <pre><code>$ kubectl get pods --all-namespaces -o wide\n</code></pre>"},{"location":"system/kubernetes/k3s/#reference","title":"Reference","text":"<ul> <li>https://docs.k3s.io/</li> <li>https://stackoverflow.com/questions/35757620/how-to-gracefully-remove-a-node-from-kubernetes</li> </ul>"},{"location":"system/linux/canbus/","title":"CAN Bus in Linux","text":""},{"location":"system/linux/canbus/#bring-up-can-interface","title":"Bring up CAN Interface","text":"<p>Note that the maximum bitrate depends on your specific hardware, for example PiCAN2 supports up to 1Mbps.</p> <pre><code>$ sudo ip link set can0 up type can bitrate 1000000\n</code></pre> <p>To automatically bring up the interface during boot, you can modify \"/etc/network/interfaces\"</p> <pre><code>$ sudo nano /etc/network/interfaces\n</code></pre> <p>Add the following lines</p> <pre><code>auto can0\n    iface can0 inet manual\n    up /sbin/ip link set can0 up type can bitrate 1000000 \n    post-up /sbin/ip link set can0 txqueuelen 1000\n    down /sbin/ip link set can0 down\n</code></pre> <p>You can check if CAN is brought up by using command \"ifconfig\". You should see something similar to this</p> <pre><code>$ can0: flags=193&lt;UP,RUNNING,NOARP&gt;  mtu 16\n$     unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 10  (UNSPEC)\n$     RX packets 4  bytes 32 (32.0 B)\n$     RX errors 0  dropped 0  overruns 0  frame 0\n$     TX packets 4  bytes 32 (32.0 B)\n$     TX errors 1  dropped 1 overruns 0  carrier 1  collisions 0\n</code></pre>"},{"location":"system/linux/canbus/#loopback-test","title":"Loopback Test","text":"<p>You can use the loopback mode to test if PiCAN2 is working properly. You need to enable the loopback mode first.</p> <pre><code>$ sudo ip link set can0 down\n$ sudo ip link set can0 type can loopback on\n$ sudo ip link set can0 up type can bitrate 1000000\n</code></pre> <p>Now open two terminals, one as sender and one as receiver.</p> <p>In sender terminal:</p> <pre><code>$ cansend can0 001#1122334455667788\n</code></pre> <p>In receiver terminal:</p> <pre><code>$ candump can0\n</code></pre> <p>If successful, you should expect</p> <pre><code>$ candump can0\n$ can0  001   [8]  11 22 33 44 55 66 77 88\n$ can0  001   [8]  11 22 33 44 55 66 77 88\n</code></pre> <p>Turn off the loopback mode:</p> <pre><code>$ sudo ip link set can0 down\n$ sudo ip link set can0 type can loopback off\n$ sudo ip link set can0 up type can bitrate 1000000\n</code></pre>"},{"location":"system/linux/canbus/#log-frames-and-playback","title":"Log Frames and Playback","text":"<p>You can log can frames from a CAN interface to a file for debugging</p> <pre><code>$ candump -l can0\n</code></pre> <p>Then you can playback the log file</p> <pre><code>$ canplayer -I &lt;candump-log-file-name&gt;.log\n</code></pre>"},{"location":"system/linux/canbus/#dump-frames-with-filter-mask","title":"Dump Frames with Filter Mask","text":"<p>Dump can frames with filter</p> <pre><code>$ candump can0,&lt;interested-can-id(s)&gt;:&lt;filter-mask&gt;\n</code></pre> <p>Example:</p> <pre><code>$ candump can0,602:1fffffff\n</code></pre> <p>The example command dumps CAN message with ID 0x602 from can0. If you wang to dump all messages with ID 0x60x, you can adjust the filter to be 1ffffff0.</p>"},{"location":"system/linux/canbus/#more-commands","title":"More Commands","text":"<p>Use this command to find more information of CAN related commands</p> <pre><code>$ ip link set can0 up type can help\n</code></pre>"},{"location":"system/linux/canbus/#reference","title":"Reference","text":"<ul> <li>[1] http://copperhilltech.com/pican2-controller-area-network-can-interface-for-raspberry-pi/</li> <li>[2] https://raspberrypi.stackexchange.com/questions/51829/unable-to-bring-can-interface-up-on-raspberry-pi-3</li> <li>[3] https://www.raspberrypi.org/forums/viewtopic.php?t=141052</li> <li>[4] https://harrisonsand.com/can-on-the-raspberry-pi/</li> <li>[5] https://dayba.wordpress.com/2017/05/25/playing-with-socketcan-using-can-utils/</li> <li>[6] http://www.cse.dmu.ac.uk/~eg/tele/CanbusIDandMask.html</li> </ul>"},{"location":"system/linux/command/","title":"Linux Commands","text":""},{"location":"system/linux/command/#add-new-user","title":"Add New User","text":"<pre><code>$ sudo adduser --ingroup users &lt;USERNAME&gt;\n$ sudo adduser &lt;YOUR_USERNAME&gt; sudo\n$ logout\n$ sudo deluser --remove-home user\n</code></pre>"},{"location":"system/linux/command/#setup-wifi","title":"Setup Wifi","text":"<ul> <li>Generate WPA passphrase for your WiFi</li> </ul> <pre><code>$ wpa_passphrase &lt;ssid&gt; &lt;password&gt;\n</code></pre> <ul> <li>Update /etc/network/interfaces</li> </ul> <pre><code>$ sudo nano /etc/network/interfaces\n</code></pre> <pre><code># interfaces(5) file used by ifup(8) and ifdown(8)\nauto lo\niface lo inet loopback\n\nauto wlan0\niface wlan0 inet dhcp\n    wpa-ssid &lt;ExampleWifi&gt;\n    wpa-psk &lt;wpa-psk-generated-by-wpa-passphrase-command&gt;\n</code></pre>"},{"location":"system/linux/command/#update-system-time","title":"Update System Time","text":"<pre><code>$ sudo apt-get install ntp       \n</code></pre>"},{"location":"system/linux/command/#download-file-with-url","title":"Download File with URL","text":"<pre><code>$ curl -O link-to-remote-file\n</code></pre>"},{"location":"system/linux/command/#get-root-privileges","title":"Get Root Privileges","text":"<p>if root user account is enabled.</p> <p><pre><code>$ su\n</code></pre> You can logout using key: Ctrl+D </p> <p>Otherwise if system only allows using sudo</p> <pre><code>$ sudo -i\n</code></pre>"},{"location":"system/linux/command/#merge-multiple-pdfs","title":"Merge Multiple PDFs","text":"<pre><code># Install pdftk\n$ sudo snap install pdftk\n\n# Merge files\n$ pdftk file1.pdf file2.pdf cat output result.pdf\n</code></pre>"},{"location":"system/linux/command/#extract-pages-from-pdfs","title":"Extract Pages from PDFs","text":"<pre><code>$ sudo apt-get install qpdf\n# extract page 1 to 5 from input.pdf to output.pdf\n$ qpdf input.pdf --pages . 1-5 -- output.pdf\n</code></pre>"},{"location":"system/linux/command/#convert-pdf-to-jpg","title":"Convert PDF to JPG","text":"<pre><code>$ sudo apt install libvips-tools\n$ vips copy input.pdf[dpi=300] output.jpg\n</code></pre>"},{"location":"system/linux/command/#create-gif-animation","title":"Create Gif Animation","text":"<pre><code>$ convert -delay 120 -loop 0 *.png animated.gif\n</code></pre>"},{"location":"system/linux/command/#screenshot-and-screencast","title":"Screenshot and Screencast","text":"<pre><code>$ sudo apt install kazam\n</code></pre>"},{"location":"system/linux/command/#get-statistics-of-a-code-base","title":"Get statistics of a code base","text":"<pre><code>$ sudo apt install cloc\n$ cd &lt;code-folder&gt;\n$ cloc --exclude-dir=cmake,third_party .\n</code></pre>"},{"location":"system/linux/command/#reference","title":"Reference","text":"<ul> <li>[1] https://askubuntu.com/questions/2799/how-to-merge-several-pdf-files</li> </ul>"},{"location":"system/linux/git/","title":"Git Reference","text":""},{"location":"system/linux/git/#find-commit-id-by-commit-message","title":"Find Commit ID by Commit Message","text":"<ul> <li>General search</li> </ul> <pre><code>$ git log --grep=&lt;pattern&gt;\n</code></pre> <ul> <li>Case-insensitive match </li> </ul> <pre><code>$ git log --grep=&lt;pattern&gt; -i\n</code></pre> <ul> <li>Search multiple keywords</li> </ul> <p>Commit message that matches \"pattern1\" or \"pattern2\"</p> <pre><code>$ git log --grep=&lt;pattern1&gt; --grep=&lt;pattern2&gt;\n</code></pre> <p>Commit message that matches \"pattern1\" and \"pattern2\"</p> <pre><code>$ git log --grep=&lt;pattern1&gt; --grep=&lt;pattern2&gt; --all-match\n</code></pre>"},{"location":"system/linux/git/#remove-a-submodule","title":"Remove a submodule","text":"<p>Remove the filetree at , and the submodule's entry in the .gitmodules file <pre><code>$ git rm &lt;path-to-submodule&gt;, and commit.\n</code></pre> <p>\"The .git dir of the submodule is kept around (in the modules/ directory of the main project's .git dir), 'to make it possible to checkout past commits without requiring fetching from another repository'. If you nonetheless want to remove this info, manually delete the submodule's directory in .git/modules/, and remove the submodule's entry in the file .git/config.\"[2]</p> <pre><code>$ rm -rf .git/modules/&lt;path-to-submodule&gt;\n$ git config --remove-section submodule.&lt;path-to-submodule&gt;.\n</code></pre>"},{"location":"system/linux/git/#reference","title":"Reference","text":"<ul> <li>[1] https://www.designcise.com/web/tutorial/how-to-find-git-commit-id-by-commit-message</li> <li>[2] https://stackoverflow.com/a/1260982</li> </ul>"},{"location":"system/linux/gpg/","title":"GPG Reference","text":"<p>GPG (GNU Privacy guard) is an open-source implementation of the OpenPGP protocol. It's often used to sign contents to ensure you're getting authentic information from the original publisher, not a modified version by someone else. It can also be used to encrypt and decrypt contents so that only people with the public key can get access to the contents that are encrypted with the paring private key.</p> <p>Comparatively, GPG is mainly used with information \"at rest\", while TLS and SSH are more often used for data \"in transit\". </p>"},{"location":"system/linux/gpg/#install-gpg","title":"Install GPG","text":"<pre><code>$ sudo apt install gpg\n$ gpg --version\n</code></pre>"},{"location":"system/linux/gpg/#generate-a-key","title":"Generate a Key","text":"<p>If you're generating the key in a graphical environment (where gpg will pop up a window to ask you to type in the password)</p> <pre><code>$ gpg --expert --full-gen-key\n</code></pre> <p>If you generate GPG key on the console or in a pure command-line environment, you should run the command with \"--pinentry-mode=loopback\" argument:</p> <pre><code>$ gpg --expert --pinentry-mode=loopback --full-gen-key\n</code></pre> <p>Example:</p> <pre><code>rdu@rdu-acer:~/Website/notes$ gpg --expert --full-gen-key\ngpg (GnuPG) 2.2.27; Copyright (C) 2021 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nPlease select what kind of key you want:\n   (1) RSA and RSA (default)\n   (2) DSA and Elgamal\n   (3) DSA (sign only)\n   (4) RSA (sign only)\n   (7) DSA (set your own capabilities)\n   (8) RSA (set your own capabilities)\n   (9) ECC and ECC\n  (10) ECC (sign only)\n  (11) ECC (set your own capabilities)\n  (13) Existing key\n  (14) Existing key from card\nYour selection? 9\nPlease select which elliptic curve you want:\n   (1) Curve 25519\n   (3) NIST P-256\n   (4) NIST P-384\n   (5) NIST P-521\n   (6) Brainpool P-256\n   (7) Brainpool P-384\n   (8) Brainpool P-512\n   (9) secp256k1\nYour selection? 1\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      &lt;n&gt;  = key expires in n days\n      &lt;n&gt;w = key expires in n weeks\n      &lt;n&gt;m = key expires in n months\n      &lt;n&gt;y = key expires in n years\nKey is valid for? (0) 1y\nKey expires at Fri 21 Jun 2024 01:57:56 PM +08\nIs this correct? (y/N) y\n\nGnuPG needs to construct a user ID to identify your key.\n\nReal name: Ruixiang Du\nEmail address: ruixiang.du@westonrobot.com\nComment: test keygen\nYou selected this USER-ID:\n    \"Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\"\n\nChange (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O\nWe need to generate a lot of random bytes. It is a good idea to perform\nsome other action (type on the keyboard, move the mouse, utilize the\ndisks) during the prime generation; this gives the random number\ngenerator a better chance to gain enough entropy.\nWe need to generate a lot of random bytes. It is a good idea to perform\nsome other action (type on the keyboard, move the mouse, utilize the\ndisks) during the prime generation; this gives the random number\ngenerator a better chance to gain enough entropy.\ngpg: key 713107D9E065DBCE marked as ultimately trusted\ngpg: directory '/home/rdu/.gnupg/openpgp-revocs.d' created\ngpg: revocation certificate stored as '/home/rdu/.gnupg/openpgp-revocs.d/D9304ED388718B0A014F262D713107D9E065DBCE.rev'\npublic and secret key created and signed.\n\npub   ed25519 2023-06-22 [SC] [expires: 2024-06-21]\n      D9304ED388718B0A014F262D713107D9E065DBCE\nuid                      Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\nsub   cv25519 2023-06-22 [E] [expires: 2024-06-21]\n</code></pre>"},{"location":"system/linux/gpg/#manage-keys","title":"Manage Keys","text":"<p>List all keys in your public keyring</p> <pre><code>$ gpg --list-keys\n$ gpg --list-secret-key\n</code></pre> <p>List all keys with signature</p> <pre><code>$ gpg --list-sigs\n</code></pre> <p>Check your keys generated with your email</p> <pre><code>$ gpg --list-sigs &lt;your-email&gt;\n</code></pre> <p>Delete a key</p> <pre><code>$ gpg --delete-key &lt;key-id&gt;\n</code></pre> <p>Example:</p> <pre><code>$ gpg --list-sigs ruixiang.du@westonrobot.com\ngpg: checking the trustdb\ngpg: marginals needed: 3  completes needed: 1  trust model: pgp\ngpg: depth: 0  valid:   1  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 1u\ngpg: next trustdb check due at 2024-06-21\npub   ed25519 2023-06-22 [SC] [expires: 2024-06-21]\n      D9304ED388718B0A014F262D713107D9E065DBCE\nuid           [ultimate] Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\nsig 3        713107D9E065DBCE 2023-06-22  Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\nsub   cv25519 2023-06-22 [E] [expires: 2024-06-21]\nsig          713107D9E065DBCE 2023-06-22  Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\n</code></pre> <p>In the above example, 713107D9E065DBCE is the key ID and D9304ED388718B0A014F262D713107D9E065DBCE is the key fingerprint.</p>"},{"location":"system/linux/gpg/#export-keys-to-files","title":"Export Keys to Files","text":"<pre><code>$ gpg --armor --export &lt;key-id&gt; &gt; pubkey.asc\n$ gpg --export-secret-keys --armor &lt;key-id&gt; &gt; privkey.asc\n</code></pre> <p>You can name the file to anything you want. But \"normally, .sig is used for detached signatures using the binary OpenPGP format, and .asc for when the contents are ASCII-armored. For everything else, .gpg is common for the binary format, .asc when armored.\" [2]</p>"},{"location":"system/linux/gpg/#share-public-keys-on-public-keyserver","title":"Share Public Keys on Public Keyserver","text":"<p>Note you should only share public keys with others and never share your private keys.</p> <pre><code>$ gpg --send-key &lt;key-id&gt;\n</code></pre> <p>By default, it will send the key to \"https://keys.openpgp.org/\", you can specify a different keyserver, for example</p> <pre><code>$ gpg --keyserver hkps://keyserver.ubuntu.com --send-key &lt;key-id&gt;\n</code></pre>"},{"location":"system/linux/gpg/#import-keys-from-filekeyserver","title":"Import Keys from File/Keyserver","text":"<pre><code>$ gpg --import &lt;key-file&gt;\n$ gpg --recv-keys &lt;key-id&gt;\n</code></pre>"},{"location":"system/linux/gpg/#extend-key-expiration-date","title":"Extend Key Expiration Date","text":"<p>You can modify the expiration date for both the primary key (0) and subkey (1). Read more about subkeys here [4].</p> <pre><code>$ gpg --pinentry-mode=loopback --edit-key &lt;key-id&gt;\ngpg&gt; key 0\ngpg&gt; expire\n# enter new date and confirm\ngpg&gt; key 1\ngpg&gt; expire\n# enter new date and confirm\ngpg&gt; save\n</code></pre> <p>Example:</p> <pre><code>$ gpg --pinentry-mode=loopback --edit-key 713107D9E065DBCE\ngpg (GnuPG) 2.2.27; Copyright (C) 2021 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nSecret key is available.\n\nsec  ed25519/713107D9E065DBCE\n     created: 2023-06-22  expires: 2024-06-21  usage: SC  \n     trust: ultimate      validity: ultimate\nssb  cv25519/FCFBABCEE6D345D4\n     created: 2023-06-22  expires: 2024-06-21  usage: E   \n[ultimate] (1). Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\ngpg&gt; key 0\n\nsec  ed25519/713107D9E065DBCE\n     created: 2023-06-22  expires: 2024-06-21  usage: SC  \n     trust: ultimate      validity: ultimate\nssb  cv25519/FCFBABCEE6D345D4\n     created: 2023-06-22  expires: 2023-06-23  usage: E   \n[ultimate] (1). Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\n\ngpg&gt; expire\nChanging expiration time for the primary key.\nPlease specify how long the key should be valid.\n         0 = key does not expire\n      &lt;n&gt;  = key expires in n days\n      &lt;n&gt;w = key expires in n weeks\n      &lt;n&gt;m = key expires in n months\n      &lt;n&gt;y = key expires in n years\nKey is valid for? (0) 1\nKey expires at Fri 23 Jun 2023 03:10:59 PM +08\nIs this correct? (y/N) y\n\nsec  ed25519/713107D9E065DBCE\n     created: 2023-06-22  expires: 2023-06-23  usage: SC  \n     trust: ultimate      validity: ultimate\nssb  cv25519/FCFBABCEE6D345D4\n     created: 2023-06-22  expires: 2023-06-23  usage: E   \n[ultimate] (1). Ruixiang Du (test keygen) &lt;ruixiang.du@westonrobot.com&gt;\n\ngpg: WARNING: Your encryption subkey expires soon.\ngpg: You may want to change its expiration date too.\ngpg&gt; save\n</code></pre>"},{"location":"system/linux/gpg/#reference","title":"Reference","text":"<ul> <li>[1] https://www.linuxbabe.com/security/a-practical-guide-to-gpg-part-1-generate-your-keypair</li> <li>[2] https://superuser.com/questions/814355/what-file-extensions-should-be-used-on-gpg-generated-output</li> <li>[3] https://www.linuxbabe.com/security/gpg-guide-public-key-management</li> <li>[4] https://wiki.debian.org/Subkeys</li> </ul>"},{"location":"system/linux/gpsd/","title":"GPSd Reference","text":"<p>gpsd is a service daemon that monitors GNSS receiver devices, inteprets the serial data and make the data available on TCP port 2947 for other programs to consume.</p>"},{"location":"system/linux/gpsd/#installation","title":"Installation","text":"<p>You can install gpsd from apt-get on Ubuntu and Debian.</p> <pre><code>$ sudo apt-get install gpsd\n</code></pre> <p>After installation, there are two systemd services installed automatically. You can disable the two services or modify them according to your needs.</p> <pre><code>$ sudo systemctl stop gpsd.socket\n$ sudo systemctl disable gpsd.socket\n</code></pre> <p>The \"gpsd.socket\" service monitors the 2947 port and triggers the gpsd.service to start if it detects any client applications trying to listen to the port. If you don't need this auto-triggering, you can disable this socket monitor.</p>"},{"location":"system/linux/gpsd/#typical-usage","title":"Typical Usage","text":""},{"location":"system/linux/gpsd/#monitor-a-gps-receiver","title":"Monitor a GPS receiver","text":"<p>You can use gpsd to connect to a GPS receiver via serial/USB port:</p> <pre><code>$ sudo gpsd -D4 -N -n -s 115200 /dev/ttyUSB0\n</code></pre> <p>In the about example, the command has the following additional arguments:</p> <ul> <li>-D4: enable level 4 logging</li> <li>-N: to keep the program running at foreground</li> <li>-n: no need to wait for client application to connect</li> <li>-s: to set the baudrate to be 115200</li> <li>/dev/ttyUSB0: the port the GPS receiver is connected to</li> </ul> <p>If the gpsd connects to the port successfully, you can use cgps to monitor the state of the GPS receiver:</p> <pre><code>$ cgps\n</code></pre>"},{"location":"system/linux/gpsd/#feed-rtcm-data-to-a-rtk-receiver","title":"Feed RTCM data to a RTK receiver","text":"<p>If your GPS receiver supports differential or RTK mode, you can feed the correction data from a NTRIP server to the receiver:</p> <pre><code>$ sudo gpsd -G ntrip://&lt;user-name&gt;:&lt;password&gt;@&lt;ntrip-server-address&gt;:&lt;ntrip-service-port&gt;/&lt;service-endpoint&gt; -D4 -N -n -s 115200 /dev/ttyUSB0\n</code></pre> <p>With this command, you can feed the RTCM data to the receiver as well as receiving corrected positioning data from the receiver.</p> <pre><code>$ cgps -s\n</code></pre> <p>You should see something similar to this screenshot</p> <p></p>"},{"location":"system/linux/journalctl/","title":"Journalctl Reference","text":""},{"location":"system/linux/journalctl/#list-journal-entries-from-boot","title":"List Journal Entries from Boot","text":"<ul> <li>List logs from current boot</li> </ul> <pre><code>$ journalctl -b\n</code></pre> <ul> <li>List logs from past boots</li> </ul> <pre><code>$ journalctl --list-boots\n$ journalctl -b &lt;boot-id&gt;\n# example\n$ journalctl -b -1\n</code></pre>"},{"location":"system/linux/journalctl/#list-logs-based-on-time","title":"List Logs Based on Time","text":"<pre><code>$ journalctl --since \"2022-02-04 12:40:49\u201d\n$ journalctl --since \"2015-06-26 23:15:00\" --until \"2015-06-26 23:20:00\"\n$ journalctl --since \"yesterday\"\n$ journalctl --since 10:10 --until \"1 hour ago\"\n</code></pre>"},{"location":"system/linux/journalctl/#list-logs-based-on-service-unit","title":"List Logs Based on Service Unit","text":"<ul> <li>Check logs from a single service</li> </ul> <pre><code>$ journalctl -u &lt;service-name.service&gt;\n# example\n$ journalctl -u nginx.service --since today\n</code></pre> <ul> <li>Check interleaved records from multiple units</li> </ul> <pre><code>$ journalctl -u nginx.service -u php-fpm.service --since today\n</code></pre> <ul> <li>Following logs of services</li> </ul> <pre><code>$ journalctl -fu &lt;service-name.service&gt;\n</code></pre> <ul> <li>List last n entries from the logs</li> </ul> <pre><code>$ journalctl -n &lt;number-of-entries&gt;\n</code></pre>"},{"location":"system/linux/journalctl/#journalctl-storage","title":"Journalctl Storage","text":"<ul> <li>Check existing disk usage</li> </ul> <pre><code>$ journalctl --disk-usage\n</code></pre> <ul> <li>Delete old logs</li> </ul> <pre><code>$ sudo journalctl --vacuum-size=1G\n$ sudo journalctl --vacuum-time=1years\n</code></pre> <ul> <li>Keep logs persistent</li> </ul> <pre><code>$ sudo nano /etc/systemd/journald.conf\n</code></pre> <pre><code>[Journal]\nStorage=persistent\n</code></pre> <ul> <li>Limit journal storage</li> </ul> <p>You can set the storage limits in \"/etc/systemd/journald.conf\" by setting values to the following entries [1] </p> <ul> <li>SystemMaxUse=: Specifies the maximum disk space that can be used by the journal in persistent storage.</li> <li>SystemKeepFree=: Specifies the amount of space that the journal should leave free when adding journal entries to persistent storage.</li> <li>SystemMaxFileSize=: Controls how large individual journal files can grow to in persistent storage before being rotated.</li> <li>RuntimeMaxUse=: Specifies the maximum disk space that can be used in volatile storage (within the /run filesystem).</li> <li>RuntimeKeepFree=: Specifies the amount of space to be set aside for other uses when writing data to volatile storage (within the /run filesystem). RuntimeMaxFileSize=: Specifies the amount of space that an individual journal file can take up in volatile storage (within the /run filesystem) before being rotated.</li> </ul>"},{"location":"system/linux/journalctl/#reference","title":"Reference","text":"<ul> <li>[1] https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs</li> <li>[2] https://www.loggly.com/ultimate-guide/using-journalctl/</li> <li>[3] https://www.loggly.com/ultimate-guide/linux-logging-with-systemd/</li> </ul>"},{"location":"system/linux/ssh/","title":"SSH Reference","text":""},{"location":"system/linux/ssh/#setup-authorized_keys","title":"Setup authorized_keys","text":"<p>If you don't want to always type in password to access a remote server, you can create a keypair on your local machine and add the public key to the remote servers' authorized_keys file.</p> <p>On your local machine:</p> <pre><code># create a ssh key pair\n$ ssh-keygen -f ~/.ssh/my_sshkey -t rsa -b 4096\n# transfer the public key to the server\n$ scp ~/.ssh/my_sshkey.pub &lt;username&gt;@&lt;server-address&gt;:~/.ssh\n</code></pre> <p>Note: you're only supposed to share the \"PUBLIC\" key to the remote server.</p> <p>On the remote server:</p> <pre><code>$ cat ~/.ssh/my_sshkey.pub &gt;&gt; ~/.ssh/authorized_keys\n</code></pre> <p>A simpler method to copy the public key to the remote server is to use the \"ssh-copy-id\" tool.</p> <pre><code>$ ssh-copy-id -i ~/.ssh/my_sshkey.pub &lt;username&gt;@&lt;server-address&gt;\n</code></pre> <p>Now you can try the SSH access on the local machine:</p> <pre><code># $ ssh -i ~/.ssh/my_sshkey &lt;username&gt;@&lt;server-address&gt;\n</code></pre> <p>If you don't want to pass in the argument \"-i ~/.ssh/my_sshkey\" everytime, you can add the following to your \"~/.ssh/config\" file:</p> <pre><code>Host &lt;server-address&gt;\n  Preferredauthentications publickey\n  IdentityFile ~/.ssh/my_sshkey\n</code></pre>"},{"location":"system/linux/ssh/#ssh-agent","title":"SSH Agent","text":"<p>The previous section has shown how to add your public key to the authroized keys list on a remote server. If you generated your SSH key pair with passphrase, you will need to type in the passphrase every time you connect to the server with \"my_sshkey\". In order to simplify this, you can use ssh-agent to store and retrieve the credential for you from the background:</p> <pre><code># start the ssh-agent\n$ eval `ssh-agent`\n# add key to the ssh-agent\n$ ssh-add ~/.ssh/my_sshkey\n# to check all keys added to ssh-agent\n$ ssh-add -l\n# to delete a key from ssh-agent\n$ ssh-add -D &lt;key-to-be-deleted&gt;\n# to delete a key file from ssh-agent\n$ ssh-add -d &lt;key-to-be-deleted&gt;\n</code></pre> <p>Now you only need to type in the passphrase once at the very first time you use the key.</p>"},{"location":"system/linux/ssh/#ssh-agent-forwarding","title":"SSH Agent Forwarding","text":"<p>A typical use case of SSH agent forwarding is when you need SSH access to some resources (e.g. a github repository) from a remote host (e.g. a cloud server or a computer onboard a robot) but you don't want to set up SSH keys on the remote host for security reasons or just for convenience.</p> <pre><code>$ ssh -A &lt;username&gt;@&lt;host-address&gt;\n</code></pre> <p>With the \"-A\" option, you can use your SSH credentials on the server just like you're on the local computer.</p> <p>Note: for security reasons, it's recommended that you only use the agent forwarding when necessary and exit in time when done with work, since someone with root access on the server can possibly gain access to your SSH credentials and impersonate you for unauthorized operations. Also remember not to use the forwarding to a server that you don't trust. For the same reason, it's not recommended to have the \"ForwardAgent yes\" configuration in your \"~/.ssh/config\" for your hosts.</p>"},{"location":"system/linux/ssh/#ssh-proxyjump","title":"SSH ProxyJump","text":"<p>If you want to SSH into a second server (target server) through the first server (bridge server) from you local computer, you can use ProxyJump.</p> <pre><code>$ ssh -J &lt;bridge-server&gt; &lt;target-server&gt; \n</code></pre> <p>You can also setup the ProxyJump from your ssh config file:</p> <pre><code>Host &lt;bridge-server&gt;\n    Preferredauthentications publickey\n    IdentityFile ~/.ssh/my_sshkey\n\nHost &lt;target-server&gt;\n    ProxyJump &lt;bridge-server&gt;\n    User &lt;username&gt;\n</code></pre>"},{"location":"system/linux/ssh/#ssh-port-forwardingtunneling","title":"SSH Port Forwarding/Tunneling","text":"<p>A few examples of port forwarding with SSH from [5]:</p> <ul> <li>Local forwarding</li> </ul> <pre><code>$ ssh -L 80:intra.example.com:80 gw.example.com\n</code></pre> <p>\"This example opens a connection to the gw.example.com jump server, and forwards any connection to port 80 on the local machine to port 80 on intra.example.com.\" </p> <p>For example, you will be able to access the service exposed on port 16686 on the remote server from you local machine at localhost:16686 with the following command:</p> <pre><code>$ ssh -L 16686:localhost:16686 &lt;remote-user&gt;@&lt;remote-server&gt;\n</code></pre> <p>This is particularly useful if you need to access the web interface of a remote service from your local computer.</p> <ul> <li>Remote forwarding</li> </ul> <pre><code>$ ssh -R 8080:localhost:80 public.example.com\n</code></pre> <p>\"This allows anyone on the remote server to connect to TCP port 8080 on the remote server. The connection will then be tunneled back to the client host, and the client then makes a TCP connection to port 80 on localhost. Any other host name or IP address could be used instead of localhost to specify the host to connect to.\"</p> <p>\"This particular example would be useful for giving someone on the outside access to an internal web server. Or exposing an internal web application to the public Internet. This could be done by an employee working from home, or by an attacker.\"</p> <ul> <li>Reverse SSH tunnel</li> </ul> <p>The reverse tunneling is essentially the use of remote fowarding. The following example is from [4]:</p> <p>\"For instance, to connect to your_domain on port 80 on our local computer, making the connection available on our remote host on port 8888, you could type:\"</p> <pre><code>$ ssh -f -N -R 8888:your_domain:80 username@remote_host\n</code></pre> <p>\"Now, on the remote host, opening a web browser to 127.0.0.1:8888 would allow you to see whatever content is at your_domain on port 80.\"</p> <p>The extra \"-fN\" arguments tells SSH to go to background just before command execution and do not execute a remote command. [7]</p> <p>In the above example, if you want to terminate the forwarding, you need to find the process id first and then kill the process:</p> <pre><code>$ ps aux | grep 8888\n</code></pre> <pre><code>Output\n1001      5965  0.0  0.0  48168  1136 ?        Ss   12:28   0:00 ssh -f -N -R 8888:your_domain:80 username@remote_host\n1001      6113  0.0  0.0  13648   952 pts/2    S+   12:37   0:00 grep --colour=auto 8888\n</code></pre> <p>Now you can kill the process with id 5965</p> <pre><code>$ kill 5965\n</code></pre>"},{"location":"system/linux/ssh/#reference","title":"Reference","text":"<ul> <li>[1] https://dev.to/levivm/how-to-use-ssh-and-ssh-agent-forwarding-more-secure-ssh-2c32</li> <li>[2] https://smallstep.com/blog/ssh-agent-explained/</li> <li>[3] https://www.cnblogs.com/f-ck-need-u/p/10484531.html</li> <li>[4] https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys</li> <li>[5] https://www.ssh.com/academy/ssh/tunneling/example</li> <li>[6] https://jfrog.com/connect/post/reverse-ssh-tunneling-from-start-to-end/#:~:text=Reverse%20SSH%20Tunneling%20enables%20you,have%20a%20public%20IP%20address.</li> <li>[7] https://linuxcommand.org/lc3_man_pages/ssh1.html</li> </ul>"},{"location":"system/linux/systemd/","title":"Systemd Reference","text":""},{"location":"system/linux/systemd/#systemd-utils","title":"Systemd Utils","text":"<ul> <li>To list all services</li> </ul> <pre><code>$ sudo systemctl list-units --type=service\n</code></pre> <ul> <li>To start/stop/restart/status/enable/disable a service</li> </ul> <pre><code>$ sudo systemctl [start/stop/restart/status/enable/disable] &lt;service-name&gt;\n</code></pre> <p>To enable a service means that the service will be started at boot time.</p> <ul> <li>To check boot time of all the services</li> </ul> <pre><code>$ sudo systemd-analyze blame\n</code></pre> <ul> <li>To check the log of a service</li> </ul> <pre><code>$ sudo journalctl -u &lt;service-name&gt;\n</code></pre> <p>If you want to follow the log, you can use the <code>-f</code> option, e.g. <code>sudo journalctl -fu &lt;service-name&gt;</code>.</p> <ul> <li>To reload all the unit files after making changes</li> </ul> <pre><code>$ sudo systemctl daemon-reload\n</code></pre>"},{"location":"system/linux/systemd/#systemd-unit-files","title":"Systemd Unit Files","text":"<p>Systemd unit files may be loaded from multiple locations. The main ones are (listed from lowest to highest precedence): </p> <ul> <li>/usr/lib/systemd/system/: units provided by installed packages</li> <li>/etc/systemd/system/: units installed by the system administrator</li> </ul> <p>A typical systemd unit file looks like this:</p> <pre><code>[Unit]\nDescription=sample service\nRequires=udisks2.service\nRequires=graphical.target\nAfter=graphical.target\n\n[Service]\nUser=root\nType=oneshot\nExecStartPre=/bin/sh -c 'echo \"pre start\"'\nExecStart=/usr/bin/notify-send \"Hello World\"\nExecStartPost=/bin/sh -c 'echo \"post start\"'\nExecStop=/usr/local/bin/handle_external_hdds.sh\nRestart=on-failure\nTimeoutSec=2s\nRestartSec=5s\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"system/linux/systemd/#unit-section","title":"[Unit] Section","text":"<p>In the [Unit] section, you can specify dependencies of the service:</p> <ul> <li>Requires: mandatory dependencies</li> <li>Wants: optional dependencies</li> <li>After: the service will be started after the specified services</li> </ul> <p>\"Note that Wants= and Requires= do not imply After=, meaning that if After= is not specified, the two units will be started in parallel.\"[1]</p> <p>If you need to wait for a hardware to be ready before your service, you can use the following command to check if the device is managed by systemd:</p> <pre><code>$ systemctl list-units\n# for example, if you want to wait for usb0\n$ systemctl list-units | grep ttyAMA1\n</code></pre> <p>You may find a unit like: \"sys-devices-platform-soc-fe201600.serial-tty-ttyAMA1.device\". Then in your unit section you can specify the dependency:</p> <pre><code>[Unit]\nDescription=Example service that requires ttyAMA1\nRequires=sys-devices-platform-soc-fe201600.serial-tty-ttyAMA1.device\nAfter=sys-devices-platform-soc-fe201600.serial-tty-ttyAMA1.device\n</code></pre>"},{"location":"system/linux/systemd/#service-section","title":"[Service] Section","text":"<p>In the [Service] secion, you can specify what the service does.</p> <p>Service type can one of simple/forking/oneshot/dbus/simple/notify. </p> <ul> <li>The default type is \"simple\" if \"Type\" is not set but \"ExecStart\" is set.</li> <li>The default type is \"oneshot\" if both \"Type\" and \"ExecStart\" are not set.</li> </ul> <p>The \"oneshot\" type \"indicates that the process will be short-lived and that systemd should wait for the process to exit before continuing on with other units.\"[2]</p> <p>To configure the service to auto-restart, you can use the following options [2]:</p> <ul> <li>Restart=always/on-success/on-failure/on-abnormal/on-abort/on-watchdog</li> <li>RestartSec=: the amount of time to wait before attempting to restart the service</li> <li>TimeoutSec=: the amount of time that systemd will wait when stopping or stopping the service before marking it as failed or forcefully killing it</li> </ul>"},{"location":"system/linux/systemd/#examples","title":"Examples","text":"<ul> <li>Systemd service unit to start a hardware interface</li> </ul> <pre><code>[Unit]\nDescription=Bringup CAN interface\nWants=network-online.target\nAfter=network.target network-online.target\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStartPre=/sbin/modprobe can\nExecStart=/sbin/ip link set can0 up type can bitrate 500000\nExecStop=/sbin/ip link set can0 down\n\n[Install]\nWantedBy=network-online.target\n</code></pre> <ul> <li>Systemd service unit for starting a docker compose application</li> </ul> <pre><code>[Unit]\nDescription=Sample Service\nRequires=docker.service udev.service\nAfter=docker.service udev.service\n\n[Service]\nWorkingDirectory=/home/username/docker/app\nExecStart=/usr/bin/docker compose up\nExecStop=/usr/bin/docker compose down\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"system/linux/systemd/#reference","title":"Reference","text":"<ul> <li>[1] https://wiki.archlinux.org/title/systemd</li> <li>[2] https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files</li> <li>[3] https://man.archlinux.org/man/systemd.service.5#EXAMPLES</li> </ul>"},{"location":"system/linux/tmux/","title":"Tmux Reference","text":"<p>tmux provides two main functions: window management in the terminal and session management. Around the two functions, there are a few core concepts you need to understand:</p> <ul> <li>A session contains a group of windows<ul> <li>A window contains one or more panels<ul> <li>A panel contains a terminal where you can run programs inside</li> </ul> </li> </ul> </li> </ul> <p>You can detatch from a session and re-attach to the same session again later so that you can resume your previous work. You can find the session/window/panel information from the status line, as shown in the following diagram[1].</p> <p></p> <p>Most tmux commands are carried out with the prefix key \"C-b\", which means you keep \"Ctrl\" and \"B\" key pressed together. Shortly after releasing the two keys, press another key for a specific command. For example, with \"C-b\" + \"%\", you can split a panel into a left and right panels. </p>"},{"location":"system/linux/tmux/#setup-tmux","title":"Setup tmux","text":"<ul> <li>Install tmux</li> </ul> <pre><code>$ sudo apt install tmux\n</code></pre> <ul> <li>Enable mouse support</li> </ul> <pre><code>$ tmux set-option mouse on\n</code></pre>"},{"location":"system/linux/tmux/#session-management","title":"Session Management","text":"<ul> <li>Create a new named session</li> </ul> <pre><code>$ tmux new [-t] -s mysession\n</code></pre> <p>With the \"-t\" argument the new session is detached automatically after creation.</p> <ul> <li> <p>Detach from the current session: C-b d</p> </li> <li> <p>List existing sessions</p> </li> </ul> <pre><code>$ tmux ls\n</code></pre> <ul> <li>Attach to a session</li> </ul> <pre><code># attach to session with id\n$ tmux attach -t 0\n# attach to a named session\n$ tmux attach -t mysession\n</code></pre> <ul> <li>Rename an existing session</li> </ul> <pre><code>$ tmux rename-session -t 0 mysession2\n</code></pre>"},{"location":"system/linux/tmux/#window-management","title":"Window Management","text":"<ul> <li>Create a new window: C-b c</li> <li>Rename the current window: C-b ,</li> <li>Change to window 0: C-b 0</li> <li>Change to next window: C-b n</li> <li>Change to previous window: C-b p</li> <li> <p>Change to the last window: C-b l</p> </li> <li> <p>Create a new named window</p> </li> </ul> <pre><code>$ tmux new-window [-d] -n mynewwindow\n</code></pre> <p>If the argument \"-d\" is specified, tmux will only create the new window but does not make the new window to be the current window.</p>"},{"location":"system/linux/tmux/#panel-management","title":"Panel Management","text":"<ul> <li>Splits the current panel into two horizontally: C-b %</li> <li>Splits the current panel into two vertically: C-b \"</li> <li>Switch between the panels: C-b &lt;arrow-key&gt;</li> <li>Resize panel in direction of arrow key: C-b C-&lt;arrow-key&gt;</li> <li>Toggle full-screen mode of the current panel: C-b z</li> </ul>"},{"location":"system/linux/tmux/#session-and-window-in-tree-view","title":"Session and Window in Tree View","text":"<ul> <li>Show sessions: C-b s</li> <li>Show windows of current session: C-b w</li> <li>Exit tree view mode: q</li> </ul>"},{"location":"system/linux/tmux/#reference","title":"Reference","text":"<ul> <li>[1] https://github.com/tmux/tmux/wiki/Getting-Started</li> <li>[2] https://man7.org/linux/man-pages/man1/tmux.1.html</li> <li>[3] https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/</li> </ul>"},{"location":"system/linux/udev-rules/","title":"Udev Reference","text":""},{"location":"system/linux/udev-rules/#create-a-new-udev-rule","title":"Create a New udev Rule","text":"<p>All udev rules are placed at \"/etc/udev/rules.d\". The file follow the naming convension \"[priority]-[name].rules\", for example, \"90-camera.rules\". The lower the priority number, the higher the priority of the rule. When a device is added or removed from the system, rules with higher priority are processed first.</p>"},{"location":"system/linux/udev-rules/#add-new-rules-for-a-device","title":"Add New Rules for a Device","text":"<p>A typical rule may look like this:</p> <pre><code>SUBSYSTEMS==\"usb\", KERNEL==\"ttyACM[0-9]*\", ACTION==\"add\", ATTRS{idVendor}==\"15d1\", ATTRS{idProduct}==\"0000\", MODE=\"666\", PROGRAM=\"/opt/ros/kinetic/lib/urg_node/getID /dev/%k q\", SYMLINK+=\"sensors/hokuyo_%c\", GROUP=\"dialout\"\n</code></pre> <p>You can inteprate the rule as two parts:</p> <pre><code>[matching-conditions] [configurations]\n</code></pre> <p>The rule can be understood as: if \"[matching-conditions]\" are met, then apply \"[configurations]\".</p> <p>For the matching part, you can use pattern matching. The following pattern matching rules and examples are taken from [1]:</p> <pre><code>* - match any character, zero or more times\n? - match any character exactly once\n[] - match any single character specified in the brackets, ranges are also permitted\n</code></pre> <p>For example: </p> <pre><code>KERNEL==\"fd[0-9]*\", NAME=\"floppy/%n\", SYMLINK+=\"%k\"\nKERNEL==\"hiddev*\", NAME=\"usb/%k\"\n</code></pre> <p>Once a devide is matched, you can perform certain configurations, such as adding a symbolic link to the device node or name the device with a certain name. For example, you can create a symlink as \"/dev/my-camera\" to the device node matching the following \"KERNEL\" and \"SUBSYSTEM\" conditions:</p> <pre><code>KERNEL==\"video[0-10]\", SUBSYSTEM==\"video4linux\", ATTR{index}==\"0\", KERNELS==\"1-8.1\", ATTRS{idVendor}==\"05a3\", ATTRS{idProduct}==\"9320\", SYMLINK+=\"my-camera\"\n</code></pre>"},{"location":"system/linux/udev-rules/#find-attribute-information-of-a-device-node","title":"Find Attribute Information of a Device Node","text":"<p>You can use the following command to find the attribute information of a device node:</p> <pre><code>$ udevadm info -a -p $(udevadm info -q path -n /dev/video0)\n</code></pre> <p>You can use the attributes of the device node or additional attributes from one of its parents to create a match condition. Note that you can not mix attributes from different parents.</p> <p>The following screenshot shows what you may get by checking node \"/dev/video0\":</p> <p></p> <p>You can see how the sample rule shown in the previous section are created from the above information. Within the rule, the \"KERNEL\", \"SUBSYSTEM\", and \"ATTR{inde}\" are from the device node itself, while the \"KERNELS\" and \"ATTRS{idVendor}\" are from one of the parent nodes.</p>"},{"location":"system/linux/udev-rules/#reload-and-trigger-new-rules","title":"Reload and Trigger New Rules","text":"<pre><code>$ sudo udevadm control --reload-rules\n$ sudo udevadm trigger --attr-match=subsystem=usb\n</code></pre>"},{"location":"system/linux/udev-rules/#reference","title":"Reference","text":"<ul> <li>[1] http://www.reactivated.net/writing_udev_rules.html</li> <li>[2] https://www.clearpathrobotics.com/assets/guides/kinetic/ros/Udev%20Rules.html</li> </ul>"},{"location":"system/linux/v4l2/","title":"V4L2 Reference","text":"<p>Video4Linux (V4L for short) is a collection of device drivers and an API for supporting realtime video capture on Linux systems.[1]</p>"},{"location":"system/linux/v4l2/#installation","title":"Installation","text":"<p>The v4l2 drivers should have been integrated with the kernel in most recent Linux distributions. But you may need to install the utils separately.</p> <pre><code>$ sudo apt install v4l-utils\n</code></pre> <p>For this package you get \"v4l2-ctl\".</p>"},{"location":"system/linux/v4l2/#v4l2-ctl","title":"v4l2-ctl","text":"<ul> <li>Check v4l2 version    </li> </ul> <pre><code>$ v4l2-ctl --version\n</code></pre> <ul> <li>List available v4l2 devices</li> </ul> <pre><code>$ v4l2-ctl --list-devices\n</code></pre> <ul> <li>List supported formats of a device</li> </ul> <pre><code>$ v4l2-ctl --list-formats\n$ v4l2-ctl --list-formats-ext \n$ v4l2-ctl --list-formats-ext --device /dev/video0\n</code></pre> <ul> <li>Set format to a device</li> </ul> <pre><code>$ v4l2-ctl --device /dev/video0 --set-fmt-video=pixelformat=MJPG\n</code></pre> <ul> <li>List available controls of a device</li> </ul> <pre><code>$ v4l2-ctl --list-ctrls --device /dev/video0\n</code></pre> <ul> <li>Set control of a device</li> </ul> <pre><code>$ v4l2-ctl --device /dev/video0 --set-ctrl control_name=value\n</code></pre>"},{"location":"system/linux/v4l2/#typical-use-cases","title":"Typical Use Cases","text":"<ul> <li>Pull video stream from a v4l2 device with specified format and desired frame rate</li> </ul> <pre><code>$ gst-launch-1.0 v4l2src device=/dev/video0 ! image/jpeg,width=1920,height=1080,framerate=90/1 ! \\\njpegdec ! videoconvert ! fpsdisplaysink text-overlay=true video-sink=\"autovideosink\"\n</code></pre>"},{"location":"system/linux/v4l2/#reference","title":"Reference","text":"<ul> <li>[1] https://en.wikipedia.org/wiki/Video4Linux</li> <li>[2] https://medium.com/@deepeshdeepakdd2/v4l-a-complete-practical-tutorial-c520f097b590</li> <li>[3] https://github.com/PhysicsX/Gstreamer-on-embedded-devices</li> </ul>"},{"location":"system/linux/vim-tutorials/","title":"Vim Tutorials","text":"<ul> <li>https://shapeshed.com/vim-netrw/#you-may-not-need-netrw</li> <li>http://ellengummesson.com/blog/2014/02/22/make-vim-really-behave-like-netrw/</li> <li>https://vimsheet.com/</li> <li>https://devhints.io/vim#operators</li> <li>https://idie.ru/posts/vim-modern-cpp</li> </ul>"},{"location":"system/network/m-dns/","title":"mDNS","text":""},{"location":"system/network/m-dns/#install-mdns-on-ubuntu","title":"Install mDNS on Ubuntu","text":"<p>To get mDNS support, you need to install the following packages:</p> <pre><code>$ sudo apt-get install avahi-daemon libnss-mdns\n</code></pre> <p>Edit the hosts line in: /etc/nsswitch.conf as follows:</p> <pre><code>hosts:          files mdns4_minimal [NOTFOUND=return] dns \n</code></pre> <p>This tells the computer to look first at the hosts file, then at mDNS.</p> <p>With the above setup. your computer should be reachable at <code>hostname.local</code>, for example, <code>rdu-rpi4.local</code>.</p>"},{"location":"system/network/m-dns/#change-the-host-name","title":"Change the Host Name","text":"<p>If you would like to have a different name, you can modify the configuration file <code>/etc/avahi/avahi-daemon.conf</code>. Look for the lines</p> <pre><code>#host-name=foo\n#domain-name=local\n</code></pre> <p>Uncomment the lines and update the names accordingly.</p>"},{"location":"system/network/m-dns/#reference","title":"Reference","text":"<ul> <li>https://support.bostondynamics.com/s/article/Configuring-multicast-DNS</li> <li>https://wiki.archlinux.org/title/avahi</li> </ul>"},{"location":"system/network/netplan/","title":"Netplan Reference","text":""},{"location":"system/network/netplan/#what-is-netplan","title":"What is Netplan","text":"<p>Since Ubuntu 20.04, \"netplan\" is used to manage network interfaces. You can treat netplan as a frontend of network managers. The diagram from the official documentation illustrates this idea very clearly:</p> <p></p> <p>You configure the interfaces with the netplan config files and netplan will render the config files to the backend configs for the programs that actually manages the interface. Currently the two supported backend managers are systemd-networkd and Network Manager. </p> <p>Note: systemd-networkd and Network Manager are not the only two network managers in the Linux world. You may find other network managers such as Wicd, ConnMan in other Linux distributions. Raspberry Pi OS uses dhcpcd to manage the network interfaces by default.</p>"},{"location":"system/network/netplan/#netplan-configuration","title":"Netplan Configuration","text":"<p>Netplan configurations may exist in the following locations (ordered from higher priority to lower):</p> <ul> <li>/run/netplan/*.yaml</li> <li>/etc/netplan/*.yaml</li> <li>/lib/netplan/*.yaml</li> </ul> <p>\"Alphabetically later files, no matter what directory in, will amend keys if the key does not already exist and override previous keys if they do.\" [1]</p>"},{"location":"system/network/netplan/#apply-netplan-configurations","title":"Apply Netplan Configurations","text":"<p>After modifying the \"*.yaml\" file, you can use the following command to apply the changes:</p> <pre><code>$ sudo netplan apply\n</code></pre>"},{"location":"system/network/netplan/#create-a-loopback-interface","title":"Create a Loopback Interface","text":"<pre><code>network:\n    version: 2\n    renderer: networkd\n    ethernets:\n        lo:\n            addresses: [ \"127.0.0.1/8\", \"::1/128\", \"7.7.7.7/32\" ]\n</code></pre>"},{"location":"system/network/netplan/#connect-to-network-with-dhcp","title":"Connect to Network with DHCP","text":"<pre><code>network:\n  version: 2\n  ethernets:\n    eth0:\n      dhcp4: true\n  wifis:\n    wlan0:\n      dhcp4: true\n</code></pre>"},{"location":"system/network/netplan/#connect-to-ethernet-with-static-ip","title":"Connect to Ethernet with Static IP","text":"<pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      dhcp4: no\n      addresses:\n        - 10.10.10.2/24\n      nameservers:\n        search: [mydomain, otherdomain]\n        addresses: [10.10.10.1, 1.1.1.1]\n      routes:\n        - to: default\n          via: 10.10.10.1\n</code></pre>"},{"location":"system/network/netplan/#connect-to-wireless-network-with-static-ip","title":"Connect to Wireless Network with Static IP","text":"<pre><code>network:\n  version: 2\n  renderer: networkd\n  wifis:\n    wlan0:\n      dhcp4: no\n      dhcp6: no\n      addresses: [192.168.0.21/24]\n      nameservers:\n        addresses: [192.168.0.1, 8.8.8.8]\n      access-points:\n        \"network_ssid_name\":\n            password: \"**********\"\n      routes:\n        - to: default\n          via: 192.168.0.1\n</code></pre>"},{"location":"system/network/netplan/#configure-a-network-bridge","title":"Configure a Network Bridge","text":"<pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n      enp3s0:\n          dhcp4: no\n  bridges:\n      br0:\n          dhcp4: yes\n          interfaces:\n              - enp3s0\n</code></pre> <p>More references can be found at [3].</p>"},{"location":"system/network/netplan/#reference","title":"Reference","text":"<ul> <li>[1] https://netplan.io/faq</li> <li>[2] https://netplan.io/examples</li> <li>[3] https://netplan.readthedocs.io/en/latest/netplan-yaml/</li> </ul>"},{"location":"system/network/network-config/","title":"Network Configuration","text":"<p>On newer Ubuntu releases, you may not have \"ifconfig\" command by default. Instead, you have \"ip\" command out-of-box. \"ip\" is starting to replace \"ifconfig\" in newer Linux distributions.</p> <p>You can still install ifconfig if it's not present in the system:</p> <pre><code>$ sudo apt-get install net-tools\n</code></pre> <p>Similarly, you can manually install the ip tool:</p> <pre><code>$ sudo apt-get install iproute2\n</code></pre> <ul> <li>Display Current Network Settings</li> </ul> <pre><code>$ ifconfig\n</code></pre> <pre><code>$ ip a\n</code></pre> <ul> <li>Enable and Disable an Interface</li> </ul> <pre><code>$ sudo ifconfig eth0 up\n$ sudo ifconfig eth0 down\n</code></pre> <pre><code>$ sudo ip link set eth0 up\n$ sudo ip link set eth0 down\n</code></pre> <ul> <li>Assign a IP/Netmask to an Interface</li> </ul> <pre><code>$ sudo ifconfig eth0 192.168.0.2\n$ sudo ifconfig eth0 netmask 255.255.255.0\n$ sudo ifconfig eth0 del 192.168.1.10\n$ sudo ifconfig eth0 mtu 1080\n</code></pre> <pre><code>$ sudo ip addr add 192.168.0.2/24 dev eth0\n$ sudo ip addr del 192.168.0.2/24 dev eth0\n$ sudo ip link set dev eth0 mtu 1500\n</code></pre> <ul> <li>Show Routing Table</li> </ul> <pre><code>$ route -n\n$ sudo route add default gw 192.168.1.1\n$ sudo route add -net 10.5.5.10 netmask 255.255.255.0 gw 192.168.0.1\n</code></pre> <pre><code>$ ip route show\n$ sudo ip route add default via 192.168.1.1\n$ sudo ip route add 10.5.5.10/24 via 192.168.0.1 dev eth0\n$ sudo ip route del 10.5.5.10/24\n$ sudo ip route del default via 62.12.113.1 dev eth1\n</code></pre>"},{"location":"system/network/network-inspection/","title":"Network Inspection","text":""},{"location":"system/network/network-inspection/#port","title":"Port","text":"<p>Both <code>netstat</code> and <code>ss</code> command can be used for port usage inspection. <code>ss</code> is regarded as a newer and faster alternative to the older <code>netstat</code>. </p> <p>You can find port information with the following arguments:</p> <pre><code>$ sudo netstat -tulpn\n$ sudo ss -tulpn\n</code></pre> <p>\"tulpn\" is a combination of flags with the following meanings:</p> <pre><code>-t : display only TCP sockets\n-u : display only UDP sockets\n-l : display listening sockets\n-p : show process using socket\n-n : don't resolve service names (e.g. using DNS)\n</code></pre> <p>If you want to see all ports instead of only listening ports, you can replace \"-l\" with \"-a\".</p> <p>More filtering can be done with the result returned by the above command. </p> <p>For example, to inspect usage of port 22:</p> <pre><code>$ sudo ss -tulpn | grep :22\n</code></pre> <p>You should see something similiar to the following if you have sshd installed:</p> <pre><code>tcp   LISTEN 0      128               0.0.0.0:22         0.0.0.0:*    users:((\"sshd\",pid=1638,fd=3))            \ntcp   LISTEN 0      128                  [::]:22            [::]:*    users:((\"sshd\",pid=1638,fd=4))\n</code></pre>"},{"location":"system/network/network-inspection/#dns","title":"DNS","text":"<p>Perform a DNS lookup</p> <pre><code>$ nslookup google.com    \n</code></pre>"},{"location":"system/network/network-inspection/#routing","title":"Routing","text":"<p>Track the route that packets take to reach a destination on a TCP/IP network</p> <pre><code>$ sudo traceroute -T www.google.com\n</code></pre>"},{"location":"system/network/network-inspection/#bandwidth","title":"Bandwidth","text":"<p>Check bandwidth between two hosts</p> <pre><code># on the first computer\n$ iperf3 -s\n\n# on the second computer\n$ iperf3 -c &lt;ip-of-1st-host&gt;\n</code></pre>"},{"location":"system/network/network-inspection/#traffic","title":"Traffic","text":"<p>Monitor network traffic on the host:</p> <pre><code>$ sudo iftop\n</code></pre>"},{"location":"system/network/network-inspection/#reference","title":"Reference","text":"<ul> <li>https://www.cyberciti.biz/faq/how-do-i-check-if-a-port-is-in-use-on-linux/</li> </ul>"},{"location":"system/network/time-sync-using-ntp/","title":"Time Synchronization using NTP and Chrony","text":""},{"location":"system/network/time-sync-using-ntp/#local-time-sync","title":"Local Time Sync","text":"<p>You can use chrony to get one computer to synchronize time with another computer in the same network (e.g. sync between an onboard computer and the host computer).</p> <ol> <li>On computer 1 (which acts as time source), edit \"/etc/chrony/chrony.conf\" and add the network id</li> </ol> <pre><code>allow 192.168.1.0/24\n</code></pre> <ol> <li>On the client computer, edit \"/etc/chrony/chrony.conf\", add the ip of the reference computer</li> </ol> <pre><code>server 192.168.1.XX iburst\n</code></pre> <ol> <li>Make sure you restart the chronyd service after the changes on both of the computers</li> </ol> <pre><code>$ sudo systemctl restart chronyd\n</code></pre>"},{"location":"system/network/time-sync-using-ntp/#command-reference","title":"Command Reference","text":"<ul> <li>Chrony service management</li> </ul> <pre><code>$ sudo apt-get install chrony\n$ sudo systemctl status chronyd\n$ sudo systemctl restart chronyd\n</code></pre> <ul> <li>Check the status of time tracking </li> </ul> <pre><code>$ chronyc tracking\n</code></pre> <p>Example output:</p> <pre><code>$ chronyc tracking\nReference ID    : AC682C78 (ntp-singapore.gombadi.com)\nStratum         : 3\nRef time (UTC)  : Tue Sep 26 07:26:09 2023\nSystem time     : 0.000219948 seconds slow of NTP time\nLast offset     : -0.000393732 seconds\nRMS offset      : 0.000415190 seconds\nFrequency       : 14.277 ppm slow\nResidual freq   : -0.011 ppm\nSkew            : 0.149 ppm\nRoot delay      : 0.041356131 seconds\nRoot dispersion : 0.003122247 seconds\nUpdate interval : 1024.8 seconds\nLeap status     : Normal\n</code></pre> <ul> <li>Check source of time references</li> </ul> <pre><code>$ chronyc sources\n</code></pre> <p>Example output:</p> <pre><code>$ chronyc sources\nMS Name/IP address         Stratum Poll Reach LastRx Last sample               \n===============================================================================\n^- prod-ntp-5.ntp4.ps5.cano&gt;     2  10   377   753  -1024us[-1349us] +/-   85ms\n^- prod-ntp-3.ntp4.ps5.cano&gt;     2  10   377  1052  -3399us[-3719us] +/-   82ms\n^- prod-ntp-4.ntp1.ps5.cano&gt;     2  10   377   51m   -435us[  -88us] +/-   80ms\n^- alphyn.canonical.com          2  10   377   24m    +11ms[  +11ms] +/-  157ms\n^+ time.cloudflare.com           3  10   377   987  -2820us[-3141us] +/-   47ms\n^+ time.cloudflare.com           3  10   377   218  -3917us[-3917us] +/-   48ms\n^* ntp-singapore.gombadi.com     2  10   377   675  +1893us[+1566us] +/-   22ms\n^- sg.time.clearnet.pw           2  10   377   819  -9809us[  -10ms] +/-  118ms\n</code></pre>"},{"location":"system/network/time-sync-using-ntp/#reference","title":"Reference","text":"<ul> <li>https://chrony-project.org/</li> <li>https://robofoundry.medium.com/how-to-sync-time-between-robot-and-host-machine-for-ros2-ecbcff8aadc4</li> </ul>"},{"location":"system/network/time-sync-using-ptp/","title":"Time Synchronization using PTP/IEEE1588","text":"<p>For a complicated robotic system, there may be multiple onboard computers and sensors working together to have the whole system functional. To ensure the data from different devices are synchronized in time, you may need to consider time synchronization among the devices. PTP is a synchronization protocol designed for this purpose and it allows sub-microsecond accuracy if properly configured. One example usage of PTP time synchronization is setting up an Ouster OS1-64 Lidar on a mobile robot for 3D mapping and navigation. To get the right timestamp for the pointcloud to be used with other parts of ROS stack, such as mapping and localization, a PTP grandmaster can be configured on the navigation computer to synchronize the time between Lidar and the computer.</p>"},{"location":"system/network/time-sync-using-ptp/#1-background-information","title":"1. Background Information","text":""},{"location":"system/network/time-sync-using-ptp/#11-how-ptp-works","title":"1.1 How PTP works","text":"<p>Here are some good references:</p> <ul> <li>AlliedTelesis Doc: Precision Time Protocol &amp; Transparent Clock</li> <li>NetTimeLogic Doc: PTP Basics</li> </ul> <p>You can either use a dedicated PTP grand master hardware or set up a Linux computer to act as the master. In this note, we mainly consider the latter case. </p>"},{"location":"system/network/time-sync-using-ptp/#12-ptp-profiles","title":"1.2 PTP profiles","text":"<p>The following table is taken from [4] by peci1 published on ROS Discourse:</p> Profile BMCA Delay mech. Layer Default Yes P2P/E2E L2/L3 gPTP (802.1AS) 17 Yes P2P L2 Automotive        10 No P2P L2 Autosar 9 No P2P L2 LXI 1 Yes P2P L3 IEC 62439-3 L2P2P Yes P2P L2 IEC 62439-3 L3E2E Yes E2E L3 Power Profile Yes P2P L2 GigE Vision 11 Yes P2P/E2E ? <ul> <li>The <code>default</code> profile is most commonly supported and used by computers and sensors on the robot</li> <li>The <code>gPTP</code> profile has more strict requirements in the setup (for both the devices and network switches)</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#13-additional-tutorials-references","title":"1.3 Additional tutorials &amp; references","text":"<ul> <li>Redhat Doc: Configuring PTP Using ptp4l</li> <li>ptp4l (manual)</li> <li>phc2sys (manual)</li> <li>Ouster PTP Reference</li> <li>PTP support in the Raspberry Pi CM4 and CM5</li> <li>TSN Documentation Project for Linux</li> <li>Raspberry Pi CM4 PTP Guide</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#2-configure-ptp-in-linux","title":"2. Configure PTP in Linux","text":""},{"location":"system/network/time-sync-using-ptp/#21-sofware-packages","title":"2.1 Sofware packages","text":"<p>You may use <code>ethtool</code>, <code>linuxptp</code> and <code>chrony</code> in the setup. They can be installed from apt-get directly:</p> <pre><code>## install the packages\n$ sudo apt install ethtool linuxptp \n\n## only install if needed\nsudo apt install chrony\n</code></pre> <p>The following list is taken from the Ouster documentation to give you a brief idea of the functions of the packages:</p> <ul> <li>ethtool - A tool to query the hardware and driver capabilities of a given Ethernet interface.</li> <li>linuxptp - Linux PTP package with the following components:<ul> <li>ptp4l daemon to manage hardware and participate as a PTP node</li> <li>phc2sys to synchronize the Ethernet controller\u2019s hardware clock to the Linux system clock or shared memory region</li> <li>pmc to query the PTP nodes on the network.</li> <li>ts2phc to synchronize PTP Hardware Clocks (PHC) to external time stamp signals.</li> </ul> </li> <li>chrony - A NTP and PTP time synchronization daemon. It can be configured to listen to both NTP time sources via the Internet and a PTP master clock such as one provided by a GPS with PTP support. This will validate the time configuration makes sense given multiple time sources.</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#22-check-hardware-and-driver-support","title":"2.2 Check hardware and driver support","text":"<p>You can use the following command to check the hardware and driver support of the network interface:</p> <pre><code>$ ethtool -T eth0\n</code></pre> <p>Ideally the ethernet adapter and driver should support hardware timestamp. You may get something like this:</p> <pre><code>Time stamping parameters for eth0:\nCapabilities:\n    hardware-transmit     (SOF_TIMESTAMPING_TX_HARDWARE)\n    software-transmit     (SOF_TIMESTAMPING_TX_SOFTWARE)\n    hardware-receive      (SOF_TIMESTAMPING_RX_HARDWARE)\n    software-receive      (SOF_TIMESTAMPING_RX_SOFTWARE)\n    software-system-clock (SOF_TIMESTAMPING_SOFTWARE)\n    hardware-raw-clock    (SOF_TIMESTAMPING_RAW_HARDWARE)\nPTP Hardware Clock: 0\nHardware Transmit Timestamp Modes:\n    off                   (HWTSTAMP_TX_OFF)\n    on                    (HWTSTAMP_TX_ON)\n    one-step-sync         (HWTSTAMP_TX_ONESTEP_SYNC)\nHardware Receive Filter Modes:\n    none                  (HWTSTAMP_FILTER_NONE)\n    ptpv1-l4-sync         (HWTSTAMP_FILTER_PTP_V1_L4_SYNC)\n    ptpv1-l4-delay-req    (HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ)\n    ptpv2-l4-sync         (HWTSTAMP_FILTER_PTP_V2_L4_SYNC)\n    ptpv2-l4-delay-req    (HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ)\n    ptpv2-l2-sync         (HWTSTAMP_FILTER_PTP_V2_L2_SYNC)\n    ptpv2-l2-delay-req    (HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ)\n    ptpv2-event           (HWTSTAMP_FILTER_PTP_V2_EVENT)\n</code></pre> <p>Otherwise if only software timestamp is support, you may see</p> <pre><code>Time stamping parameters for eth0:\nCapabilities:\n    software-transmit\n    software-receive\n    software-system-clock\nPTP Hardware Clock: none\nHardware Transmit Timestamp Modes: none\nHardware Receive Filter Modes: none\n</code></pre>"},{"location":"system/network/time-sync-using-ptp/#23-general-workflow","title":"2.3 General workflow","text":"<p>In general, what we try to achieve in time synchronization for devices within a robot include:</p> <ul> <li>all these devices share the same time base after synchronization (with bounded time offset)</li> <li>the system time on all devices should not jump backwards (monotonically increasing)</li> </ul> <p>The general synchonization setup is illustrated as follows:</p> <pre><code>              [ Internet NTP Servers (optional) ]\n                             |\n                             v\n        +-----------------------------------------------+\n        |          \ud83e\udde0 PTP Grandmaster Node              |\n        | (Main onboard PC with PHC-capable NIC)   |\n        | ---------------------------------------- |\n        |                                          |\n        | 1. Chrony disciplines CLOCK_REALTIME     |\n        | - One-time step (makestep 1.0 1)         |\n        | - Then slews slowly to avoid jumps       |\n        |                                          |\n        | 2. phc2sys pushes CLOCK_REALTIME to PHC: |\n        | phc2sys -w -s CLOCK_REALTIME -c eth0     |\n        | -&gt; Ensures PHC stays aligned to system   |\n        |                                          |\n        | 3. ptp4l advertises PHC to PTP network:  |\n        | ptp4l -i eth0 -f /etc/ptp4l.conf         |\n        | -&gt; Acts as Grandmaster                   |\n        +-----------------------------------------------+\n                             |\n                             |   (PTP over Ethernet)\n                             v\n        +-----------------------------------------------+\n        | \ud83e\udde9 PTP Slave Nodes (Aux PCs, Jetsons)     |\n        | ---------------------------------------- |\n        |                                          |\n        | 1. ptp4l syncs PHC from Grandmaster:     |\n        | ptp4l -s -i eth0                         |\n        |                                          |\n        | 2. phc2sys updates system clock:         |\n        | phc2sys -w -s eth0 -c CLOCK_REALTIME     |\n        |                                          |\n        | -&gt; CLOCK_REALTIME is now aligned with GM |\n        +-----------------------------------------------+\n                             |\n                             v\n        +-----------------------------------------------+\n        |        \ud83c\udfa5 Sensors with PTP support (optional) |\n        | (e.g., Ouster LiDAR, FLIR cameras)            |\n        | --------------------------------------------- |\n        | Internal PTP slave logic or hardware          |\n        | syncs device clock from network               |\n        | -&gt; Ensures timestamps align with robot clocks |\n        +-----------------------------------------------+\n</code></pre>"},{"location":"system/network/time-sync-using-ptp/#24-ptp-grandmaster-setup","title":"2.4 PTP grandmaster setup","text":""},{"location":"system/network/time-sync-using-ptp/#241-configure-chrony-to-synchonize-system-time-from-the-ntp-servers","title":"2.4.1 Configure Chrony to synchonize system time from the NTP servers","text":"<p>This step is optional as all devices can still work with a local time base. But in most cases, we may want the robot system to use the correct global time for convenience (e.g. when checking and retrieving logs from the robot). This can be achived with Chrony. </p> <p>Edit <code>/etc/chrony/chrony.conf</code>:</p> <pre><code># Step the system clock instead of slewing it if the adjustment is larger than\n# one second, but only in the first clock update (default 3 =&gt; 1).\nmakestep 1 1\n</code></pre> <p>The main change we make is to make sure chony only steps once at the start (before the robot starts working) to avoid the system time to jump backwards.</p> <p>You can use the following commands to check the chrony synchonization status:</p> <pre><code>$ chronyc tracking\n$ chronyc sources -v\n</code></pre>"},{"location":"system/network/time-sync-using-ptp/#242-configure-phc2sys-to-synchronize-the-system-time-to-the-ptp-clock","title":"2.4.2 Configure phc2sys to synchronize the system time to the PTP clock","text":"<p>This step synchonizes time from the system clock to the PHC. Otherwise, the initial value of the PHC time is undefined that you may see nonsense values from it. You can check the system time and PHC time with the following commands: </p> <pre><code># system time\n$ date\n\n# PHC time on eth0\n$ sudo phc_ctl eth0 get\n</code></pre> <ol> <li> <p>Create a systemd service for phc2sys: /etc/systemd/system/phc2sys.service</p> <pre><code>[Unit]\nDescription=Synchronize system clock or PTP hardware clock (PHC)\nDocumentation=man:phc2sys\nRequires=ptp4l.service\nAfter=chrony.service ptp4l.service\n\n[Service]\n# -s: master clock, -c: slave clock\nExecStart=/usr/sbin/phc2sys -s CLOCK_REALTIME -c eth0 -w\nRestart=on-failure\nRestartSec=2\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>The <code>-w</code> argument instructs phc2sys to get the TAI-UTC offset from the kernel, so leap seconds are handled automatically.</p> </li> <li> <p>Start and enable the phc2sys service</p> <pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl start phc2sys.service\n# if you get no errors starting the service\n$ sudo systemctl enable phc2sys.service\n</code></pre> <p>You will see phc2sys starts waiting for ptp4l as it the ptp4l service to set up everything in order for it to acquire the TAI-UTC offset properly. Proceed to the next step first.</p> </li> </ol>"},{"location":"system/network/time-sync-using-ptp/#243-set-up-ptp-clock-master","title":"2.4.3 Set up ptp clock master","text":"<ol> <li> <p>Update the configuration file /etc/linuxptp/ptp4l.conf</p> <p>If you're setting  up a master clock, change the following lines:</p> <p><pre><code>#clockClass     248\nclockClass      128\n</code></pre> clockClass with a value of 128 indicates that the clock you're setting up is free-running and not synchonized to an external reference source (e.g. GPS time)</p> <p>If you have multiple network intefaces on the computer and you want the computer to act as a boundary clock: <pre><code>  # at very bottom of the file\nboundary_clock_jbod 1\n[eth0]\n[eth1]\n</code></pre> Typically you won't need this configuration as it only gives you multiple isolated PTP networks (where the name \"boundary\" is from). </p> <p>If what you really want is to synchonize time bewteen the interfaces, you still need to further configure the time using <code>phc2sys</code>.</p> <pre><code># e.g. set eth0 time to eth1\nphc2sys -w -s eth0 -c eth1\n</code></pre> </li> <li> <p>Create a systemd service for ptp4l: /etc/systemd/system/ptp4l.service</p> <p>Make sure you update the interface name in the <code>-i eth0</code> part</p> <pre><code>[Unit]\nDescription=ptp4l service\nRequires=network-online.target\nAfter=network-online.target\n\n[Service]\nExecStart=/usr/sbin/ptp4l -i eth0 -f /etc/linuxptp/ptp4l.conf\nRestart=on-failure\nRestartSec=2\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Start and enable the ptp4l service</p> <pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl start ptp4l.service\n# if you get no errors starting the service\n$ sudo systemctl enable ptp4l.service\n</code></pre> </li> </ol>"},{"location":"system/network/time-sync-using-ptp/#25-ptp-slave-setup","title":"2.5 PTP slave setup","text":""},{"location":"system/network/time-sync-using-ptp/#251-set-up-ptp-slave","title":"2.5.1 Set up PTP slave","text":"<ol> <li> <p>Update the configuration file /etc/linuxptp/ptp4l.conf</p> <p>If you're setting up a slave device, change the following lines: <pre><code>#slaveOnly              0\nslaveOnly               1\n</code></pre></p> </li> <li> <p>Create a systemd service for ptp4l: /etc/systemd/system/ptp4l.service</p> <p>Make sure you update the interface name in the <code>-i eth0</code> part</p> <pre><code>[Unit]\nDescription=ptp4l service\nRequires=network-online.target\nAfter=network-online.target\n\n[Service]\nExecStart=/usr/sbin/ptp4l -i eth0 -f /etc/linuxptp/ptp4l.conf\nRestart=on-failure\nRestartSec=2\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Start and enable the ptp4l service</p> <pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl start ptp4l.service\n# if you get no errors starting the service\n$ sudo systemctl enable ptp4l.service\n</code></pre> </li> </ol>"},{"location":"system/network/time-sync-using-ptp/#252-configure-phc2sys-to-synchronize-the-ptp-clock-to-the-system-time","title":"2.5.2 Configure phc2sys to synchronize the PTP clock to the system time","text":"<ol> <li> <p>Create a systemd service for phc2sys: /etc/systemd/system/phc2sys.service</p> <pre><code>[Unit]\nDescription=Synchronize system clock or PTP hardware clock (PHC)\nDocumentation=man:phc2sys\nRequires=ptp4l.service\nAfter=ptp4l.service\n\n[Service]\nExecStart=/usr/sbin/phc2sys -w -s eth0 -c CLOCK_REALTIME\nRestart=on-failure\nRestartSec=2\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Start and enable the phc2sys service</p> <pre><code>$ sudo systemctl daemon-reload\n$ sudo systemctl start phc2sys.service\n# if you get no errors starting the service\n$ sudo systemctl enable phc2sys.service\n</code></pre> </li> <li> <p>Make sure you have disabled all NTP clients that may change the system clock</p> <pre><code>sudo systemctl disable --now chrony\nsudo systemctl disable --now systemd-timesyncd\nsudo systemctl disable --now ntp\n</code></pre> </li> </ol>"},{"location":"system/network/time-sync-using-ptp/#26-check-clock-synchronization","title":"2.6 Check clock synchronization","text":"<ul> <li> <p>Check time synchronization between PHC and the Grandmaster clock (on PTP slave)</p> <p>Look at output of the ptp4l:</p> <pre><code>ptp4l[5374018.735]: rms  787 max 1208 freq -38601 +/- 1071 delay  -14 +/-   0\nptp4l[5374019.735]: rms 1314 max 1380 freq -36204 +/- 346 delay   -14 +/-   0\nptp4l[5374020.735]: rms  836 max 1106 freq -35734 +/-  31 delay   -14 +/-   0\nptp4l[5374021.736]: rms  273 max  450 freq -35984 +/-  97 delay   -14 +/-   0\nptp4l[5374022.736]: rms   50 max   82 freq -36271 +/-  64 delay   -14 +/-   0\nptp4l[5374023.736]: rms   81 max   86 freq -36413 +/-  17 delay   -14 +/-   0\n</code></pre> </li> </ul> <p>Units: rms/max: nanoseconds (ns), freq: parts per billion (ppb), delay: nanoseconds (ns)</p> <ul> <li> <p>Check time synchronization between the PHC and the system clock</p> <p>Look at output of the phc2sys:</p> <pre><code>phc2sys[5374168.545]: CLOCK_REALTIME phc offset   -372582 s0 freq    +246 delay   6649\nphc2sys[5374169.545]: CLOCK_REALTIME phc offset   -372832 s1 freq      -4 delay   6673\nphc2sys[5374170.547]: CLOCK_REALTIME phc offset        68 s2 freq     +64 delay   6640\nphc2sys[5374171.547]: CLOCK_REALTIME phc offset       -20 s2 freq      -3 delay   6687\nphc2sys[5374172.547]: CLOCK_REALTIME phc offset        47 s2 freq     +58 delay   6619\nphc2sys[5374173.548]: CLOCK_REALTIME phc offset       -40 s2 freq     -15 delay   6680\n</code></pre> </li> </ul> <p>Units: offset: nanoseconds (ns), freq: parts per billion (ppb), delay: nanoseconds (ns)</p> <ul> <li> <p>Typical ranges of the synchronization accuracy you may expect:</p> Metric Software TimeStamps Hardware TimeStamps Offset 10\u2013100 \u00b5s &lt;1 \u00b5s Path delay 50\u2013300 \u00b5s &lt;10 \u00b5s Freq correction \u00b110\u201350 ppm \u00b11 ppm </li> </ul> <p>Units: 1 \u00b5s = 1000 ns, 1 ppm = 1000 ppb</p> <p>More information about clock synchronization check can be found from [6].</p>"},{"location":"system/network/time-sync-using-ptp/#3-key-parameters-to-tune","title":"3. Key Parameters to Tune","text":""},{"location":"system/network/time-sync-using-ptp/#31-role-topology-control-bmca-related","title":"3.1 Role &amp; topology control (BMCA-related)","text":"<p>These decide who becomes master and prevent \u201ceveryone is GM\u201d disasters.</p> <p>Best practice</p> <ul> <li>Explicitly set these everywhere</li> <li>Don\u2019t rely on defaults</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#slaveonly","title":"<code>slaveOnly</code>","text":"<pre><code>slaveOnly 1   # force this node to never be GM\n</code></pre> <ul> <li>Most important safety switch</li> <li>Use on all non-GM nodes</li> <li>Prevents accidental GM election</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#priority1-priority2","title":"<code>priority1</code>, <code>priority2</code>","text":"<pre><code>priority1 100\npriority2 100\n</code></pre> <p>BMCA ranking order (simplified):</p> <ol> <li><code>priority1</code></li> <li>clockClass</li> <li>clockAccuracy</li> <li><code>priority2</code></li> <li>clockIdentity</li> </ol> <p>Lower = better.</p>"},{"location":"system/network/time-sync-using-ptp/#clockclass","title":"<code>clockClass</code>","text":"<ul> <li>Advertised automatically</li> <li><code>&lt;128</code> = GM-capable</li> <li><code>248</code> = slave-only</li> </ul> <p>You usually don\u2019t set this directly, but you must know what it means when debugging BMCA.</p>"},{"location":"system/network/time-sync-using-ptp/#32-transport-profile-common-failure-source","title":"3.2 Transport &amp; profile (common failure source)","text":"<p>These must match exactly across all nodes.</p>"},{"location":"system/network/time-sync-using-ptp/#network_transport","title":"<code>network_transport</code>","text":"<pre><code>network_transport UDPv4   # most common\n# or: L2\n</code></pre> <p>Mismatch \u2192 foreign master, bad message, or silent failure.</p>"},{"location":"system/network/time-sync-using-ptp/#delay_mechanism","title":"<code>delay_mechanism</code>","text":"<pre><code>delay_mechanism E2E\n# or: P2P (gPTP / TSN)\n</code></pre> <ul> <li><code>E2E</code> \u2192 standard IEEE 1588</li> <li><code>P2P</code> \u2192 requires switch support</li> </ul> <p>\ud83d\udccc Never mix.</p>"},{"location":"system/network/time-sync-using-ptp/#domainnumber","title":"<code>domainNumber</code>","text":"<pre><code>domainNumber 0\n</code></pre> <ul> <li>Logical PTP \u201cnetwork\u201d</li> <li>Masters and slaves must match</li> <li>Multiple domains can coexist on one LAN</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#ptp_profile","title":"<code>ptp_profile</code>","text":"<pre><code>ptp_profile default\n</code></pre> <p>Profiles change message formats &amp; expectations.</p> <p>\u26a0\ufe0f Mixing profiles = guaranteed pain.</p>"},{"location":"system/network/time-sync-using-ptp/#33-timestamping-clock-devices-accuracy-stability","title":"3.3 Timestamping &amp; clock devices (accuracy + stability)","text":""},{"location":"system/network/time-sync-using-ptp/#time_stamping","title":"<code>time_stamping</code>","text":"<pre><code>time_stamping software\n# or: hardware\n</code></pre> Mode Accuracy Complexity software 10\u2013100 \u00b5s easy hardware &lt;1 \u00b5s harder <p>Know which one you\u2019re running and why.</p>"},{"location":"system/network/time-sync-using-ptp/#phc-hardware-clock-concepts","title":"PHC (hardware clock) concepts","text":"<p>Even if you don\u2019t configure it directly, understand:</p> <ul> <li><code>/dev/ptp0</code></li> <li>NIC \u2194 PHC mapping</li> <li><code>ethtool -T</code></li> </ul> <p>Misunderstanding PHC = FAULTY state (<code>/dev/ptp-1</code>).</p>"},{"location":"system/network/time-sync-using-ptp/#34-servo-convergence-behavior-performance-tuning","title":"3.4 Servo &amp; convergence behavior (performance tuning)","text":"<p>These affect how fast and how smoothly clocks lock.</p>"},{"location":"system/network/time-sync-using-ptp/#servo-state-s0-s1-s2","title":"Servo state (<code>s0</code>, <code>s1</code>, <code>s2</code>)","text":"<p>Observed in logs:</p> <pre><code>s0 = unlocked\ns1 = coarse\ns2 = locked\n</code></pre> <p>You want s2 most of the time.</p>"},{"location":"system/network/time-sync-using-ptp/#pi_proportional_const-pi_integral_const","title":"<code>pi_proportional_const</code>, <code>pi_integral_const</code>","text":"<ul> <li>PI servo gains</li> <li> <p>Rarely touched unless you:</p> </li> <li> <p>have oscillations</p> </li> <li>do very fast sync intervals</li> </ul> <p>\ud83d\udccc Leave defaults unless you know control theory.</p>"},{"location":"system/network/time-sync-using-ptp/#sanity_freq_limit","title":"<code>sanity_freq_limit</code>","text":"<pre><code>sanity_freq_limit 200000000\n</code></pre> <ul> <li>Prevents insane freq corrections</li> <li>Important for unstable oscillators</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#35-message-rates-bandwidth-vs-responsiveness","title":"3.5 Message rates (bandwidth vs responsiveness)","text":""},{"location":"system/network/time-sync-using-ptp/#logsyncinterval","title":"<code>logSyncInterval</code>","text":"<pre><code>logSyncInterval -3   # 8 Hz\n</code></pre> <p>Actual rate = <code>2^logSyncInterval</code>.</p> Value Rate 0 1 Hz -3 8 Hz -6 64 Hz <p>Higher rate \u2192 faster convergence, more CPU.</p>"},{"location":"system/network/time-sync-using-ptp/#logannounceinterval","title":"<code>logAnnounceInterval</code>","text":"<pre><code>logAnnounceInterval 1   # every 2s\n</code></pre> <p>Controls BMCA responsiveness.</p>"},{"location":"system/network/time-sync-using-ptp/#logmindelayreqinterval","title":"<code>logMinDelayReqInterval</code>","text":"<p>Controls DELAY_REQ frequency.</p>"},{"location":"system/network/time-sync-using-ptp/#36-diagnostics-observability-debugging-superpowers","title":"3.6 Diagnostics &amp; observability (debugging superpowers)","text":""},{"location":"system/network/time-sync-using-ptp/#verbose","title":"<code>verbose</code>","text":"<pre><code>verbose 1\n</code></pre> <p>More insight into state transitions.</p>"},{"location":"system/network/time-sync-using-ptp/#pmc-datasets-to-understand","title":"PMC datasets to understand","text":"<p>Learn these commands:</p> <pre><code>pmc -u -b 0 \"GET TIME_STATUS_NP\"\npmc -u -b 0 \"GET DEFAULT_DATA_SET\"\npmc -u -b 0 \"GET PARENT_DATA_SET\"\npmc -u -b 0 \"GET CLOCK_DESCRIPTION\"\n</code></pre> <p>These tell you:</p> <ul> <li>Who the GM is</li> <li>Why BMCA chose it</li> <li>Whether you\u2019re locked</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#37-parameters-you-usually-should-not-touch","title":"3.7 Parameters you usually (should NOT touch)","text":"<p>(know them, but don\u2019t tweak lightly)</p> <ul> <li><code>announceReceiptTimeout</code></li> <li><code>syncReceiptTimeout</code></li> <li><code>neighborPropDelayThresh</code></li> <li><code>clock_servo</code> (unless experimenting)</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#38-recommended-mental-model","title":"3.8 Recommended mental model","text":"<p>Think in layers:</p> <pre><code>Topology (BMCA)\n   \u2193\nTransport / Profile\n   \u2193\nTimestamping (SW vs HW)\n   \u2193\nServo behavior\n   \u2193\nApplication time usage\n</code></pre> <p>Most PTP bugs happen in the top two layers.</p>"},{"location":"system/network/time-sync-using-ptp/#39-minimal-good-citizen-checklist","title":"3.9 Minimal \u201cgood citizen\u201d checklist","text":"<p>Every node should explicitly set:</p> <pre><code>network_transport UDPv4\ndelay_mechanism E2E\ndomainNumber 0\nptp_profile default\n</code></pre> <p>Every non-GM node:</p> <pre><code>slaveOnly 1\n</code></pre> <p>Every GM:</p> <pre><code>priority1 &lt; slaves\n</code></pre>"},{"location":"system/network/time-sync-using-ptp/#4-additional-information","title":"4. Additional Information","text":"<ul> <li>https://botblox.io/collections/frontpage</li> </ul>"},{"location":"system/network/time-sync-using-ptp/#reference","title":"Reference","text":"<ul> <li>[1] Ouster Sensor Docs (wiki)</li> <li>[2] Ouster Lidar Software User Manual</li> <li>[3] PTP for Mobile Robots</li> <li>[4] Combining PTP with NTP to Get the Best of Both Worlds </li> <li>[5] Synchronize to PTP or NTP Time Using timemaster</li> <li>[6] Synchronizing Time with Linux PTP</li> <li>[7] Multi-robot coordination: Distributed synchronization of industrial robots through ROS 2</li> </ul>"},{"location":"system/network/wireshark-reference/","title":"Wireshark Reference","text":""},{"location":"system/network/wireshark-reference/#installation","title":"Installation","text":"<pre><code># GUI version\n$ sudo apt install wireshark\n\n# terminal version\n$ sudo apt install tshark\n</code></pre>"},{"location":"system/network/wireshark-reference/#packet-filtering","title":"Packet Filtering","text":"<p>TODO</p>"},{"location":"system/network/wireshark-reference/#reference","title":"Reference","text":""},{"location":"system/security/ca_setup/","title":"Certificate Authority Setup","text":""},{"location":"system/security/ca_setup/#openssl-certificate-authority","title":"OpenSSL Certificate Authority","text":"<p>Refer to [1] for more details about how to create a private certificate authority and use it to self-sign SSL certificates. For key generate and protection, refer to [2] and [3].</p>"},{"location":"system/security/ca_setup/#reference","title":"Reference","text":"<ul> <li>[1] https://jamielinux.com/docs/openssl-certificate-authority/index.html</li> <li>[2] https://tpm2-software.github.io/software/</li> <li>[3] https://github.com/tpm2-software</li> </ul>"},{"location":"system/security/resource/","title":"Resource","text":""},{"location":"system/security/resource/#security","title":"Security","text":"<ul> <li>https://github.com/keylime/keylime</li> </ul>"},{"location":"system/security/resource/#access-management","title":"Access Management","text":"<ul> <li>https://www.keycloak.org/</li> <li>https://github.com/hashicorp/vault</li> </ul>"},{"location":"system/security/ssl_handshake/","title":"SSL/TLS Handshake","text":"<p>Info</p> <p>This note was written with the assistance of ChatGPT.</p> <p>The following is an overview of the SSL/TLS handshake process:</p>"},{"location":"system/security/ssl_handshake/#1-verification-of-trusted-entities-using-ca-certificates","title":"1. Verification of Trusted Entities Using CA Certificates","text":"<ul> <li>Purpose: The primary purpose of the CA certificate is to establish trust between the communicating entities (server and client).</li> <li>How it works: When a client connects to a server, the server presents its certificate to the client. This certificate includes the server's public key and is signed by a trusted Certificate Authority (CA). The client uses the CA's certificate (which includes the CA's public key) to verify the server's certificate. If the verification is successful, it means the server's certificate is trusted.</li> <li>Mutual TLS: In mutual TLS (mTLS), the client also presents its certificate to the server, and the server verifies it using the CA's certificate.</li> </ul>"},{"location":"system/security/ssl_handshake/#2-exchange-of-public-keys","title":"2. Exchange of Public Keys","text":"<ul> <li>Initial Handshake: During the SSL/TLS handshake, the server and client exchange their public keys. This is part of the certificate exchange process.</li> <li>Server Key Exchange: The server sends its public key to the client in its certificate. If using mTLS, the client also sends its public key to the server in its certificate.</li> <li>Purpose: These public keys are used to securely exchange a session key, which will be used for encrypting the data during the session.</li> </ul>"},{"location":"system/security/ssl_handshake/#3-encryption-and-decryption-using-public-and-private-keys","title":"3. Encryption and Decryption Using Public and Private Keys","text":"<ul> <li>Public Key Encryption: Once the public keys are exchanged, the client and server can encrypt data using the public key of the other party. However, in most SSL/TLS implementations, this direct encryption/decryption with public/private keys is used primarily for secure key exchange rather than for the bulk data encryption.</li> <li>Session Key: The actual data encryption uses symmetric encryption with a session key (also called a shared secret). The session key is exchanged securely using the public keys of the server and client.</li> <li>RSA Key Exchange: The client generates a session key, encrypts it with the server\u2019s public key, and sends it to the server. Only the server, with its private key, can decrypt this session key.</li> <li> <p>Diffie-Hellman Key Exchange: The client and server use the Diffie-Hellman algorithm (or its elliptic curve variant) to securely agree on a session key over an insecure channel without directly exchanging the key.</p> </li> <li> <p>Data Encryption: After the session key is established:</p> </li> <li>The client and server use this symmetric session key to encrypt and decrypt the data they send to each other.</li> <li>Symmetric encryption (e.g., AES) is used for the actual data encryption because it is much faster than asymmetric encryption.</li> </ul>"},{"location":"system/security/ssl_handshake/#detailed-steps-in-an-ssltls-handshake","title":"Detailed Steps in an SSL/TLS Handshake","text":"<ol> <li> <p>Client Hello:    The client sends a \"Client Hello\" message to the server, which includes supported SSL/TLS versions, cipher suites, and a random number.</p> </li> <li> <p>Server Hello:    The server responds with a \"Server Hello\" message, including the chosen SSL/TLS version, cipher suite, and a random number.</p> </li> <li> <p>Server Certificate:    The server sends its certificate to the client. This certificate contains the server\u2019s public key and is signed by a CA.</p> </li> <li> <p>(Optional) Client Certificate:    In mTLS, the server also requests the client\u2019s certificate, and the client sends it in this step.</p> </li> <li> <p>Key Exchange:</p> <ul> <li>RSA: The client generates a session key, encrypts it with the server\u2019s public key, and sends it to the server.</li> <li>Diffie-Hellman: The client and server exchange Diffie-Hellman parameters to securely agree on a session key.</li> </ul> </li> <li> <p>Server and Client Finished:    Both the server and client send a \"Finished\" message encrypted with the session key, indicating that the handshake is complete.</p> </li> <li> <p>Secure Communication:    All subsequent data is encrypted with the symmetric session key established during the handshake.</p> </li> </ol>"},{"location":"system/security/ssl_handshake/#summary","title":"Summary","text":"<ul> <li>CA Certificate: Used to verify the authenticity of the server and client certificates, ensuring they are trusted entities.</li> <li>Public Key Exchange: Public keys are exchanged to securely establish a session key.</li> <li>Session Key: A symmetric session key is used for encrypting and decrypting the actual data during the communication.</li> </ul> <p>By following this process, SSL/TLS ensures secure and authenticated communication between the client and server.</p>"}]}